"""
DataCulture Unified Platform
–û–±—ä–µ–¥–∏–Ω—ë–Ω–Ω–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –¥–ª—è –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ Data Culture @ HSE University
–ê–≤—Ç–æ—Ä: –¢–∏–º–æ—à–∫–∞
"""
import streamlit as st
import pandas as pd
import numpy as np
from datetime import datetime
import io
import json
from openai import OpenAI
import tempfile
import os
from typing import Dict, Tuple, List
from supabase import create_client, Client

# =============================================================================
# –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø –ü–†–ò–õ–û–ñ–ï–ù–ò–Ø
# =============================================================================
st.set_page_config(
    page_title="DataCulture Platform",
    page_icon="üìä",
    layout="wide",
    initial_sidebar_state="expanded"
)

# =============================================================================
# –ö–û–ù–°–¢–ê–ù–¢–´
# =============================================================================
LOGO_URL = "https://raw.githubusercontent.com/TimPad/html/main/DC_green.svg"
HTML_EXAMPLE = f"""<div style="font-family: 'Inter', 'Segoe UI', Roboto, Arial, sans-serif; max-width: 860px; margin: 40px auto; background: #ffffff; border-radius: 16px; box-shadow: 0 4px 14px rgba(0,0,0,0.08); border: 1px solid #e5ebf8; overflow: hidden;">
    <div style="background: #00256c; color: white; padding: 28px 32px; text-align: center;">
        <img src="{LOGO_URL}" alt="–õ–æ–≥–æ—Ç–∏–ø Data Culture" style="height: 48px; margin-bottom: 16px;">
        <p><span style="font-size: 1.6em; font-weight: 700;">–ó–ê–ì–û–õ–û–í–û–ö –û–ë–™–Ø–í–õ–ï–ù–ò–Ø</span></p>
        <p style="margin-top: 8px; line-height: 1.5;">–ö—Ä–∞—Ç–∫–æ–µ –≤–≤–µ–¥–µ–Ω–∏–µ –∏–ª–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç.</p>
    </div>
    <div style="padding: 28px 32px; color: #111827; line-height: 1.65;">
        <p>–û—Å–Ω–æ–≤–Ω–æ–π —Ç–µ–∫—Å—Ç –æ–±—ä—è–≤–ª–µ–Ω–∏—è...</p>
        <h3 style="color: #00256c;">–ü–æ–¥–∑–∞–≥–æ–ª–æ–≤–æ–∫</h3>
        <ul style="margin: 12px 0 22px 22px;">
            <li>–ü—É–Ω–∫—Ç —Å–ø–∏—Å–∫–∞</li>
        </ul>
        <div style="background: #f4f6fb; border-radius: 10px; padding: 16px 20px; margin: 16px 0;">
            <p>–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω—ã–π –±–ª–æ–∫</p>
        </div>
        <div style="background: #fff8e1; border-left: 4px solid #f59e0b; padding: 14px 18px; border-radius: 8px; margin-bottom: 20px;">
            <p style="margin: 0; font-weight: 600; color: #92400e;">‚ö†Ô∏è –í–Ω–∏–º–∞–Ω–∏–µ! –í–∞–∂–Ω–æ–µ —É—Ç–æ—á–Ω–µ–Ω–∏–µ.</p>
        </div>
        <div style="background: #f0fdf4; border-left: 4px solid #16a34a; padding: 16px 20px; border-radius: 8px;">
            <p style="margin: 4px 0 0;"><strong>–£–¥–∞—á–∏!</strong> üöÄ</p>
        </div>
    </div>
</div>"""

SYSTEM_MESSAGE = (
    "–í—ã ‚Äî —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏—é –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã—Ö —Ä–∞—Å—Å—ã–ª–æ–∫ –ù–ò–£ –í–®–≠. "
    "–í–∞—à–∞ –∑–∞–¥–∞—á–∞ ‚Äî –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –≤—Ö–æ–¥–Ω–æ–π —Ç–µ–∫—Å—Ç –æ–±—ä—è–≤–ª–µ–Ω–∏—è –≤ HTML-–∫–∞—Ä—Ç–æ—á–∫—É, —Å—Ç—Ä–æ–≥–æ —Å–ª–µ–¥—É—è —Ñ–∏—Ä–º–µ–Ω–Ω–æ–º—É —Å—Ç–∏–ª—é. "
    "–í —à–∞–ø–∫–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –ª–æ–≥–æ—Ç–∏–ø –ø–æ —Å—Å—ã–ª–∫–µ: " + LOGO_URL + ". "
    "–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—É –∏ CSS-—Å—Ç–∏–ª–∏ –∏–∑ –ø—Ä–∏–≤–µ–¥—ë–Ω–Ω–æ–≥–æ –Ω–∏–∂–µ –ø—Ä–∏–º–µ—Ä–∞. "
    "–ù–µ –¥–æ–±–∞–≤–ª—è–π—Ç–µ –ø–æ—è—Å–Ω–µ–Ω–∏–π, –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ –∏–ª–∏ –ª–∏—à–Ω–∏—Ö —Ç–µ–≥–æ–≤. "
    "–í–µ—Ä–Ω–∏—Ç–µ –¢–û–õ–¨–ö–û –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π JSON –≤ —Ñ–æ—Ä–º–∞—Ç–µ: {\"type\": \"HTML\", \"content\": \"<div>...</div>\"}."
    "–ü—Ä–∏–º–µ—Ä –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ –≤—ã–≤–æ–¥–∞:"
    + json.dumps({"type": "HTML", "content": HTML_EXAMPLE}, ensure_ascii=False, indent=2)
)

# =============================================================================
# –§–£–ù–ö–¶–ò–ò –î–õ–Ø –ú–û–î–£–õ–Ø 1: –ü–ï–†–ï–ó–ê–ß–ï–¢ –û–¶–ï–ù–û–ö
# =============================================================================
# ... (–æ—Å—Ç–∞—ë—Ç—Å—è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)
def process_grade_recalculation(df: pd.DataFrame, use_dynamics: bool) -> pd.DataFrame:
    """
    –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø–µ—Ä–µ–∑–∞—á–µ—Ç–∞ –æ—Ü–µ–Ω–æ–∫
    Args:
        df: DataFrame —Å –¥–∞–Ω–Ω—ã–º–∏ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤
        use_dynamics: –£—á–∏—Ç—ã–≤–∞—Ç—å –ª–∏ –¥–∏–Ω–∞–º–∏–∫—É –æ—Ü–µ–Ω–æ–∫
    Returns:
        –û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π DataFrame —Å –∫–æ–ª–æ–Ω–∫–∞–º–∏ –î–ü–†_–∏—Ç–æ–≥ –∏ –ù–≠_–∏—Ç–æ–≥
    """
    processed_df = df.copy()
    required_columns = [
        '–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –ù–≠', '–û—Ü–µ–Ω–∫–∞ –ù–≠', '–û—Ü–µ–Ω–∫–∞ –¥–∏—Å—Ü–∏–ø–ª–∏–Ω—ã-–ø—Ä–µ—Ä–µ–∫–≤–∏–∑–∏—Ç–∞',
        '–í–Ω–µ—à–Ω–µ–µ –∏–∑–º–µ—Ä–µ–Ω–∏–µ —Ü–∏—Ñ—Ä–æ–≤—ã—Ö –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–π. –í—Ö–æ–¥–Ω–æ–π –∫–æ–Ω—Ç—Ä–æ–ª—å',
        '–í–Ω–µ—à–Ω–µ–µ –∏–∑–º–µ—Ä–µ–Ω–∏–µ —Ü–∏—Ñ—Ä–æ–≤—ã—Ö –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–π. –ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–π –∫–æ–Ω—Ç—Ä–æ–ª—å',
        '–í–Ω–µ—à–Ω–µ–µ –∏–∑–º–µ—Ä–µ–Ω–∏–µ —Ü–∏—Ñ—Ä–æ–≤—ã—Ö –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–π. –ò—Ç–æ–≥–æ–≤—ã–π –∫–æ–Ω—Ç—Ä–æ–ª—å'
    ]
    for col in required_columns:
        if col not in processed_df.columns:
            raise KeyError(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–π —Å—Ç–æ–ª–±–µ—Ü: '{col}'")
    processed_df['–û—Ü–µ–Ω–∫–∞ –¥–∏—Å—Ü–∏–ø–ª–∏–Ω—ã-–ø—Ä–µ—Ä–µ–∫–≤–∏–∑–∏—Ç–∞'] = processed_df['–û—Ü–µ–Ω–∫–∞ –¥–∏—Å—Ü–∏–ø–ª–∏–Ω—ã-–ø—Ä–µ—Ä–µ–∫–≤–∏–∑–∏—Ç–∞'].apply(
        lambda x: 8 if x >= 9 else x
    )
    processed_df['–≠—Ç–∞–ø'] = 1
    processed_df.loc[processed_df['–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –ù–≠'].str.contains('–∞–Ω–∞–ª–∏–∑—É –¥–∞–Ω–Ω—ã—Ö', case=False, na=False), '–≠—Ç–∞–ø'] = 3
    processed_df.loc[processed_df['–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –ù–≠'].str.contains('–ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—é', case=False, na=False), '–≠—Ç–∞–ø'] = 2
    dpr_results = []
    ie_results = []
    for index, row in processed_df.iterrows():
        if row['–≠—Ç–∞–ø'] == 1:
            innopolis_grade = row['–í–Ω–µ—à–Ω–µ–µ –∏–∑–º–µ—Ä–µ–Ω–∏–µ —Ü–∏—Ñ—Ä–æ–≤—ã—Ö –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–π. –í—Ö–æ–¥–Ω–æ–π –∫–æ–Ω—Ç—Ä–æ–ª—å']
        elif row['–≠—Ç–∞–ø'] == 2:
            innopolis_grade = row['–í–Ω–µ—à–Ω–µ–µ –∏–∑–º–µ—Ä–µ–Ω–∏–µ —Ü–∏—Ñ—Ä–æ–≤—ã—Ö –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–π. –ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–π –∫–æ–Ω—Ç—Ä–æ–ª—å']
        else:
            innopolis_grade = row['–í–Ω–µ—à–Ω–µ–µ –∏–∑–º–µ—Ä–µ–Ω–∏–µ —Ü–∏—Ñ—Ä–æ–≤—ã—Ö –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–π. –ò—Ç–æ–≥–æ–≤—ã–π –∫–æ–Ω—Ç—Ä–æ–ª—å']
        if use_dynamics:
            vhod = row['–í–Ω–µ—à–Ω–µ–µ –∏–∑–º–µ—Ä–µ–Ω–∏–µ —Ü–∏—Ñ—Ä–æ–≤—ã—Ö –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–π. –í—Ö–æ–¥–Ω–æ–π –∫–æ–Ω—Ç—Ä–æ–ª—å']
            prom = row['–í–Ω–µ—à–Ω–µ–µ –∏–∑–º–µ—Ä–µ–Ω–∏–µ —Ü–∏—Ñ—Ä–æ–≤—ã—Ö –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–π. –ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–π –∫–æ–Ω—Ç—Ä–æ–ª—å']
            itog = row['–í–Ω–µ—à–Ω–µ–µ –∏–∑–º–µ—Ä–µ–Ω–∏–µ —Ü–∏—Ñ—Ä–æ–≤—ã—Ö –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–π. –ò—Ç–æ–≥–æ–≤—ã–π –∫–æ–Ω—Ç—Ä–æ–ª—å']
            if (vhod - prom > 1) or (vhod - itog > 1) or (prom - itog > 1):
                dpr_results.append(np.nan)
                ie_results.append(np.nan)
                continue
        ne_grade = row['–û—Ü–µ–Ω–∫–∞ –ù–≠']
        dpr_grade = row['–û—Ü–µ–Ω–∫–∞ –¥–∏—Å—Ü–∏–ø–ª–∏–Ω—ã-–ø—Ä–µ—Ä–µ–∫–≤–∏–∑–∏—Ç–∞']
        ne_grade = 0 if pd.isna(ne_grade) else ne_grade
        dpr_grade = 0 if pd.isna(dpr_grade) else dpr_grade
        innopolis_grade = 0 if pd.isna(innopolis_grade) else innopolis_grade
        max_grade = max(ne_grade, dpr_grade, innopolis_grade)
        # –†–∞—Å—á–µ—Ç –î–ü–†_–∏—Ç–æ–≥
        dpr_final = np.nan
        if ne_grade < 4:
            dpr_final = np.nan
        elif max_grade == innopolis_grade and innopolis_grade > 3 and innopolis_grade != dpr_grade and innopolis_grade != ne_grade:
            dpr_final = innopolis_grade
        elif ne_grade == dpr_grade:
            dpr_final = np.nan
        elif dpr_grade < 4:
            dpr_final = ne_grade if ne_grade >= 4 else np.nan
        elif max_grade == dpr_grade and dpr_grade >= 4:
            dpr_final = np.nan
        else:
            dpr_final = ne_grade
        dpr_results.append(dpr_final)
        # –†–∞—Å—á–µ—Ç –ù–≠_–∏—Ç–æ–≥
        ie_final = np.nan
        if ne_grade < 4:
            ie_final = np.nan
        elif max_grade == innopolis_grade and innopolis_grade > 3 and innopolis_grade != dpr_grade and innopolis_grade != ne_grade:
            ie_final = innopolis_grade
        elif ne_grade == dpr_grade:
            ie_final = np.nan
        elif max_grade == dpr_grade and dpr_grade >= 4:
            if ne_grade >= 8:
                ie_final = np.nan
            elif dpr_grade >= 8:
                ie_final = 8
            else:
                ie_final = dpr_grade
        elif ne_grade < 4 and innopolis_grade > 3 and use_dynamics:
             ie_final = innopolis_grade
        else:
            ie_final = np.nan
        ie_results.append(ie_final)
    processed_df['–î–ü–†_–∏—Ç–æ–≥'] = dpr_results
    processed_df['–ù–≠_–∏—Ç–æ–≥'] = ie_results
    return processed_df

# =============================================================================
# –§–£–ù–ö–¶–ò–ò –î–õ–Ø –ú–û–î–£–õ–Ø 2: –ì–ï–ù–ï–†–ê–¢–û–† HTML-–ö–ê–†–¢–û–ß–ï–ö
# =============================================================================
@st.cache_resource
def get_nebius_client():
    """–ü–æ–ª—É—á–∏—Ç—å –∫–ª–∏–µ–Ω—Ç Nebius API"""
    if "NEBIUS_API_KEY" not in st.secrets:
        raise ValueError("NEBIUS_API_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ secrets.")
    return OpenAI(
        base_url="https://api.studio.nebius.com/v1/",
        api_key=st.secrets["NEBIUS_API_KEY"]
    )

def generate_hse_html(client: OpenAI, user_text: str) -> str:
    """
    –ì–µ–Ω–µ—Ä–∞—Ü–∏—è HTML-–∫–∞—Ä—Ç–æ—á–∫–∏ —á–µ—Ä–µ–∑ Nebius API
    Args:
        client: OpenAI –∫–ª–∏–µ–Ω—Ç
        user_text: –¢–µ–∫—Å—Ç –æ–±—ä—è–≤–ª–µ–Ω–∏—è
    Returns:
        HTML-–∫–æ–¥ –∫–∞—Ä—Ç–æ—á–∫–∏
    """
    response = client.chat.completions.create(
        model="Qwen/Qwen3-Coder-30B-A3B-Instruct",
        response_format={"type": "json_object"},
        messages=[
            {"role": "system", "content": SYSTEM_MESSAGE},
            {"role": "user", "content": user_text}
        ],
        timeout=60.0
    )
    raw_content = response.choices[0].message.content.strip()
    try:
        parsed = json.loads(raw_content)
    except json.JSONDecodeError:
        raise ValueError(f"–ú–æ–¥–µ–ª—å –≤–µ—Ä–Ω—É–ª–∞ –Ω–µ-JSON. –û—Ç–≤–µ—Ç:\n{raw_content[:500]}")
    if not isinstance(parsed, dict):
        raise ValueError("–û—Ç–≤–µ—Ç –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –æ–±—ä–µ–∫—Ç–æ–º JSON.")
    if parsed.get("type") != "HTML":
        raise ValueError("–ü–æ–ª–µ 'type' –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å 'HTML'.")
    content = parsed.get("content")
    if not isinstance(content, str) or not content.strip():
        raise ValueError("–ü–æ–ª–µ 'content' –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∏–ª–∏ –ø—É—Å—Ç–æ–µ.")
    return content.strip()

# =============================================================================
# –§–£–ù–ö–¶–ò–ò –î–õ–Ø –ú–û–î–£–õ–Ø 3: –û–ë–†–ê–ë–û–¢–ö–ê –°–ï–†–¢–ò–§–ò–ö–ê–¢–û–í
# =============================================================================
def deduplicate_lines(text):
    """–£–¥–∞–ª—è–µ—Ç –¥—É–±–ª–∏—Ä—É—é—â–∏–µ—Å—è —Å—Ç—Ä–æ–∫–∏ –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
    if pd.isna(text) or not isinstance(text, str):
        return text
    lines = text.split('\n')
    seen_lines = set()
    unique_lines = []
    for line in lines:
        line_clean = line.strip()
        if line_clean and line_clean not in seen_lines:
            seen_lines.add(line_clean)
            unique_lines.append(line)
    return '\n'.join(unique_lines)

@st.cache_data
def load_reference_data(skills_content: bytes) -> Dict[str, str]:
    """–ó–∞–≥—Ä—É–∑–∫–∞ —Å–ø—Ä–∞–≤–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∏–∑ —Ñ–∞–π–ª–∞ –Ω–∞–≤—ã–∫–æ–≤"""
    with tempfile.NamedTemporaryFile(delete=False, suffix='.xlsx') as tmp_file:
        tmp_file.write(skills_content)
        tmp_file_path = tmp_file.name
    try:
        skills_df = pd.read_excel(tmp_file_path)
        grade_mapping = {}
        for _, row in skills_df.iterrows():
            discipline = row['–î–∏—Å—Ü–∏–ø–ª–∏–Ω–∞']
            level = row['–£—Ä–æ–≤–µ–Ω—å_–æ—Ü–µ–Ω–∫–∏']
            description = row['–û–ø–∏—Å–∞–Ω–∏–µ_–Ω–∞–≤—ã–∫–æ–≤']
            clean_description = deduplicate_lines(description)
            composite_key = f"{discipline}‚Äî{level}"
            grade_mapping[composite_key] = clean_description
        return grade_mapping
    finally:
        os.unlink(tmp_file_path)

# =============================================================================
# –§–£–ù–ö–¶–ò–ò –î–õ–Ø –ú–û–î–£–õ–Ø 4: –û–ë–†–ê–ë–û–¢–ö–ê –ü–ï–†–ï–°–î–ê–ß –í–ù–ï–®–ù–ï–ô –û–¶–ï–ù–ö–ò
# =============================================================================
@st.cache_resource
def get_supabase_client() -> Client:
    """–ü–æ–ª—É—á–∏—Ç—å –∫–ª–∏–µ–Ω—Ç Supabase"""
    if "url" not in st.secrets or "key" not in st.secrets:
        raise ValueError("Supabase URL –∏ KEY –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ secrets.toml")
    return create_client(st.secrets["url"], st.secrets["key"])

def get_unique_courses_from_supabase() -> List[str]:
    """–ü–æ–ª—É—á–∏—Ç—å —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –∏–∑ –∫–æ–ª–æ–Ω–∫–∏ '–∫—É—Ä—Å' –≤ —Ç–∞–±–ª–∏—Ü–µ students"""
    try:
        supabase = get_supabase_client()
        response = supabase.table('students').select('–∫—É—Ä—Å').execute()
        if response.data:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏—è, —Ñ–∏–ª—å—Ç—Ä—É–µ–º None/–ø—É—Å—Ç—ã–µ –∏ –¥–µ–ª–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–º–∏
            courses = {row['–∫—É—Ä—Å'] for row in response.data if row.get('–∫—É—Ä—Å')}
            return sorted(courses)
        else:
            return []
    except Exception as e:
        st.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å–ø–∏—Å–æ–∫ –∫—É—Ä—Å–æ–≤: {str(e)}")
        return []

def load_students_from_supabase(selected_courses: List[str] = None) -> pd.DataFrame:
    """
    –ó–∞–≥—Ä—É–∑–∫–∞ —Å–ø–∏—Å–∫–∞ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ –∏–∑ Supabase —Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π –ø–æ –≤—ã–±—Ä–∞–Ω–Ω—ã–º –∫—É—Ä—Å–∞–º.
    –ï—Å–ª–∏ selected_courses –ø—É—Å—Ç–æ–π –∏–ª–∏ None ‚Äî –∑–∞–≥—Ä—É–∂–∞—é—Ç—Å—è –≤—Å–µ —Å—Ç—É–¥–µ–Ω—Ç—ã.
    """
    try:
        supabase = get_supabase_client()
        all_data = []
        page_size = 1000
        offset = 0

        while True:
            query = supabase.table('students').select('*')
            if selected_courses:
                query = query.in_('–∫—É—Ä—Å', selected_courses)
            response = query.range(offset, offset + page_size - 1).execute()

            if response.data:
                all_data.extend(response.data)
                if len(response.data) < page_size:
                    break
                offset += page_size
            else:
                break

        if all_data:
            df = pd.DataFrame(all_data)
            column_mapping = {
                '–∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∞—è_–ø–æ—á—Ç–∞': '–ê–¥—Ä–µ—Å —ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω–æ–π –ø–æ—á—Ç—ã',
                '—Ñ–∏–æ': '–§–ò–û',
                '—Ñ–∏–ª–∏–∞–ª_–∫–∞–º–ø—É—Å': '–§–∏–ª–∏–∞–ª (–∫–∞–º–ø—É—Å)',
                '—Ñ–∞–∫—É–ª—å—Ç–µ—Ç': '–§–∞–∫—É–ª—å—Ç–µ—Ç',
                '–æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è_–ø—Ä–æ–≥—Ä–∞–º–º–∞': '–û–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≥—Ä–∞–º–º–∞',
                '–≥—Ä—É–ø–ø–∞': '–ì—Ä—É–ø–ø–∞',
                '–∫—É—Ä—Å': '–ö—É—Ä—Å'
            }
            existing_columns = {k: v for k, v in column_mapping.items() if k in df.columns}
            df = df.rename(columns=existing_columns)
            return df
        else:
            st.warning("‚ö†Ô∏è –¢–∞–±–ª–∏—Ü–∞ students –ø—É—Å—Ç–∞ –∏–ª–∏ –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –∑–∞–ø–∏—Å–µ–π –ø–æ –≤—ã–±—Ä–∞–Ω–Ω—ã–º –∫—É—Ä—Å–∞–º")
            return pd.DataFrame()
    except Exception as e:
        st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ –∏–∑ Supabase: {str(e)}")
        return pd.DataFrame()

def create_peresdachi_table_if_not_exists():
    """–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ: –¢–∞–±–ª–∏—Ü–∞ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å —Å–æ–∑–¥–∞–Ω–∞ –≤—Ä—É—á–Ω—É—é –≤ Supabase Dashboard"""
    pass

def load_existing_peresdachi() -> pd.DataFrame:
    """–ó–∞–≥—Ä—É–∑–∫–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –∑–∞–ø–∏—Å–µ–π –∏–∑ —Ç–∞–±–ª–∏—Ü—ã peresdachi (–≤—Å–µ –∑–∞–ø–∏—Å–∏ —Å –ø–∞–≥–∏–Ω–∞—Ü–∏–µ–π)"""
    try:
        supabase = get_supabase_client()
        all_data = []
        page_size = 1000
        offset = 0
        while True:
            response = supabase.table('peresdachi').select('*').range(offset, offset + page_size - 1).execute()
            if response.data:
                all_data.extend(response.data)
                if len(response.data) < page_size:
                    break
                offset += page_size
            else:
                break
        if all_data:
            return pd.DataFrame(all_data)
        else:
            return pd.DataFrame()
    except Exception as e:
        st.warning(f"‚ö†Ô∏è –¢–∞–±–ª–∏—Ü–∞ peresdachi –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –∏–ª–∏ –ø—É—Å—Ç–∞: {str(e)}")
        return pd.DataFrame()

def save_to_supabase(df: pd.DataFrame) -> Tuple[int, int]:
    """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –≤ —Ç–∞–±–ª–∏—Ü—É peresdachi –≤ Supabase"""
    try:
        supabase = get_supabase_client()
        existing_df = load_existing_peresdachi()
        if existing_df.empty:
            new_records = df.to_dict('records')
            new_count = len(new_records)
        else:
            merge_cols = ['–ê–¥—Ä–µ—Å —ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω–æ–π –ø–æ—á—Ç—ã', '–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –¥–∏—Å—Ü–∏–ø–ª–∏–Ω—ã']
            if all(col in existing_df.columns for col in merge_cols) and all(col in df.columns for col in merge_cols):
                merged = df.merge(
                    existing_df[merge_cols],
                    on=merge_cols,
                    how='left',
                    indicator=True
                )
                new_df = merged[merged['_merge'] == 'left_only'].drop('_merge', axis=1)
                new_records = new_df.to_dict('records')
                new_count = len(new_records)
            else:
                new_records = df.to_dict('records')
                new_count = len(new_records)
        if new_records:
            cleaned_records = []
            for record in new_records:
                cleaned_record = {k: (v if pd.notna(v) else None) for k, v in record.items()}
                cleaned_records.append(cleaned_record)
            supabase.table('peresdachi').insert(cleaned_records).execute()
        return new_count, len(df)
    except Exception as e:
        st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –≤ Supabase: {str(e)}")
        raise e

def get_new_records(all_df: pd.DataFrame) -> pd.DataFrame:
    """–ü–æ–ª—É—á–∏—Ç—å —Ç–æ–ª—å–∫–æ –Ω–æ–≤—ã–µ –∑–∞–ø–∏—Å–∏, –∫–æ—Ç–æ—Ä—ã—Ö –µ—â–µ –Ω–µ—Ç –≤ –±–∞–∑–µ"""
    try:
        existing_df = load_existing_peresdachi()
        if existing_df.empty:
            return all_df
        merge_cols = ['–ê–¥—Ä–µ—Å —ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω–æ–π –ø–æ—á—Ç—ã', '–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –¥–∏—Å—Ü–∏–ø–ª–∏–Ω—ã']
        if all(col in existing_df.columns for col in merge_cols) and all(col in all_df.columns for col in merge_cols):
            merged = all_df.merge(
                existing_df[merge_cols],
                on=merge_cols,
                how='left',
                indicator=True
            )
            new_df = merged[merged['_merge'] == 'left_only'].drop('_merge', axis=1)
            return new_df
        else:
            return all_df
    except Exception as e:
        st.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–∏ –Ω–æ–≤—ã—Ö –∑–∞–ø–∏—Å–µ–π: {str(e)}")
        return all_df

def process_external_assessment(grades_df: pd.DataFrame, students_df: pd.DataFrame) -> pd.DataFrame:
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–µ—Ä–µ—Å–¥–∞—á –≤–Ω–µ—à–Ω–µ–π –æ—Ü–µ–Ω–∫–∏"""
    for col in grades_df.columns:
        if grades_df[col].dtype == 'object':
            grades_df[col] = grades_df[col].astype(str).str.replace('-', '', regex=False).str.strip()
    column_mapping = {
        '–¢–µ—Å—Ç:–í—Ö–æ–¥–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ (–ó–Ω–∞—á–µ–Ω–∏–µ)': '–í–Ω–µ—à–Ω–µ–µ –∏–∑–º–µ—Ä–µ–Ω–∏–µ —Ü–∏—Ñ—Ä–æ–≤—ã—Ö –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–π. –í—Ö–æ–¥–Ω–æ–π –∫–æ–Ω—Ç—Ä–æ–ª—å',
        '–¢–µ—Å—Ç:–ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ (–ó–Ω–∞—á–µ–Ω–∏–µ)': '–í–Ω–µ—à–Ω–µ–µ –∏–∑–º–µ—Ä–µ–Ω–∏–µ —Ü–∏—Ñ—Ä–æ–≤—ã—Ö –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–π. –ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–π –∫–æ–Ω—Ç—Ä–æ–ª—å',
        '–¢–µ—Å—Ç:–ò—Ç–æ–≥–æ–≤–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ (–ó–Ω–∞—á–µ–Ω–∏–µ)': '–í–Ω–µ—à–Ω–µ–µ –∏–∑–º–µ—Ä–µ–Ω–∏–µ —Ü–∏—Ñ—Ä–æ–≤—ã—Ö –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–π. –ò—Ç–æ–≥–æ–≤—ã–π –∫–æ–Ω—Ç—Ä–æ–ª—å'
    }
    grades_df = grades_df.rename(columns=column_mapping)
    value_columns = [
        '–í–Ω–µ—à–Ω–µ–µ –∏–∑–º–µ—Ä–µ–Ω–∏–µ —Ü–∏—Ñ—Ä–æ–≤—ã—Ö –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–π. –í—Ö–æ–¥–Ω–æ–π –∫–æ–Ω—Ç—Ä–æ–ª—å',
        '–í–Ω–µ—à–Ω–µ–µ –∏–∑–º–µ—Ä–µ–Ω–∏–µ —Ü–∏—Ñ—Ä–æ–≤—ã—Ö –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–π. –ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–π –∫–æ–Ω—Ç—Ä–æ–ª—å',
        '–í–Ω–µ—à–Ω–µ–µ –∏–∑–º–µ—Ä–µ–Ω–∏–µ —Ü–∏—Ñ—Ä–æ–≤—ã—Ö –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–π. –ò—Ç–æ–≥–æ–≤—ã–π –∫–æ–Ω—Ç—Ä–æ–ª—å'
    ]
    id_cols = ['–ê–¥—Ä–µ—Å —ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω–æ–π –ø–æ—á—Ç—ã']
    if '–ê–¥—Ä–µ—Å —ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω–æ–π –ø–æ—á—Ç—ã' not in grades_df.columns:
        st.error("–ö–æ–ª–æ–Ω–∫–∞ '–ê–¥—Ä–µ—Å —ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω–æ–π –ø–æ—á—Ç—ã' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ —Ñ–∞–π–ª–µ –æ—Ü–µ–Ω–æ–∫")
        return pd.DataFrame()
    melted_df = pd.melt(
        grades_df,
        id_vars=id_cols,
        value_vars=value_columns,
        var_name='–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –¥–∏—Å—Ü–∏–ø–ª–∏–Ω—ã',
        value_name='–û—Ü–µ–Ω–∫–∞'
    )
    students_cols = ['–§–ò–û', '–ê–¥—Ä–µ—Å —ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω–æ–π –ø–æ—á—Ç—ã', '–§–∏–ª–∏–∞–ª (–∫–∞–º–ø—É—Å)', 
                     '–§–∞–∫—É–ª—å—Ç–µ—Ç', '–û–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≥—Ä–∞–º–º–∞', '–ì—Ä—É–ø–ø–∞', '–ö—É—Ä—Å']
    missing_cols = [col for col in students_cols if col not in students_df.columns]
    if missing_cols:
        st.warning(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –∫–æ–ª–æ–Ω–∫–∏ –≤ —Ñ–∞–π–ª–µ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤: {missing_cols}")
        available_cols = [col for col in students_cols if col in students_df.columns]
    else:
        available_cols = students_cols
    students_subset = students_df[available_cols].copy()
    melted_df['–ê–¥—Ä–µ—Å —ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω–æ–π –ø–æ—á—Ç—ã'] = melted_df['–ê–¥—Ä–µ—Å —ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω–æ–π –ø–æ—á—Ç—ã'].astype(str).str.strip().str.lower()
    students_subset['–ê–¥—Ä–µ—Å —ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω–æ–π –ø–æ—á—Ç—ã'] = students_subset['–ê–¥—Ä–µ—Å —ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω–æ–π –ø–æ—á—Ç—ã'].astype(str).str.strip().str.lower()
    result_df = melted_df.merge(
        students_subset,
        on='–ê–¥—Ä–µ—Å —ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω–æ–π –ø–æ—á—Ç—ã',
        how='left'
    )
    result_df['ID –¥–∏—Å—Ü–∏–ø–ª–∏–Ω—ã'] = ''
    result_df['–ü–µ—Ä–∏–æ–¥ –∞—Ç—Ç–µ—Å—Ç–∞—Ü–∏–∏'] = ''
    if '–§–∏–ª–∏–∞–ª (–∫–∞–º–ø—É—Å)' in result_df.columns:
        result_df = result_df.rename(columns={'–§–∏–ª–∏–∞–ª (–∫–∞–º–ø—É—Å)': '–ö–∞–º–ø—É—Å'})
    output_columns = [
        '–§–ò–û', '–ê–¥—Ä–µ—Å —ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω–æ–π –ø–æ—á—Ç—ã', '–ö–∞–º–ø—É—Å', '–§–∞–∫—É–ª—å—Ç–µ—Ç',
        '–û–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≥—Ä–∞–º–º–∞', '–ì—Ä—É–ø–ø–∞', '–ö—É—Ä—Å', 'ID –¥–∏—Å—Ü–∏–ø–ª–∏–Ω—ã',
        '–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –¥–∏—Å—Ü–∏–ø–ª–∏–Ω—ã', '–ü–µ—Ä–∏–æ–¥ –∞—Ç—Ç–µ—Å—Ç–∞—Ü–∏–∏', '–û—Ü–µ–Ω–∫–∞'
    ]
    final_columns = [col for col in output_columns if col in result_df.columns]
    result_df = result_df[final_columns]
    result_df = result_df[result_df['–û—Ü–µ–Ω–∫–∞'].notna()]
    result_df = result_df[result_df['–û—Ü–µ–Ω–∫–∞'].astype(str).str.strip() != '']
    result_df = result_df[result_df['–û—Ü–µ–Ω–∫–∞'].astype(str).str.strip() != 'nan']
    return result_df

# =============================================================================
# –û–°–ù–û–í–ù–û–ï –ü–†–ò–õ–û–ñ–ï–ù–ò–ï
# =============================================================================
def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è"""
    st.title("‚ù§Ô∏èüå∏ DataCulture Platform üå∏‚ù§Ô∏è")
    st.markdown("**–û–±—ä–µ–¥–∏–Ω—ë–Ω–Ω–∞—è –ø–ª–∞—Ç—Ñ–æ—Ä–º–∞ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ Data Culture @ HSE University**")
    st.markdown("*–î–ª—è —Å–∞–º—ã—Ö –ª—É—á—à–∏—Ö —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤ –ø—Ä–æ–µ–∫—Ç–∞ –æ—Ç –¢–∏–º–æ—à–∫–∏!*")
    st.markdown("---")
    with st.sidebar:
        st.image(LOGO_URL, width=200)
        st.markdown("---")
        tool = st.radio(
            "üéØ –í—ã–±–µ—Ä–∏—Ç–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç:",
            [
                "üìä –ü–µ—Ä–µ–∑–∞—á–µ—Ç –æ—Ü–µ–Ω–æ–∫",
                "üéì –ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä HTML-–∫–∞—Ä—Ç–æ—á–µ–∫",
                "üìú –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç–æ–≤",
                "üìù –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–µ—Ä–µ—Å–¥–∞—á –≤–Ω–µ—à–Ω–µ–π –æ—Ü–µ–Ω–∫–∏"
            ],
            index=0
        )
        st.markdown("---")
        st.markdown("### ‚ÑπÔ∏è –û –ø–ª–∞—Ç—Ñ–æ—Ä–º–µ")
        st.info("""
        **DataCulture Platform** –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç —á–µ—Ç—ã—Ä–µ –∫–ª—é—á–µ–≤—ã—Ö –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞:
        1. **–ü–µ—Ä–µ–∑–∞—á–µ—Ç –æ—Ü–µ–Ω–æ–∫** - –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π —Ä–∞—Å—á–µ—Ç –∏—Ç–æ–≥–æ–≤—ã—Ö –æ—Ü–µ–Ω–æ–∫
        2. **–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –∫–∞—Ä—Ç–æ—á–µ–∫** - —Å–æ–∑–¥–∞–Ω–∏–µ HTML-—Ä–∞—Å—Å—ã–ª–æ–∫ –≤ —Ñ–∏—Ä–º–µ–Ω–Ω–æ–º —Å—Ç–∏–ª–µ –í–®–≠
        3. **–°–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç—ã** - –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≤—ã–¥–∞—á–∏ —Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç–æ–≤
        4. **–ü–µ—Ä–µ—Å–¥–∞—á–∏** - –æ–±—Ä–∞–±–æ—Ç–∫–∞ –ø–µ—Ä–µ—Å–¥–∞—á –≤–Ω–µ—à–Ω–µ–π –æ—Ü–µ–Ω–∫–∏
        """)

    # =============================================================================
    # –ú–û–î–£–õ–¨ 1‚Äì3: –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π
    # =============================================================================
    if tool == "üìä –ü–µ—Ä–µ–∑–∞—á–µ—Ç –æ—Ü–µ–Ω–æ–∫":
        # ... (–æ—Å—Ç–∞—ë—Ç—Å—è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)
        st.header("üìä –°–µ—Ä–≤–∏—Å –ø–µ—Ä–µ–∑–∞—á–µ—Ç–∞ –æ—Ü–µ–Ω–æ–∫")
        st.markdown("""
        –ó–∞–≥—Ä—É–∑–∏—Ç–µ Excel –∏–ª–∏ CSV —Ñ–∞–π–ª —Å –¥–∞–Ω–Ω—ã–º–∏ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ —Ä–∞—Å—á–µ—Ç–∞ –∏—Ç–æ–≥–æ–≤—ã—Ö –æ—Ü–µ–Ω–æ–∫.
        **–¢—Ä–µ–±—É–µ–º—ã–µ –∫–æ–ª–æ–Ω–∫–∏:**
        - –ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –ù–≠
        - –û—Ü–µ–Ω–∫–∞ –ù–≠
        - –û—Ü–µ–Ω–∫–∞ –¥–∏—Å—Ü–∏–ø–ª–∏–Ω—ã-–ø—Ä–µ—Ä–µ–∫–≤–∏–∑–∏—Ç–∞
        - –í–Ω–µ—à–Ω–µ–µ –∏–∑–º–µ—Ä–µ–Ω–∏–µ —Ü–∏—Ñ—Ä–æ–≤—ã—Ö –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–π (–í—Ö–æ–¥–Ω–æ–π, –ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–π, –ò—Ç–æ–≥–æ–≤—ã–π –∫–æ–Ω—Ç—Ä–æ–ª—å)
        """)
        uploaded_file = st.file_uploader(
            "–í—ã–±–µ—Ä–∏—Ç–µ —Ñ–∞–π–ª –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏",
            type=['xlsx', 'csv'],
            key="grade_file"
        )
        if uploaded_file is not None:
            file_name = uploaded_file.name
            processing_mode = st.radio(
                "–†–µ–∂–∏–º –æ–±—Ä–∞–±–æ—Ç–∫–∏:",
                ("–ü–µ—Ä–µ–∑–∞—á–µ—Ç –ë–ï–ó –¥–∏–Ω–∞–º–∏–∫–∏", "–ü–µ—Ä–µ–∑–∞—á–µ—Ç –° –¥–∏–Ω–∞–º–∏–∫–æ–π"),
                help="""
                - **–ë–ï–ó –¥–∏–Ω–∞–º–∏–∫–∏**: –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –ø–µ—Ä–µ–∑–∞—á–µ—Ç –ø–æ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –æ—Ü–µ–Ω–∫–µ.
                - **–° –¥–∏–Ω–∞–º–∏–∫–æ–π**: –ï—Å–ª–∏ –æ—Ü–µ–Ω–∫–∞ –ø–∞–¥–∞–µ—Ç –±–æ–ª–µ–µ —á–µ–º –Ω–∞ 1 –±–∞–ª–ª –º–µ–∂–¥—É —ç—Ç–∞–ø–∞–º–∏, –ø–µ—Ä–µ–∑–∞—á–µ—Ç –±–ª–æ–∫–∏—Ä—É–µ—Ç—Å—è.
                """
            )
            if st.button("üöÄ –û–±—Ä–∞–±–æ—Ç–∞—Ç—å —Ñ–∞–π–ª", type="primary"):
                with st.spinner("–û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö..."):
                    try:
                        if file_name.endswith('.xlsx'):
                            df_initial = pd.read_excel(uploaded_file, engine='openpyxl')
                        else:
                            df_initial = pd.read_csv(uploaded_file)
                        use_dynamics_flag = (processing_mode == "–ü–µ—Ä–µ–∑–∞—á–µ—Ç –° –¥–∏–Ω–∞–º–∏–∫–æ–π")
                        result_df = process_grade_recalculation(df_initial, use_dynamics=use_dynamics_flag)
                        st.success("‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
                        st.subheader("üìä –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–π –ø—Ä–æ—Å–º–æ—Ç—Ä")
                        st.dataframe(result_df.head(10), use_container_width=True)
                        output = io.BytesIO()
                        with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
                            result_df.to_excel(writer, index=False, sheet_name='–†–µ–∑—É–ª—å—Ç–∞—Ç')
                        excel_data = output.getvalue()
                        current_date = datetime.now().strftime('%d-%m-%y')
                        download_filename = f"–†–µ–∑—É–ª—å—Ç–∞—Ç_{file_name.split('.')[0]}_{current_date}.xlsx"
                        st.download_button(
                            label="üì• –°–∫–∞—á–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç",
                            data=excel_data,
                            file_name=download_filename,
                            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                        )
                    except KeyError as e:
                        st.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä–µ —Ñ–∞–π–ª–∞: {e}")
                    except Exception as e:
                        st.error(f"‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {e}")

    elif tool == "üéì –ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä HTML-–∫–∞—Ä—Ç–æ—á–µ–∫":
        # ... (–æ—Å—Ç–∞—ë—Ç—Å—è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)
        st.header("üéì –ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –∫–∞—Ä—Ç–æ—á–µ–∫ –ù–ò–£ –í–®–≠")
        st.markdown("""
        –°–æ–∑–¥–∞–π—Ç–µ HTML-–∫–∞—Ä—Ç–æ—á–∫—É —Ä–∞—Å—Å—ã–ª–∫–∏ –≤ —Ñ–∏—Ä–º–µ–Ω–Ω–æ–º —Å—Ç–∏–ª–µ –í–®–≠ —Å –ø–æ–º–æ—â—å—é –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞.
        **–ö–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:**
        1. –í–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç –æ–±—ä—è–≤–ª–µ–Ω–∏—è –∏–ª–∏ –Ω–æ–≤–æ—Å—Ç–∏
        2. –ù–∞–∂–º–∏—Ç–µ –∫–Ω–æ–ø–∫—É –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
        3. –ü–æ–ª—É—á–∏—Ç–µ –≥–æ—Ç–æ–≤—ã–π HTML-–∫–æ–¥ –∏ –ø—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä
        """)
        try:
            has_api_key = "NEBIUS_API_KEY" in st.secrets
        except FileNotFoundError:
            has_api_key = False
        if not has_api_key:
            st.error("‚ùå NEBIUS_API_KEY –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω. –û–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä—É.")
            st.info("üí° –°–æ–∑–¥–∞–π—Ç–µ —Ñ–∞–π–ª `.streamlit/secrets.toml` —Å –≤–∞—à–∏–º API –∫–ª—é—á–æ–º")
            st.stop()
        user_text = st.text_area(
            "–í–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç –æ–±—ä—è–≤–ª–µ–Ω–∏—è:",
            height=250,
            placeholder="–í—Å—Ç–∞–≤—å—Ç–µ —Å—é–¥–∞ —Ç–µ–∫—Å—Ç –ø–∏—Å—å–º–∞ –∏–ª–∏ –Ω–æ–≤–æ—Å—Ç–∏..."
        )
        if st.button("‚ú® –°—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å HTML", type="primary"):
            if not user_text.strip():
                st.warning("‚ö†Ô∏è –í–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏")
            else:
                with st.spinner("–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–∞—Ä—Ç–æ—á–∫–∏..."):
                    try:
                        client = get_nebius_client()
                        html_code = generate_hse_html(client, user_text)
                        st.success("‚úÖ –ö–∞—Ä—Ç–æ—á–∫–∞ —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω–∞!")
                        col1, col2 = st.columns([1, 1])
                        with col1:
                            st.subheader("üìÑ HTML-–∫–æ–¥")
                            st.code(html_code, language="html")
                            st.download_button(
                                label="üíæ –°–∫–∞—á–∞—Ç—å HTML",
                                data=html_code.encode("utf-8"),
                                file_name="hse_card.html",
                                mime="text/html"
                            )
                        with col2:
                            st.subheader("üåê –ü—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä")
                            import streamlit.components.v1 as components
                            components.html(html_code, height=800, scrolling=True)
                    except Exception as e:
                        st.error(f"‚ùå –û—à–∏–±–∫–∞: {e}")

    elif tool == "üìú –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç–æ–≤":
        # ... (–æ—Å—Ç–∞—ë—Ç—Å—è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)
        st.header("üìú –°–∏—Å—Ç–µ–º–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç–æ–≤")
        st.markdown("""
        –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö —ç–∫–∑–∞–º–µ–Ω–æ–≤ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ –¥–ª—è —Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç–æ–≤.
        **–¢—Ä–µ–±—É–µ—Ç—Å—è –¥–≤–∞ —Ñ–∞–π–ª–∞:**
        1. Excel —Å –¥–∞–Ω–Ω—ã–º–∏ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ (–∫–æ–ª–æ–Ω–∫–∏: –£—á–∞—â–∏–π—Å—è, –î–∏—Å—Ü–∏–ø–ª–∏–Ω–∞ 1/2/3, –û—Ü–µ–Ω–∫–∞ 5 –±–∞–ª–ª–æ–≤)
        2. Excel —Å–æ —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–æ–º –Ω–∞–≤—ã–∫–æ–≤ (–∫–æ–ª–æ–Ω–∫–∏: –î–∏—Å—Ü–∏–ø–ª–∏–Ω–∞, –£—Ä–æ–≤–µ–Ω—å_–æ—Ü–µ–Ω–∫–∏, –û–ø–∏—Å–∞–Ω–∏–µ_–Ω–∞–≤—ã–∫–æ–≤)
        """)
        with st.sidebar:
            st.markdown("---")
            st.markdown("### üì• –°–∫–∞—á–∞—Ç—å –ø—Ä–∏–º–µ—Ä—ã")
            current_dir = os.path.dirname(os.path.abspath(__file__))
            excel_example_path = os.path.join(current_dir, '–°–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç—ã –ø—Ä–∏–º–µ—Ä.xlsx')
            if os.path.exists(excel_example_path):
                with open(excel_example_path, 'rb') as example_file:
                    excel_example_data = example_file.read()
                st.download_button(
                    label="üìä –ü—Ä–∏–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö —Å—Ç—É–¥–µ–Ω—Ç–æ–≤",
                    data=excel_example_data,
                    file_name="–°–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç—ã_–ø—Ä–∏–º–µ—Ä.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    help="–°–∫–∞—á–∞–π—Ç–µ —ç—Ç–æ—Ç —Ñ–∞–π–ª –∫–∞–∫ —à–∞–±–ª–æ–Ω –¥–ª—è –≤–∞—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö —Å—Ç—É–¥–µ–Ω—Ç–æ–≤",
                    use_container_width=True
                )
            skills_example_path = os.path.join(current_dir, '–∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ_–Ω–∞–≤—ã–∫–∏.xlsx')
            if os.path.exists(skills_example_path):
                with open(skills_example_path, 'rb') as skills_file:
                    skills_data = skills_file.read()
                st.download_button(
                    label="üìÑ –°–ø—Ä–∞–≤–æ—á–Ω–∏–∫ –Ω–∞–≤—ã–∫–æ–≤",
                    data=skills_data,
                    file_name="–∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ_–Ω–∞–≤—ã–∫–∏.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    help="–°–∫–∞—á–∞–π—Ç–µ —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫ —Å –æ–ø–∏—Å–∞–Ω–∏—è–º–∏ –Ω–∞–≤—ã–∫–æ–≤",
                    use_container_width=True
                )
            st.markdown("---")
            st.markdown("### üìã –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ —Ñ–∞–π–ª–∞–º")
            st.markdown("""
            **üìä –î–∞–Ω–Ω—ã–µ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤:**
            - `–£—á–∞—â–∏–π—Å—è`
            - `–ù–∞–∑–≤–∞–Ω–∏–µ –î–∏—Å—Ü–∏–ø–ª–∏–Ω—ã 1/2/3`
            - `–î–∏—Å—Ü–∏–ø–ª–∏–Ω–∞ 1/2/3`
            - `–û—Ü–µ–Ω–∫–∞ 5 –±–∞–ª–ª–æ–≤ –î–∏—Å—Ü–∏–ø–ª–∏–Ω–∞ 1/2/3`
            **üìÑ –°–ø—Ä–∞–≤–æ—á–Ω–∏–∫ –Ω–∞–≤—ã–∫–æ–≤:**
            - `–î–∏—Å—Ü–∏–ø–ª–∏–Ω–∞`
            - `–£—Ä–æ–≤–µ–Ω—å_–æ—Ü–µ–Ω–∫–∏`
            - `–û–ø–∏—Å–∞–Ω–∏–µ_–Ω–∞–≤—ã–∫–æ–≤`
            üí° **–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –ø—Ä–∏–º–µ—Ä—ã –≤—ã—à–µ!**
            """)
        col1, col2 = st.columns([1, 1])
        with col1:
            st.subheader("üìä –î–∞–Ω–Ω—ã–µ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤")
            excel_file = st.file_uploader(
                "–í—ã–±–µ—Ä–∏—Ç–µ Excel —Ñ–∞–π–ª",
                type=['xlsx', 'xls'],
                key="students_file"
            )
        with col2:
            st.subheader("üìÑ –°–ø—Ä–∞–≤–æ—á–Ω–∏–∫ –Ω–∞–≤—ã–∫–æ–≤")
            skills_file = st.file_uploader(
                "–í—ã–±–µ—Ä–∏—Ç–µ Excel —Ñ–∞–π–ª",
                type=['xlsx', 'xls'],
                key="skills_file"
            )
        if excel_file and skills_file:
            try:
                with st.spinner("üì• –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–æ–≤..."):
                    df = pd.read_excel(excel_file)
                    skills_content = skills_file.read()
                    grade_mapping = load_reference_data(skills_content)
                st.success("‚úÖ –§–∞–π–ª—ã —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã!")
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("–°—Ç—É–¥–µ–Ω—Ç–æ–≤", len(df))
                with col2:
                    st.metric("–ö–æ–ª–æ–Ω–æ–∫", len(df.columns))
                with col3:
                    st.metric("–ù–∞–≤—ã–∫–æ–≤ –≤ —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–µ", len(grade_mapping))
                with st.expander("üëÄ –ü—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä –¥–∞–Ω–Ω—ã—Ö"):
                    st.dataframe(df.head(), use_container_width=True)
                if st.button("üöÄ –û–±—Ä–∞–±–æ—Ç–∞—Ç—å –¥–∞–Ω–Ω—ã–µ", type="primary"):
                    with st.spinner("‚öôÔ∏è –û–±—Ä–∞–±–æ—Ç–∫–∞..."):
                        result_df, processing_log = process_student_data(df, grade_mapping)
                    st.success("‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
                    st.subheader("üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã")
                    st.dataframe(result_df, use_container_width=True)
                    output = io.BytesIO()
                    with pd.ExcelWriter(output, engine='openpyxl', mode='w') as writer:
                        result_df.to_excel(writer, index=False)
                    output.seek(0)
                    st.download_button(
                        label="üì• –°–∫–∞—á–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã",
                        data=output.getvalue(),
                        file_name="–°–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç—ã_—Å_—Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏.xlsx",
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                    )
            except Exception as e:
                st.error(f"‚ùå –û—à–∏–±–∫–∞: {str(e)}")
        elif excel_file:
            st.info("üìÑ –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ç–∞–∫–∂–µ —Ñ–∞–π–ª —Å–æ —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–æ–º –Ω–∞–≤—ã–∫–æ–≤")
        elif skills_file:
            st.info("üìä –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ç–∞–∫–∂–µ —Ñ–∞–π–ª —Å –¥–∞–Ω–Ω—ã–º–∏ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤")
        else:
            st.info("üìÅ –ó–∞–≥—Ä—É–∑–∏—Ç–µ –æ–±–∞ —Ñ–∞–π–ª–∞ –¥–ª—è –Ω–∞—á–∞–ª–∞ —Ä–∞–±–æ—Ç—ã")

    # =============================================================================
    # –ú–û–î–£–õ–¨ 4: –û–ë–†–ê–ë–û–¢–ö–ê –ü–ï–†–ï–°–î–ê–ß –í–ù–ï–®–ù–ï–ô –û–¶–ï–ù–ö–ò ‚Äî –û–ë–ù–û–í–õ–Å–ù–ù–´–ô
    # =============================================================================
    else:  # –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–µ—Ä–µ—Å–¥–∞—á –≤–Ω–µ—à–Ω–µ–π –æ—Ü–µ–Ω–∫–∏
        st.header("üìù –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–µ—Ä–µ—Å–¥–∞—á –≤–Ω–µ—à–Ω–µ–π –æ—Ü–µ–Ω–∫–∏")
        st.markdown("""
        –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –ø–µ—Ä–µ—Å–¥–∞—á –∏–∑ –≤–Ω–µ—à–Ω–µ–π —Å–∏—Å—Ç–µ–º—ã –æ—Ü–µ–Ω–∏–≤–∞–Ω–∏—è —Å –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–µ–π Supabase.
        **–¢—Ä–µ–±—É–µ—Ç—Å—è:**
        1. **–§–∞–π–ª —Å –æ—Ü–µ–Ω–∫–∞–º–∏** - —Ç–∞–±–ª–∏—Ü–∞ –∏–∑ –≤–Ω–µ—à–Ω–µ–π —Å–∏—Å—Ç–µ–º—ã —Å —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è–º–∏
        2. **–°–ø–∏—Å–æ–∫ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤** - –∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏–∑ Supabase (—Ç–∞–±–ª–∏—Ü–∞ `students`)
        **–ß—Ç–æ –¥–µ–ª–∞–µ—Ç –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç:**
        - –û—á–∏—â–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –æ—Ç –ª–∏—à–Ω–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤ –∏ –ø—Ä–æ–±–µ–ª–æ–≤
        - –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞–µ—Ç –∫–æ–ª–æ–Ω–∫–∏ –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–∏ —Å–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞–º–∏
        - –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ —à–∏—Ä–æ–∫–æ–≥–æ –≤ –¥–ª–∏–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç (melt)
        - –û–±—ä–µ–¥–∏–Ω—è–µ—Ç –¥–∞–Ω–Ω—ã–µ —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ —Å—Ç—É–¥–µ–Ω—Ç–∞—Ö –∏–∑ Supabase
        - –°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ —Ç–∞–±–ª–∏—Ü—É `peresdachi` –≤ Supabase
        - –ü–æ–∑–≤–æ–ª—è–µ—Ç —Å–∫–∞—á–∞—Ç—å –≤—Å–µ –¥–∞–Ω–Ω—ã–µ –∏–ª–∏ —Ç–æ–ª—å–∫–æ –Ω–æ–≤—ã–µ –∑–∞–ø–∏—Å–∏
        """)

        try:
            supabase = get_supabase_client()
            st.success("‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Supabase —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ")
        except Exception as e:
            st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Supabase: {str(e)}")
            st.stop()

        st.markdown("---")

        # –ó–∞–≥—Ä—É–∑–∫–∞ —Å–ø–∏—Å–∫–∞ –∫—É—Ä—Å–æ–≤
        with st.spinner("üì• –ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –∫—É—Ä—Å–æ–≤ –∏–∑ Supabase..."):
            all_courses = get_unique_courses_from_supabase()

        if not all_courses:
            st.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –∫—É—Ä—Å–æ–≤. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ç–∞–±–ª–∏—Ü—É students –≤ Supabase.")
            st.stop()

        # –í—ã–±–æ—Ä –∫—É—Ä—Å–æ–≤
        st.subheader("üéì –í—ã–±–µ—Ä–∏—Ç–µ –∫—É—Ä—Å—ã –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
        selected_courses = st.multiselect(
            "–ö—É—Ä—Å",
            options=all_courses,
            default=all_courses,
            placeholder="–í—ã–±–µ—Ä–∏—Ç–µ –æ–¥–∏–Ω –∏–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ –∫—É—Ä—Å–æ–≤"
        )

        if not selected_courses:
            st.info("‚ÑπÔ∏è –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤—ã–±–µ—Ä–∏—Ç–µ —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω –∫—É—Ä—Å –¥–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è.")
            st.stop()

        # –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞ —Å –æ—Ü–µ–Ω–∫–∞–º–∏
        st.subheader("üìä –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞ —Å –æ—Ü–µ–Ω–∫–∞–º–∏")
        grades_file = st.file_uploader(
            "–í—ã–±–µ—Ä–∏—Ç–µ —Ñ–∞–π–ª —Å –æ—Ü–µ–Ω–∫–∞–º–∏ (external_assessment)",
            type=['xlsx', 'xls'],
            key="external_grades_file",
            help="–§–∞–π–ª –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å –∫–æ–ª–æ–Ω–∫–∏: –ê–¥—Ä–µ—Å —ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω–æ–π –ø–æ—á—Ç—ã, –¢–µ—Å—Ç:–í—Ö–æ–¥–Ω–æ–µ/–ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω–æ–µ/–ò—Ç–æ–≥–æ–≤–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ (–ó–Ω–∞—á–µ–Ω–∏–µ)"
        )

        if grades_file:
            try:
                with st.spinner("üì• –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞ —Å –æ—Ü–µ–Ω–∫–∞–º–∏..."):
                    grades_df = pd.read_excel(grades_file)
                st.success("‚úÖ –§–∞–π–ª —Å –æ—Ü–µ–Ω–∫–∞–º–∏ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω!")

                # –ó–∞–≥—Ä—É–∑–∫–∞ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ –ø–æ –≤—ã–±—Ä–∞–Ω–Ω—ã–º –∫—É—Ä—Å–∞–º
                with st.spinner(f"üì• –ó–∞–≥—Ä—É–∑–∫–∞ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ –ø–æ {len(selected_courses)} –∫—É—Ä—Å–∞–º –∏–∑ Supabase..."):
                    students_df = load_students_from_supabase(selected_courses=selected_courses)

                if students_df.empty:
                    st.error("‚ùå –°–ø–∏—Å–æ–∫ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ –ø—É—Å—Ç. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –¥–∞–Ω–Ω—ã–µ –≤ —Ç–∞–±–ª–∏—Ü–µ `students` –≤ Supabase.")
                    st.stop()
                else:
                    st.success(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(students_df)} —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ –∏–∑ Supabase")

                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("–ó–∞–ø–∏—Å–µ–π —Å –æ—Ü–µ–Ω–∫–∞–º–∏", len(grades_df))
                with col2:
                    st.metric("–°—Ç—É–¥–µ–Ω—Ç–æ–≤ –≤ –±–∞–∑–µ", len(students_df))
                with col3:
                    st.metric("–ö–æ–ª–æ–Ω–æ–∫ –≤ –æ—Ü–µ–Ω–∫–∞—Ö", len(grades_df.columns))

                col_preview1, col_preview2 = st.columns(2)
                with col_preview1:
                    with st.expander("üëÄ –ü—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä —Ñ–∞–π–ª–∞ —Å –æ—Ü–µ–Ω–∫–∞–º–∏"):
                        st.dataframe(grades_df.head(), use_container_width=True)
                with col_preview2:
                    with st.expander("üëÄ –ü—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä —Å–ø–∏—Å–∫–∞ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤"):
                        st.dataframe(students_df.head(10), use_container_width=True)

                if st.button("üöÄ –û–±—Ä–∞–±–æ—Ç–∞—Ç—å –¥–∞–Ω–Ω—ã–µ", type="primary", key="process_btn"):
                    with st.spinner("‚öôÔ∏è –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–µ—Ä–µ—Å–¥–∞—á..."):
                        try:
                            result_df = process_external_assessment(grades_df, students_df)
                            if result_df.empty:
                                st.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –¥–∞–Ω–Ω—ã–µ. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Ñ–∞–π–ª–∞.")
                            else:
                                st.success("‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")

                                with st.spinner("üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ Supabase..."):
                                    try:
                                        new_count, total_count = save_to_supabase(result_df)
                                        st.success(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ Supabase: {new_count} –Ω–æ–≤—ã—Ö –∑–∞–ø–∏—Å–µ–π –∏–∑ {total_count}")
                                    except Exception as e:
                                        st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏: {str(e)}")

                                st.subheader("üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—Ä–∞–±–æ—Ç–∫–∏")
                                col1, col2, col3 = st.columns(3)
                                with col1:
                                    st.metric("–í—Å–µ–≥–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∑–∞–ø–∏—Å–µ–π", total_count)
                                with col2:
                                    st.metric("–ù–æ–≤—ã—Ö –∑–∞–ø–∏—Å–µ–π", new_count)
                                with col3:
                                    existing_count = total_count - new_count
                                    st.metric("–£–∂–µ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–ª–æ", existing_count)

                                new_records_df = get_new_records(result_df)

                                tab1, tab2 = st.tabs(["üìã –í—Å–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ", "üÜï –¢–æ–ª—å–∫–æ –Ω–æ–≤—ã–µ –∑–∞–ø–∏—Å–∏"])
                                with tab1:
                                    st.dataframe(result_df, use_container_width=True)
                                    output_all = io.BytesIO()
                                    with pd.ExcelWriter(output_all, engine='openpyxl') as writer:
                                        result_df.to_excel(writer, index=False, sheet_name='–í—Å–µ –ø–µ—Ä–µ—Å–¥–∞—á–∏')
                                    output_all.seek(0)
                                    current_date = datetime.now().strftime('%d-%m-%Y')
                                    download_filename_all = f"–ü–µ—Ä–µ—Å–¥–∞—á–∏_–≤—Å–µ_{current_date}.xlsx"
                                    st.download_button(
                                        label="üì• –°–∫–∞—á–∞—Ç—å –≤—Å–µ –∑–∞–ø–∏—Å–∏ (XLSX)",
                                        data=output_all.getvalue(),
                                        file_name=download_filename_all,
                                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                                        key="download_all"
                                    )
                                with tab2:
                                    if new_records_df.empty:
                                        st.info("‚ÑπÔ∏è –ù–æ–≤—ã—Ö –∑–∞–ø–∏—Å–µ–π –Ω–µ—Ç. –í—Å–µ –¥–∞–Ω–Ω—ã–µ —É–∂–µ –±—ã–ª–∏ –≤ –±–∞–∑–µ.")
                                    else:
                                        st.dataframe(new_records_df, use_container_width=True)
                                        output_new = io.BytesIO()
                                        with pd.ExcelWriter(output_new, engine='openpyxl') as writer:
                                            new_records_df.to_excel(writer, index=False, sheet_name='–ù–æ–≤—ã–µ –ø–µ—Ä–µ—Å–¥–∞—á–∏')
                                        output_new.seek(0)
                                        download_filename_new = f"–ü–µ—Ä–µ—Å–¥–∞—á–∏_–Ω–æ–≤—ã–µ_{current_date}.xlsx"
                                        st.download_button(
                                            label="üì• –°–∫–∞—á–∞—Ç—å —Ç–æ–ª—å–∫–æ –Ω–æ–≤—ã–µ –∑–∞–ø–∏—Å–∏ (XLSX)",
                                            data=output_new.getvalue(),
                                            file_name=download_filename_new,
                                            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                                            key="download_new"
                                        )

                                with st.expander("üìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –æ–±—Ä–∞–±–æ—Ç–∫–µ"):
                                    col1, col2 = st.columns(2)
                                    with col1:
                                        st.write("**–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –¥–∏—Å—Ü–∏–ø–ª–∏–Ω–∞–º:**")
                                        if '–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –¥–∏—Å—Ü–∏–ø–ª–∏–Ω—ã' in result_df.columns:
                                            discipline_counts = result_df['–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –¥–∏—Å—Ü–∏–ø–ª–∏–Ω—ã'].value_counts()
                                            st.dataframe(discipline_counts)
                                    with col2:
                                        st.write("**–£–Ω–∏–∫–∞–ª—å–Ω—ã–µ —Å—Ç—É–¥–µ–Ω—Ç—ã:**")
                                        if '–§–ò–û' in result_df.columns:
                                            unique_students = result_df['–§–ò–û'].nunique()
                                            st.metric("–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å—Ç—É–¥–µ–Ω—Ç–æ–≤", unique_students)
                        except Exception as e:
                            st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ: {str(e)}")
                            st.exception(e)
            except Exception as e:
                st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Ñ–∞–π–ª–∞: {str(e)}")
                st.exception(e)
        else:
            st.info("üìÅ –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª —Å –æ—Ü–µ–Ω–∫–∞–º–∏ –¥–ª—è –Ω–∞—á–∞–ª–∞ —Ä–∞–±–æ—Ç—ã")
            st.markdown("---")
            st.markdown("### üí° –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –ø–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é")
            st.markdown("""
            **–ü–µ—Ä–µ–¥ –Ω–∞—á–∞–ª–æ–º —Ä–∞–±–æ—Ç—ã:**
            1. **–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –≤ Supabase —Å–æ–∑–¥–∞–Ω—ã —Ç–∞–±–ª–∏—Ü—ã:**
               - `students` - —Å–æ —Å–ø–∏—Å–∫–æ–º —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ (–∫–æ–ª–æ–Ω–∫–∏: –§–ò–û, –ê–¥—Ä–µ—Å —ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω–æ–π –ø–æ—á—Ç—ã, –§–∏–ª–∏–∞–ª (–∫–∞–º–ø—É—Å), –§–∞–∫—É–ª—å—Ç–µ—Ç, –û–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≥—Ä–∞–º–º–∞, –ì—Ä—É–ø–ø–∞, –ö—É—Ä—Å)
               - `peresdachi` - –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –ø–µ—Ä–µ—Å–¥–∞—á
            **–ü—Ä–æ—Ü–µ—Å—Å –æ–±—Ä–∞–±–æ—Ç–∫–∏:**
            1. –í—ã–±–µ—Ä–∏—Ç–µ –Ω—É–∂–Ω—ã–µ **–∫—É—Ä—Å—ã** –∏–∑ —Å–ø–∏—Å–∫–∞
            2. –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª —Å –æ—Ü–µ–Ω–∫–∞–º–∏
            3. –ù–∞–∂–º–∏—Ç–µ **"–û–±—Ä–∞–±–æ—Ç–∞—Ç—å –¥–∞–Ω–Ω—ã–µ"**
            ‚ú® –í—Å–µ –¥–∞–Ω–Ω—ã–µ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –≤ Supabase!
            """)
            existing_peresdachi = load_existing_peresdachi()
            with st.expander("üìä –¢–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"):
                if existing_peresdachi.empty:
                    st.info("‚ÑπÔ∏è –¢–∞–±–ª–∏—Ü–∞ peresdachi –ø—É—Å—Ç–∞ –∏–ª–∏ –Ω–µ —Å–æ–∑–¥–∞–Ω–∞")
                else:
                    st.metric("–ó–∞–ø–∏—Å–µ–π –≤ —Ç–∞–±–ª–∏—Ü–µ peresdachi", len(existing_peresdachi))
                    st.dataframe(existing_peresdachi.head(10), use_container_width=True)

    st.markdown("---")
    st.markdown(
        """
        <div style='text-align: center; color: #666;'>
            <p>DataCulture Platform v1.0 | Created with ‚ù§Ô∏è by –¢–∏–º–æ—à–∫–∞ | Powered by Streamlit üöÄ</p>
        </div>
        """, 
        unsafe_allow_html=True
    )

# =============================================================================
# –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –§–£–ù–ö–¶–ò–ò –î–õ–Ø –ú–û–î–£–õ–Ø 3 (–Ω–µ –∑–∞–±—ã–≤–∞–µ–º!)
# =============================================================================
def process_student_data(df: pd.DataFrame, grade_mapping: Dict[str, str]) -> Tuple[pd.DataFrame, list]:
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ –¥–ª—è —Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç–æ–≤"""
    results = []
    processing_log = []
    processing_log.append(f"üìä –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º {len(df)} —Å—Ç—É–¥–µ–Ω—Ç–æ–≤")
    for index, row in df.iterrows():
        student_results = []
        processed_keys = set()
        for discipline_num in range(1, 4):
            discipline_col = f"–î–∏—Å—Ü–∏–ø–ª–∏–Ω–∞ {discipline_num}"
            grade_5_col = f"–û—Ü–µ–Ω–∫–∞ 5 –±–∞–ª–ª–æ–≤ –î–∏—Å—Ü–∏–ø–ª–∏–Ω–∞ {discipline_num}"
            if discipline_col not in df.columns or grade_5_col not in df.columns:
                continue
            discipline_value = str(row[discipline_col]).strip()
            grade_value = str(row[grade_5_col]).strip()
            if pd.isna(discipline_value) or pd.isna(grade_value) or discipline_value == 'nan' or grade_value == 'nan':
                continue
            lookup_key = f"{discipline_value}‚Äî{grade_value}"
            if lookup_key in processed_keys:
                continue
            if lookup_key in grade_mapping:
                skill_description = grade_mapping[lookup_key]
                short_name_col = f"–ù–∞–∑–≤–∞–Ω–∏–µ –î–∏—Å—Ü–∏–ø–ª–∏–Ω—ã {discipline_num}"
                if short_name_col in df.columns:
                    display_name = str(row[short_name_col]).strip()
                    formatted_discipline = display_name.capitalize() if display_name != 'nan' and display_name else discipline_value
                else:
                    formatted_discipline = discipline_value
                formatted_result = f"üìö {formatted_discipline}:\n{skill_description}"
                student_results.append(formatted_result)
                processed_keys.add(lookup_key)
        final_result = "\n".join(student_results) if student_results else "–ù–∞–≤—ã–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã."
        results.append(final_result)
    processing_log.append(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ")
    df_result = df.copy()
    df_result['–ò—Ç–æ–≥–æ–≤—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç'] = results
    columns_to_remove = [col for col in df_result.columns if col.startswith("–ù–∞–∑–≤–∞–Ω–∏–µ –î–∏—Å—Ü–∏–ø–ª–∏–Ω—ã ")]
    if columns_to_remove:
        df_result = df_result.drop(columns=columns_to_remove)
    return df_result, processing_log

# =============================================================================
if __name__ == "__main__":
    main()
