"""
DataCulture Unified Platform
–û–±—ä–µ–¥–∏–Ω—ë–Ω–Ω–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –¥–ª—è –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ Data Culture @ HSE University
–ê–≤—Ç–æ—Ä: –¢–∏–º–æ—à–∫–∞
"""
import streamlit as st
import pandas as pd
import numpy as np
from datetime import datetime
import io
import json
from openai import OpenAI
import tempfile
import os
from typing import Dict, Tuple
from supabase import create_client, Client
# –ò—Å–ø—Ä–∞–≤–ª–µ–Ω –∏–º–ø–æ—Ä—Ç: st.navigation –∑–∞–º–µ–Ω–µ–Ω –Ω–∞ navigation
from streamlit.navigation import navigation

# =============================================================================
# –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø –ü–†–ò–õ–û–ñ–ï–ù–ò–Ø
# =============================================================================
st.set_page_config(
    page_title="DataCulture Platform",
    page_icon="üìä",
    layout="wide",
    initial_sidebar_state="expanded"
)

# =============================================================================
# –ö–û–ù–°–¢–ê–ù–¢–´
# =============================================================================
LOGO_URL = "https://raw.githubusercontent.com/TimPad/html/main/DC_green.svg"
HTML_EXAMPLE = f"""<div style="font-family: 'Inter', 'Segoe UI', Roboto, Arial, sans-serif; max-width: 860px; margin: 40px auto; background: #ffffff; border-radius: 16px; box-shadow: 0 4px 14px rgba(0,0,0,0.08); border: 1px solid #e5ebf8; overflow: hidden;">
    <div style="background: #00256c; color: white; padding: 28px 32px; text-align: center;">
        <img src="{LOGO_URL}" alt="–õ–æ–≥–æ—Ç–∏–ø Data Culture" style="height: 48px; margin-bottom: 16px;">
        <p><span style="font-size: 1.6em; font-weight: 700;">–ó–ê–ì–û–õ–û–í–û–ö –û–ë–™–Ø–í–õ–ï–ù–ò–Ø</span></p>
        <p style="margin-top: 8px; line-height: 1.5;">–ö—Ä–∞—Ç–∫–æ–µ –≤–≤–µ–¥–µ–Ω–∏–µ –∏–ª–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç.</p>
    </div>
    <div style="padding: 28px 32px; color: #111827; line-height: 1.65;">
        <p>–û—Å–Ω–æ–≤–Ω–æ–π —Ç–µ–∫—Å—Ç –æ–±—ä—è–≤–ª–µ–Ω–∏—è...</p>
        <h3 style="color: #00256c;">–ü–æ–¥–∑–∞–≥–æ–ª–æ–≤–æ–∫</h3>
        <ul style="margin: 12px 0 22px 22px;">
            <li>–ü—É–Ω–∫—Ç —Å–ø–∏—Å–∫–∞</li>
        </ul>
        <div style="background: #f4f6fb; border-radius: 10px; padding: 16px 20px; margin: 16px 0;">
            <p>–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω—ã–π –±–ª–æ–∫</p>
        </div>
        <div style="background: #fff8e1; border-left: 4px solid #f59e0b; padding: 14px 18px; border-radius: 8px; margin-bottom: 20px;">
            <p style="margin: 0; font-weight: 600; color: #92400e;">‚ö†Ô∏è –í–Ω–∏–º–∞–Ω–∏–µ! –í–∞–∂–Ω–æ–µ —É—Ç–æ—á–Ω–µ–Ω–∏–µ.</p>
        </div>
        <div style="background: #f0fdf4; border-left: 4px solid #16a34a; padding: 16px 20px; border-radius: 8px;">
            <p style="margin: 4px 0 0;"><strong>–£–¥–∞—á–∏!</strong> üöÄ</p>
        </div>
    </div>
</div>"""

SYSTEM_MESSAGE = (
    "–í—ã ‚Äî —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏—é –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã—Ö —Ä–∞—Å—Å—ã–ª–æ–∫ –ù–ò–£ –í–®–≠. "
    "–í–∞—à–∞ –∑–∞–¥–∞—á–∞ ‚Äî –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –≤—Ö–æ–¥–Ω–æ–π —Ç–µ–∫—Å—Ç –æ–±—ä—è–≤–ª–µ–Ω–∏—è –≤ HTML-–∫–∞—Ä—Ç–æ—á–∫—É, —Å—Ç—Ä–æ–≥–æ —Å–ª–µ–¥—É—è —Ñ–∏—Ä–º–µ–Ω–Ω–æ–º—É —Å—Ç–∏–ª—é. "
    "–í —à–∞–ø–∫–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –ª–æ–≥–æ—Ç–∏–ø –ø–æ —Å—Å—ã–ª–∫–µ: " + LOGO_URL + ". "
    "–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—É –∏ CSS-—Å—Ç–∏–ª–∏ –∏–∑ –ø—Ä–∏–≤–µ–¥—ë–Ω–Ω–æ–≥–æ –Ω–∏–∂–µ –ø—Ä–∏–º–µ—Ä–∞. "
    "–ù–µ –¥–æ–±–∞–≤–ª—è–π—Ç–µ –ø–æ—è—Å–Ω–µ–Ω–∏–π, –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ –∏–ª–∏ –ª–∏—à–Ω–∏—Ö —Ç–µ–≥–æ–≤. "
    "–í–µ—Ä–Ω–∏—Ç–µ –¢–û–õ–¨–ö–û –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π JSON –≤ —Ñ–æ—Ä–º–∞—Ç–µ: {\"type\": \"HTML\", \"content\": \"<div>...</div>\"}.
"
    "–ü—Ä–∏–º–µ—Ä –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ –≤—ã–≤–æ–¥–∞:
"
    + json.dumps({"type": "HTML", "content": HTML_EXAMPLE}, ensure_ascii=False, indent=2)
)

# =============================================================================
# –§–£–ù–ö–¶–ò–ò –î–õ–Ø –ú–û–î–£–õ–Ø 1: –ü–ï–†–ï–ó–ê–ß–ï–¢ –û–¶–ï–ù–û–ö
# =============================================================================
def process_grade_recalculation(df: pd.DataFrame, use_dynamics: bool) -> pd.DataFrame:
    """
    –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø–µ—Ä–µ–∑–∞—á–µ—Ç–∞ –æ—Ü–µ–Ω–æ–∫
    Args:
        df: DataFrame —Å –¥–∞–Ω–Ω—ã–º–∏ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤
        use_dynamics: –£—á–∏—Ç—ã–≤–∞—Ç—å –ª–∏ –¥–∏–Ω–∞–º–∏–∫—É –æ—Ü–µ–Ω–æ–∫
    Returns:
        –û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π DataFrame —Å –∫–æ–ª–æ–Ω–∫–∞–º–∏ –î–ü–†_–∏—Ç–æ–≥ –∏ –ù–≠_–∏—Ç–æ–≥
    """
    processed_df = df.copy()
    required_columns = [
        '–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –ù–≠', '–û—Ü–µ–Ω–∫–∞ –ù–≠', '–û—Ü–µ–Ω–∫–∞ –¥–∏—Å—Ü–∏–ø–ª–∏–Ω—ã-–ø—Ä–µ—Ä–µ–∫–≤–∏–∑–∏—Ç–∞',
        '–í–Ω–µ—à–Ω–µ–µ –∏–∑–º–µ—Ä–µ–Ω–∏–µ —Ü–∏—Ñ—Ä–æ–≤—ã—Ö –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–π. –í—Ö–æ–¥–Ω–æ–π –∫–æ–Ω—Ç—Ä–æ–ª—å',
        '–í–Ω–µ—à–Ω–µ–µ –∏–∑–º–µ—Ä–µ–Ω–∏–µ —Ü–∏—Ñ—Ä–æ–≤—ã—Ö –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–π. –ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–π –∫–æ–Ω—Ç—Ä–æ–ª—å',
        '–í–Ω–µ—à–Ω–µ–µ –∏–∑–º–µ—Ä–µ–Ω–∏–µ —Ü–∏—Ñ—Ä–æ–≤—ã—Ö –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–π. –ò—Ç–æ–≥–æ–≤—ã–π –∫–æ–Ω—Ç—Ä–æ–ª—å'
    ]
    for col in required_columns:
        if col not in processed_df.columns:
            raise KeyError(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–π —Å—Ç–æ–ª–±–µ—Ü: '{col}'")

    processed_df['–û—Ü–µ–Ω–∫–∞ –¥–∏—Å—Ü–∏–ø–ª–∏–Ω—ã-–ø—Ä–µ—Ä–µ–∫–≤–∏–∑–∏—Ç–∞'] = processed_df['–û—Ü–µ–Ω–∫–∞ –¥–∏—Å—Ü–∏–ø–ª–∏–Ω—ã-–ø—Ä–µ—Ä–µ–∫–≤–∏–∑–∏—Ç–∞'].apply(
        lambda x: 8 if x >= 9 else x
    )
    processed_df['–≠—Ç–∞–ø'] = 1
    processed_df.loc[processed_df['–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –ù–≠'].str.contains('–∞–Ω–∞–ª–∏–∑—É –¥–∞–Ω–Ω—ã—Ö', case=False, na=False), '–≠—Ç–∞–ø'] = 3
    processed_df.loc[processed_df['–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –ù–≠'].str.contains('–ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—é', case=False, na=False), '–≠—Ç–∞–ø'] = 2

    dpr_results = []
    ie_results = []
    for index, row in processed_df.iterrows():
        if row['–≠—Ç–∞–ø'] == 1:
            innopolis_grade = row['–í–Ω–µ—à–Ω–µ–µ –∏–∑–º–µ—Ä–µ–Ω–∏–µ —Ü–∏—Ñ—Ä–æ–≤—ã—Ö –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–π. –í—Ö–æ–¥–Ω–æ–π –∫–æ–Ω—Ç—Ä–æ–ª—å']
        elif row['–≠—Ç–∞–ø'] == 2:
            innopolis_grade = row['–í–Ω–µ—à–Ω–µ–µ –∏–∑–º–µ—Ä–µ–Ω–∏–µ —Ü–∏—Ñ—Ä–æ–≤—ã—Ö –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–π. –ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–π –∫–æ–Ω—Ç—Ä–æ–ª—å']
        else:
            innopolis_grade = row['–í–Ω–µ—à–Ω–µ–µ –∏–∑–º–µ—Ä–µ–Ω–∏–µ —Ü–∏—Ñ—Ä–æ–≤—ã—Ö –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–π. –ò—Ç–æ–≥–æ–≤—ã–π –∫–æ–Ω—Ç—Ä–æ–ª—å']

        if use_dynamics:
            vhod = row['–í–Ω–µ—à–Ω–µ–µ –∏–∑–º–µ—Ä–µ–Ω–∏–µ —Ü–∏—Ñ—Ä–æ–≤—ã—Ö –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–π. –í—Ö–æ–¥–Ω–æ–π –∫–æ–Ω—Ç—Ä–æ–ª—å']
            prom = row['–í–Ω–µ—à–Ω–µ–µ –∏–∑–º–µ—Ä–µ–Ω–∏–µ —Ü–∏—Ñ—Ä–æ–≤—ã—Ö –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–π. –ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–π –∫–æ–Ω—Ç—Ä–æ–ª—å']
            itog = row['–í–Ω–µ—à–Ω–µ–µ –∏–∑–º–µ—Ä–µ–Ω–∏–µ —Ü–∏—Ñ—Ä–æ–≤—ã—Ö –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–π. –ò—Ç–æ–≥–æ–≤—ã–π –∫–æ–Ω—Ç—Ä–æ–ª—å']
            if (vhod - prom > 1) or (vhod - itog > 1) or (prom - itog > 1):
                dpr_results.append(np.nan)
                ie_results.append(np.nan)
                continue

        ne_grade = row['–û—Ü–µ–Ω–∫–∞ –ù–≠']
        dpr_grade = row['–û—Ü–µ–Ω–∫–∞ –¥–∏—Å—Ü–∏–ø–ª–∏–Ω—ã-–ø—Ä–µ—Ä–µ–∫–≤–∏–∑–∏—Ç–∞']
        ne_grade = 0 if pd.isna(ne_grade) else ne_grade
        dpr_grade = 0 if pd.isna(dpr_grade) else dpr_grade
        innopolis_grade = 0 if pd.isna(innopolis_grade) else innopolis_grade
        max_grade = max(ne_grade, dpr_grade, innopolis_grade)

        # –†–∞—Å—á–µ—Ç –î–ü–†_–∏—Ç–æ–≥
        dpr_final = np.nan
        if ne_grade < 4:
            dpr_final = np.nan
        elif max_grade == innopolis_grade and innopolis_grade > 3 and innopolis_grade != dpr_grade and innopolis_grade != ne_grade:
            dpr_final = innopolis_grade
        elif ne_grade == dpr_grade:
            dpr_final = np.nan
        elif dpr_grade < 4:
            dpr_final = ne_grade if ne_grade >= 4 else np.nan
        elif max_grade == dpr_grade and dpr_grade >= 4:
            dpr_final = np.nan
        else:
            dpr_final = ne_grade
        dpr_results.append(dpr_final)

        # –†–∞—Å—á–µ—Ç –ù–≠_–∏—Ç–æ–≥
        ie_final = np.nan
        if ne_grade < 4:
            ie_final = np.nan
        elif max_grade == innopolis_grade and innopolis_grade > 3 and innopolis_grade != dpr_grade and innopolis_grade != ne_grade:
            ie_final = innopolis_grade
        elif ne_grade == dpr_grade:
            ie_final = np.nan
        elif max_grade == dpr_grade and dpr_grade >= 4:
            if ne_grade >= 8:
                ie_final = np.nan
            elif dpr_grade >= 8:
                ie_final = 8
            else:
                ie_final = dpr_grade
        elif ne_grade < 4 and innopolis_grade > 3 and use_dynamics:
             ie_final = innopolis_grade
        else:
            ie_final = np.nan
        ie_results.append(ie_final)

    processed_df['–î–ü–†_–∏—Ç–æ–≥'] = dpr_results
    processed_df['–ù–≠_–∏—Ç–æ–≥'] = ie_results
    return processed_df

# =============================================================================
# –§–£–ù–ö–¶–ò–ò –î–õ–Ø –ú–û–î–£–õ–Ø 2: –ì–ï–ù–ï–†–ê–¢–û–† HTML-–ö–ê–†–¢–û–ß–ï–ö
# =============================================================================
@st.cache_resource
def get_nebius_client():
    """–ü–æ–ª—É—á–∏—Ç—å –∫–ª–∏–µ–Ω—Ç Nebius API"""
    if "NEBIUS_API_KEY" not in st.secrets:
        raise ValueError("NEBIUS_API_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ secrets.")
    return OpenAI(
        base_url="https://api.studio.nebius.com/v1/",
        api_key=st.secrets["NEBIUS_API_KEY"]
    )

def generate_hse_html(client: OpenAI, user_text: str) -> str:
    """
    –ì–µ–Ω–µ—Ä–∞—Ü–∏—è HTML-–∫–∞—Ä—Ç–æ—á–∫–∏ —á–µ—Ä–µ–∑ Nebius API
    Args:
        client: OpenAI –∫–ª–∏–µ–Ω—Ç
        user_text: –¢–µ–∫—Å—Ç –æ–±—ä—è–≤–ª–µ–Ω–∏—è
    Returns:
        HTML-–∫–æ–¥ –∫–∞—Ä—Ç–æ—á–∫–∏
    """
    response = client.chat.completions.create(
        model="Qwen/Qwen3-Coder-30B-A3B-Instruct",
        response_format={"type": "json_object"},
        messages=[
            {"role": "system", "content": SYSTEM_MESSAGE},
            {"role": "user", "content": user_text}
        ],
        timeout=60.0
    )
    raw_content = response.choices[0].message.content.strip()
    try:
        parsed = json.loads(raw_content)
    except json.JSONDecodeError:
        raise ValueError(f"–ú–æ–¥–µ–ª—å –≤–µ—Ä–Ω—É–ª–∞ –Ω–µ-JSON. –û—Ç–≤–µ—Ç:\n{raw_content[:500]}")

    if not isinstance(parsed, dict):
        raise ValueError("–û—Ç–≤–µ—Ç –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –æ–±—ä–µ–∫—Ç–æ–º JSON.")
    if parsed.get("type") != "HTML":
        raise ValueError("–ü–æ–ª–µ 'type' –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å 'HTML'.")
    content = parsed.get("content")
    if not isinstance(content, str) or not content.strip():
        raise ValueError("–ü–æ–ª–µ 'content' –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∏–ª–∏ –ø—É—Å—Ç–æ–µ.")

    return content.strip()

# =============================================================================
# –§–£–ù–ö–¶–ò–ò –î–õ–Ø –ú–û–î–£–õ–Ø 3: –û–ë–†–ê–ë–û–¢–ö–ê –°–ï–†–¢–ò–§–ò–ö–ê–¢–û–í
# =============================================================================
def deduplicate_lines(text):
    """–£–¥–∞–ª—è–µ—Ç –¥—É–±–ª–∏—Ä—É—é—â–∏–µ—Å—è —Å—Ç—Ä–æ–∫–∏ –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
    if pd.isna(text) or not isinstance(text, str):
        return text
    lines = text.split('\n')
    seen_lines = set()
    unique_lines = []
    for line in lines:
        line_clean = line.strip()
        if line_clean and line_clean not in seen_lines:
            seen_lines.add(line_clean)
            unique_lines.append(line)
    return '\n'.join(unique_lines)

@st.cache_data
def load_reference_data(skills_content: bytes) -> Dict[str, str]:
    """–ó–∞–≥—Ä—É–∑–∫–∞ —Å–ø—Ä–∞–≤–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∏–∑ —Ñ–∞–π–ª–∞ –Ω–∞–≤—ã–∫–æ–≤"""
    with tempfile.NamedTemporaryFile(delete=False, suffix='.xlsx') as tmp_file:
        tmp_file.write(skills_content)
        tmp_file_path = tmp_file.name

    try:
        skills_df = pd.read_excel(tmp_file_path)
        grade_mapping = {}
        for _, row in skills_df.iterrows():
            discipline = row['–î–∏—Å—Ü–∏–ø–ª–∏–Ω–∞']
            level = row['–£—Ä–æ–≤–µ–Ω—å_–æ—Ü–µ–Ω–∫–∏']
            description = row['–û–ø–∏—Å–∞–Ω–∏–µ_–Ω–∞–≤—ã–∫–æ–≤']
            clean_description = deduplicate_lines(description)
            composite_key = f"{discipline}‚Äî{level}"
            grade_mapping[composite_key] = clean_description
        return grade_mapping
    finally:
        os.unlink(tmp_file_path)

# =============================================================================
# –§–£–ù–ö–¶–ò–ò –î–õ–Ø –ú–û–î–£–õ–Ø 4: –û–ë–†–ê–ë–û–¢–ö–ê –ü–ï–†–ï–°–î–ê–ß –í–ù–ï–®–ù–ï–ô –û–¶–ï–ù–ö–ò
# =============================================================================
@st.cache_resource
def get_supabase_client() -> Client:
    """–ü–æ–ª—É—á–∏—Ç—å –∫–ª–∏–µ–Ω—Ç Supabase"""
    if "url" not in st.secrets or "key" not in st.secrets:
        raise ValueError("Supabase URL –∏ KEY –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ secrets.toml")
    return create_client(st.secrets["url"], st.secrets["key"])

def load_students_from_supabase() -> pd.DataFrame:
    """
    –ó–∞–≥—Ä—É–∑–∫–∞ —Å–ø–∏—Å–∫–∞ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ –∏–∑ Supabase (–≤—Å–µ –∑–∞–ø–∏—Å–∏ —Å –ø–∞–≥–∏–Ω–∞—Ü–∏–µ–π)
    –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞–µ—Ç –∫–æ–ª–æ–Ω–∫–∏ –≤ —Ç—Ä–µ–±—É–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç
    –§–∏–ª—å—Ç—Ä—É–µ—Ç —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ –ø–æ –∫—É—Ä—Å—É = "–ö—É—Ä—Å 4"
    Returns:
        DataFrame —Å–æ —Å—Ç—É–¥–µ–Ω—Ç–∞–º–∏ —Å –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–Ω—ã–º–∏ –∫–æ–ª–æ–Ω–∫–∞–º–∏ –∏ —Ñ–∏–ª—å—Ç—Ä–æ–º –ø–æ –∫—É—Ä—Å—É
    """
    try:
        supabase = get_supabase_client()
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤—Å–µ –∑–∞–ø–∏—Å–∏ —Å –ø–∞–≥–∏–Ω–∞—Ü–∏–µ–π –∏ —Ñ–∏–ª—å—Ç—Ä–æ–º –ø–æ –∫—É—Ä—Å—É
        all_data = []
        page_size = 1000
        offset = 0
        while True:
            # –î–æ–±–∞–≤–ª—è–µ–º —Ñ–∏–ª—å—Ç—Ä –ø–æ –∫—É—Ä—Å—É = "–ö—É—Ä—Å 4"
            response = supabase.table('students').select('*').eq('–∫—É—Ä—Å', '–ö—É—Ä—Å 4').range(offset, offset + page_size - 1).execute()
            if response.data:
                all_data.extend(response.data)
                # –ï—Å–ª–∏ –ø–æ–ª—É—á–∏–ª–∏ –º–µ–Ω—å—à–µ –∑–∞–ø–∏—Å–µ–π, —á–µ–º page_size, –∑–Ω–∞—á–∏—Ç —ç—Ç–æ –ø–æ—Å–ª–µ–¥–Ω—è—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞
                if len(response.data) < page_size:
                    break
                offset += page_size
            else:
                break

        if all_data:
            df = pd.DataFrame(all_data)
            # –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –∫–æ–ª–æ–Ω–æ–∫ –∏–∑ —Ñ–æ—Ä–º–∞—Ç–∞ Supabase –≤ —Ç—Ä–µ–±—É–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç
            column_mapping = {
                '–∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∞—è_–ø–æ—á—Ç–∞': '–ê–¥—Ä–µ—Å —ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω–æ–π –ø–æ—á—Ç—ã',
                '—Ñ–∏–æ': '–§–ò–û',
                '—Ñ–∏–ª–∏–∞–ª_–∫–∞–º–ø—É—Å': '–§–∏–ª–∏–∞–ª (–∫–∞–º–ø—É—Å)',
                '—Ñ–∞–∫—É–ª—å—Ç–µ—Ç': '–§–∞–∫—É–ª—å—Ç–µ—Ç',
                '–æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è_–ø—Ä–æ–≥—Ä–∞–º–º–∞': '–û–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≥—Ä–∞–º–º–∞',
                '–≤–µ—Ä—Å–∏—è_–æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–æ–π_–ø—Ä–æ–≥—Ä–∞–º–º—ã': '–í–µ—Ä—Å–∏—è –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–æ–π –ø—Ä–æ–≥—Ä–∞–º–º—ã',
                '–≥—Ä—É–ø–ø–∞': '–ì—Ä—É–ø–ø–∞',
                '–∫—É—Ä—Å': '–ö—É—Ä—Å'
            }
            # –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ —Ç–µ –∫–æ–ª–æ–Ω–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ —Å—É—â–µ—Å—Ç–≤—É—é—Ç
            existing_columns = {k: v for k, v in column_mapping.items() if k in df.columns}
            df = df.rename(columns=existing_columns)
            return df
        else:
            st.warning("‚ö†Ô∏è –¢–∞–±–ª–∏—Ü–∞ students –ø—É—Å—Ç–∞ –∏–ª–∏ –Ω–µ—Ç —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ –Ω–∞ –ö—É—Ä—Å–µ 4 –≤ Supabase")
            return pd.DataFrame()
    except Exception as e:
        st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ –∏–∑ Supabase: {str(e)}")
        return pd.DataFrame()

def create_peresdachi_table_if_not_exists():
    """
    –°–æ–∑–¥–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã peresdachi –≤ Supabase (–µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç)
    –ü—Ä–∏–º–µ—á–∞–Ω–∏–µ: –¢–∞–±–ª–∏—Ü–∞ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å —Å–æ–∑–¥–∞–Ω–∞ –≤—Ä—É—á–Ω—É—é –≤ Supabase Dashboard
    """
    pass  # –¢–∞–±–ª–∏—Ü–∞ —Å–æ–∑–¥–∞–µ—Ç—Å—è –≤—Ä—É—á–Ω—É—é –≤ Supabase

def load_existing_peresdachi() -> pd.DataFrame:
    """
    –ó–∞–≥—Ä—É–∑–∫–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –∑–∞–ø–∏—Å–µ–π –∏–∑ —Ç–∞–±–ª–∏—Ü—ã peresdachi (–≤—Å–µ –∑–∞–ø–∏—Å–∏ —Å –ø–∞–≥–∏–Ω–∞—Ü–∏–µ–π)
    Returns:
        DataFrame —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º–∏ –ø–µ—Ä–µ—Å–¥–∞—á–∞–º–∏
    """
    try:
        supabase = get_supabase_client()
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤—Å–µ –∑–∞–ø–∏—Å–∏ —Å –ø–∞–≥–∏–Ω–∞—Ü–∏–µ–π
        all_data = []
        page_size = 1000
        offset = 0
        while True:
            response = supabase.table('peresdachi').select('*').range(offset, offset + page_size - 1).execute()
            if response.data:
                all_data.extend(response.data)
                # –ï—Å–ª–∏ –ø–æ–ª—É—á–∏–ª–∏ –º–µ–Ω—å—à–µ –∑–∞–ø–∏—Å–µ–π, —á–µ–º page_size, –∑–Ω–∞—á–∏—Ç —ç—Ç–æ –ø–æ—Å–ª–µ–¥–Ω—è—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞
                if len(response.data) < page_size:
                    break
                offset += page_size
            else:
                break

        if all_data:
            return pd.DataFrame(all_data)
        else:
            return pd.DataFrame()
    except Exception as e:
        # –ï—Å–ª–∏ —Ç–∞–±–ª–∏—Ü–∞ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç–æ–π DataFrame
        st.warning(f"‚ö†Ô∏è –¢–∞–±–ª–∏—Ü–∞ peresdachi –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –∏–ª–∏ –ø—É—Å—Ç–∞: {str(e)}")
        return pd.DataFrame()

def save_to_supabase(df: pd.DataFrame) -> Tuple[int, int]:
    """
    –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –≤ —Ç–∞–±–ª–∏—Ü—É peresdachi –≤ Supabase
    Args:
        df: DataFrame —Å –Ω–æ–≤—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
    Returns:
        Tuple (–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–æ–≤—ã—Ö –∑–∞–ø–∏—Å–µ–π, –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π)
    """
    try:
        supabase = get_supabase_client()
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –∑–∞–ø–∏—Å–∏
        existing_df = load_existing_peresdachi()
        if existing_df.empty:
            # –ï—Å–ª–∏ —Ç–∞–±–ª–∏—Ü–∞ –ø—É—Å—Ç–∞, –≤—Å–µ –∑–∞–ø–∏—Å–∏ –Ω–æ–≤—ã–µ
            new_records = df.to_dict('records')
            new_count = len(new_records)
        else:
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω–æ–≤—ã–µ –∑–∞–ø–∏—Å–∏ (–ø–æ –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏ email + –¥–∏—Å—Ü–∏–ø–ª–∏–Ω–∞ + –æ—Ü–µ–Ω–∫–∞)
            merge_cols = ['–ê–¥—Ä–µ—Å —ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω–æ–π –ø–æ—á—Ç—ã', '–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –¥–∏—Å—Ü–∏–ø–ª–∏–Ω—ã']
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –∫–æ–ª–æ–Ω–æ–∫
            if all(col in existing_df.columns for col in merge_cols) and all(col in df.columns for col in merge_cols):
                # –ù–∞—Ö–æ–¥–∏–º –Ω–æ–≤—ã–µ –∑–∞–ø–∏—Å–∏
                merged = df.merge(
                    existing_df[merge_cols],
                    on=merge_cols,
                    how='left',
                    indicator=True
                )
                new_df = merged[merged['_merge'] == 'left_only'].drop('_merge', axis=1)
                new_records = new_df.to_dict('records')
                new_count = len(new_records)
            else:
                # –ï—Å–ª–∏ –∫–æ–ª–æ–Ω–∫–∏ –Ω–µ —Å–æ–≤–ø–∞–¥–∞—é—Ç, —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Å–µ –∫–∞–∫ –Ω–æ–≤—ã–µ
                new_records = df.to_dict('records')
                new_count = len(new_records)

        # –í—Å—Ç–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–µ –∑–∞–ø–∏—Å–∏
        if new_records:
            # –£–¥–∞–ª—è–µ–º –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏ –∏ NaN –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π –≤—Å—Ç–∞–≤–∫–∏
            cleaned_records = []
            for record in new_records:
                cleaned_record = {k: (v if pd.notna(v) else None) for k, v in record.items()}
                cleaned_records.append(cleaned_record)

            response = supabase.table('peresdachi').insert(cleaned_records).execute()

        return new_count, len(df)
    except Exception as e:
        st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –≤ Supabase: {str(e)}")
        raise e

def get_new_records(all_df: pd.DataFrame) -> pd.DataFrame:
    """
    –ü–æ–ª—É—á–∏—Ç—å —Ç–æ–ª—å–∫–æ –Ω–æ–≤—ã–µ –∑–∞–ø–∏—Å–∏, –∫–æ—Ç–æ—Ä—ã—Ö –µ—â–µ –Ω–µ—Ç –≤ –±–∞–∑–µ
    Args:
        all_df: DataFrame —Å–æ –≤—Å–µ–º–∏ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–º–∏ –∑–∞–ø–∏—Å—è–º–∏
    Returns:
        DataFrame —Ç–æ–ª—å–∫–æ —Å –Ω–æ–≤—ã–º–∏ –∑–∞–ø–∏—Å—è–º–∏
    """
    try:
        existing_df = load_existing_peresdachi()
        if existing_df.empty:
            return all_df

        merge_cols = ['–ê–¥—Ä–µ—Å —ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω–æ–π –ø–æ—á—Ç—ã', '–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –¥–∏—Å—Ü–∏–ø–ª–∏–Ω—ã']
        if all(col in existing_df.columns for col in merge_cols) and all(col in all_df.columns for col in merge_cols):
            merged = all_df.merge(
                existing_df[merge_cols],
                on=merge_cols,
                how='left',
                indicator=True
            )
            new_df = merged[merged['_merge'] == 'left_only'].drop('_merge', axis=1)
            return new_df
        else:
            return all_df
    except Exception as e:
        st.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–∏ –Ω–æ–≤—ã—Ö –∑–∞–ø–∏—Å–µ–π: {str(e)}")
        return all_df

def process_external_assessment(grades_df: pd.DataFrame, students_df: pd.DataFrame) -> pd.DataFrame:
    """
    –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–µ—Ä–µ—Å–¥–∞—á –≤–Ω–µ—à–Ω–µ–π –æ—Ü–µ–Ω–∫–∏
    Args:
        grades_df: DataFrame —Å –æ—Ü–µ–Ω–∫–∞–º–∏ –∏–∑ –≤–Ω–µ—à–Ω–µ–π —Å–∏—Å—Ç–µ–º—ã
        students_df: DataFrame —Å–æ —Å–ø–∏—Å–∫–æ–º —Å—Ç—É–¥–µ–Ω—Ç–æ–≤
    Returns:
        –û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π DataFrame —Å –∏—Ç–æ–≥–æ–≤—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
    """
    # –®–∞–≥ 1: –û—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö - —É–¥–∞–ª–µ–Ω–∏–µ "-" –∏ –ª–∏—à–Ω–∏—Ö –ø—Ä–æ–±–µ–ª–æ–≤
    for col in grades_df.columns:
        if grades_df[col].dtype == 'object':
            grades_df[col] = grades_df[col].astype(str).str.replace('-', '', regex=False).str.strip()

    # –®–∞–≥ 2: –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –∫–æ–ª–æ–Ω–æ–∫
    column_mapping = {
        '–¢–µ—Å—Ç:–í—Ö–æ–¥–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ (–ó–Ω–∞—á–µ–Ω–∏–µ)': '–í–Ω–µ—à–Ω–µ–µ –∏–∑–º–µ—Ä–µ–Ω–∏–µ —Ü–∏—Ñ—Ä–æ–≤—ã—Ö –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–π. –í—Ö–æ–¥–Ω–æ–π –∫–æ–Ω—Ç—Ä–æ–ª—å',
        '–¢–µ—Å—Ç:–ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ (–ó–Ω–∞—á–µ–Ω–∏–µ)': '–í–Ω–µ—à–Ω–µ–µ –∏–∑–º–µ—Ä–µ–Ω–∏–µ —Ü–∏—Ñ—Ä–æ–≤—ã—Ö –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–π. –ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–π –∫–æ–Ω—Ç—Ä–æ–ª—å',
        '–¢–µ—Å—Ç:–ò—Ç–æ–≥–æ–≤–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ (–ó–Ω–∞—á–µ–Ω–∏–µ)': '–í–Ω–µ—à–Ω–µ–µ –∏–∑–º–µ—Ä–µ–Ω–∏–µ —Ü–∏—Ñ—Ä–æ–≤—ã—Ö –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–π. –ò—Ç–æ–≥–æ–≤—ã–π –∫–æ–Ω—Ç—Ä–æ–ª—å'
    }
    grades_df = grades_df.rename(columns=column_mapping)

    # –®–∞–≥ 3: Melt - –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –∫–æ–ª–æ–Ω–æ–∫ –≤ —Å—Ç—Ä–æ–∫–∏
    value_columns = [
        '–í–Ω–µ—à–Ω–µ–µ –∏–∑–º–µ—Ä–µ–Ω–∏–µ —Ü–∏—Ñ—Ä–æ–≤—ã—Ö –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–π. –í—Ö–æ–¥–Ω–æ–π –∫–æ–Ω—Ç—Ä–æ–ª—å',
        '–í–Ω–µ—à–Ω–µ–µ –∏–∑–º–µ—Ä–µ–Ω–∏–µ —Ü–∏—Ñ—Ä–æ–≤—ã—Ö –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–π. –ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–π –∫–æ–Ω—Ç—Ä–æ–ª—å',
        '–í–Ω–µ—à–Ω–µ–µ –∏–∑–º–µ—Ä–µ–Ω–∏–µ —Ü–∏—Ñ—Ä–æ–≤—ã—Ö –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–π. –ò—Ç–æ–≥–æ–≤—ã–π –∫–æ–Ω—Ç—Ä–æ–ª—å'
    ]

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º ID –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
    id_cols = ['–ê–¥—Ä–µ—Å —ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω–æ–π –ø–æ—á—Ç—ã']
    if '–ê–¥—Ä–µ—Å —ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω–æ–π –ø–æ—á—Ç—ã' not in grades_df.columns:
        st.error("–ö–æ–ª–æ–Ω–∫–∞ '–ê–¥—Ä–µ—Å —ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω–æ–π –ø–æ—á—Ç—ã' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ —Ñ–∞–π–ª–µ –æ—Ü–µ–Ω–æ–∫")
        return pd.DataFrame()

    melted_df = pd.melt(
        grades_df,
        id_vars=id_cols,
        value_vars=value_columns,
        var_name='–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –¥–∏—Å—Ü–∏–ø–ª–∏–Ω—ã',
        value_name='–û—Ü–µ–Ω–∫–∞'
    )

    # –®–∞–≥ 4: –ü—Ä–∏—Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ –ø–æ email
    students_cols = ['–§–ò–û', '–ê–¥—Ä–µ—Å —ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω–æ–π –ø–æ—á—Ç—ã', '–§–∏–ª–∏–∞–ª (–∫–∞–º–ø—É—Å)',
                     '–§–∞–∫—É–ª—å—Ç–µ—Ç', '–û–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≥—Ä–∞–º–º–∞', '–ì—Ä—É–ø–ø–∞', '–ö—É—Ä—Å']
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –∫–æ–ª–æ–Ω–æ–∫
    missing_cols = [col for col in students_cols if col not in students_df.columns]
    if missing_cols:
        st.warning(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –∫–æ–ª–æ–Ω–∫–∏ –≤ —Ñ–∞–π–ª–µ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤: {missing_cols}")
        available_cols = [col for col in students_cols if col in students_df.columns]
    else:
        available_cols = students_cols

    students_subset = students_df[available_cols].copy()

    # –û—á–∏—Å—Ç–∫–∞ email –≤ –æ–±–æ–∏—Ö —Ñ–∞–π–ª–∞—Ö –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è
    melted_df['–ê–¥—Ä–µ—Å —ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω–æ–π –ø–æ—á—Ç—ã'] = melted_df['–ê–¥—Ä–µ—Å —ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω–æ–π –ø–æ—á—Ç—ã'].astype(str).str.strip().str.lower()
    students_subset['–ê–¥—Ä–µ—Å —ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω–æ–π –ø–æ—á—Ç—ã'] = students_subset['–ê–¥—Ä–µ—Å —ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω–æ–π –ø–æ—á—Ç—ã'].astype(str).str.strip().str.lower()

    result_df = melted_df.merge(
        students_subset,
        on='–ê–¥—Ä–µ—Å —ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω–æ–π –ø–æ—á—Ç—ã',
        how='left'
    )

    # –®–∞–≥ 5: –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –ø—É—Å—Ç—ã—Ö –∫–æ–ª–æ–Ω–æ–∫
    result_df['ID –¥–∏—Å—Ü–∏–ø–ª–∏–Ω—ã'] = ''
    result_df['–ü–µ—Ä–∏–æ–¥ –∞—Ç—Ç–µ—Å—Ç–∞—Ü–∏–∏'] = ''

    # –®–∞–≥ 6: –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –∫–æ–ª–æ–Ω–æ–∫ —Å–æ–≥–ª–∞—Å–Ω–æ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º
    if '–§–∏–ª–∏–∞–ª (–∫–∞–º–ø—É—Å)' in result_df.columns:
        result_df = result_df.rename(columns={'–§–∏–ª–∏–∞–ª (–∫–∞–º–ø—É—Å)': '–ö–∞–º–ø—É—Å'})

    # –®–∞–≥ 7: –£–ø–æ—Ä—è–¥–æ—á–∏–≤–∞–Ω–∏–µ –∫–æ–ª–æ–Ω–æ–∫
    output_columns = [
        '–§–ò–û', '–ê–¥—Ä–µ—Å —ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω–æ–π –ø–æ—á—Ç—ã', '–ö–∞–º–ø—É—Å', '–§–∞–∫—É–ª—å—Ç–µ—Ç',
        '–û–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≥—Ä–∞–º–º–∞', '–ì—Ä—É–ø–ø–∞', '–ö—É—Ä—Å', 'ID –¥–∏—Å—Ü–∏–ø–ª–∏–Ω—ã',
        '–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –¥–∏—Å—Ü–∏–ø–ª–∏–Ω—ã', '–ü–µ—Ä–∏–æ–¥ –∞—Ç—Ç–µ—Å—Ç–∞—Ü–∏–∏', '–û—Ü–µ–Ω–∫–∞'
    ]

    # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –∫–æ–ª–æ–Ω–∫–∏
    final_columns = [col for col in output_columns if col in result_df.columns]
    result_df = result_df[final_columns]

    # –£–¥–∞–ª–µ–Ω–∏–µ —Å—Ç—Ä–æ–∫ —Å –ø—É—Å—Ç—ã–º–∏ –æ—Ü–µ–Ω–∫–∞–º–∏ –∏–ª–∏ –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
    result_df = result_df[result_df['–û—Ü–µ–Ω–∫–∞'].notna()]
    result_df = result_df[result_df['–û—Ü–µ–Ω–∫–∞'].astype(str).str.strip() != '']
    result_df = result_df[result_df['–û—Ü–µ–Ω–∫–∞'].astype(str).str.strip() != 'nan']

    return result_df

def process_student_data(df: pd.DataFrame, grade_mapping: Dict[str, str]) -> Tuple[pd.DataFrame, list]:
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ –¥–ª—è —Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç–æ–≤"""
    results = []
    processing_log = []
    processing_log.append(f"üìä –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º {len(df)} —Å—Ç—É–¥–µ–Ω—Ç–æ–≤")
    for index, row in df.iterrows():
        student_results = []
        processed_keys = set()
        for discipline_num in range(1, 4):
            discipline_col = f"–î–∏—Å—Ü–∏–ø–ª–∏–Ω–∞ {discipline_num}"
            grade_5_col = f"–û—Ü–µ–Ω–∫–∞ 5 –±–∞–ª–ª–æ–≤ –î–∏—Å—Ü–∏–ø–ª–∏–Ω–∞ {discipline_num}"

            if discipline_col not in df.columns or grade_5_col not in df.columns:
                continue

            discipline_value = str(row[discipline_col]).strip()
            grade_value = str(row[grade_5_col]).strip()

            if pd.isna(discipline_value) or pd.isna(grade_value) or discipline_value == 'nan' or grade_value == 'nan':
                continue

            lookup_key = f"{discipline_value}‚Äî{grade_value}"
            if lookup_key in processed_keys:
                continue

            if lookup_key in grade_mapping:
                skill_description = grade_mapping[lookup_key]

                short_name_col = f"–ù–∞–∑–≤–∞–Ω–∏–µ –î–∏—Å—Ü–∏–ø–ª–∏–Ω—ã {discipline_num}"
                if short_name_col in df.columns:
                    display_name = str(row[short_name_col]).strip()
                    formatted_discipline = display_name.capitalize() if display_name != 'nan' and display_name else discipline_value
                else:
                    formatted_discipline = discipline_value

                formatted_result = f"üìö {formatted_discipline}:\n{skill_description}"
                student_results.append(formatted_result)
                processed_keys.add(lookup_key)

        final_result = "\n".join(student_results) if student_results else "–ù–∞–≤—ã–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã."
        results.append(final_result)

    processing_log.append(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ")
    df_result = df.copy()
    df_result['–ò—Ç–æ–≥–æ–≤—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç'] = results

    columns_to_remove = [col for col in df_result.columns if col.startswith("–ù–∞–∑–≤–∞–Ω–∏–µ –î–∏—Å—Ü–∏–ø–ª–∏–Ω—ã ")]
    if columns_to_remove:
        df_result = df_result.drop(columns=columns_to_remove)

    return df_result, processing_log

# =============================================================================
# –§–£–ù–ö–¶–ò–ò –î–õ–Ø –ú–û–î–£–õ–Ø 5: –ê–ù–ê–õ–ò–¢–ò–ö–ê –ö–£–†–°–û–í
# =============================================================================
from io import StringIO
import time

def upload_students_to_supabase(supabase, student_data):
    """
    –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ –≤ —Ç–∞–±–ª–∏—Ü—É students —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ UPSERT
    """
    try:
        st.info("üë• –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ (UPSERT)...")
        records_for_upsert = []
        processed_emails = set()
        for _, row in student_data.iterrows():
            email = str(row.get('–ö–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∞—è –ø–æ—á—Ç–∞', '')).strip().lower()
            if not email or '@edu.hse.ru' not in email:
                continue
            if email in processed_emails:
                continue
            processed_emails.add(email)
            student_record = {
                '–∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∞—è_–ø–æ—á—Ç–∞': email,
                '—Ñ–∏–æ': str(row.get('–§–ò–û', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')).strip() or '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ',
                '—Ñ–∏–ª–∏–∞–ª_–∫–∞–º–ø—É—Å': str(row.get('–§–∏–ª–∏–∞–ª (–∫–∞–º–ø—É—Å)', '')) if pd.notna(row.get('–§–∏–ª–∏–∞–ª (–∫–∞–º–ø—É—Å)')) and str(row.get('–§–∏–ª–∏–∞–ª (–∫–∞–º–ø—É—Å)', '')).strip() else None,
                '—Ñ–∞–∫—É–ª—å—Ç–µ—Ç': str(row.get('–§–∞–∫—É–ª—å—Ç–µ—Ç', '')) if pd.notna(row.get('–§–∞–∫—É–ª—å—Ç–µ—Ç')) and str(row.get('–§–∞–∫—É–ª—å—Ç–µ—Ç', '')).strip() else None,
                '–æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è_–ø—Ä–æ–≥—Ä–∞–º–º–∞': str(row.get('–û–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≥—Ä–∞–º–º–∞', '')) if pd.notna(row.get('–û–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≥—Ä–∞–º–º–∞')) and str(row.get('–û–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≥—Ä–∞–º–º–∞', '')).strip() else None,
                '–≤–µ—Ä—Å–∏—è_–æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–æ–π_–ø—Ä–æ–≥—Ä–∞–º–º—ã': str(row.get('–í–µ—Ä—Å–∏—è –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–æ–π –ø—Ä–æ–≥—Ä–∞–º–º—ã', '')) if pd.notna(row.get('–í–µ—Ä—Å–∏—è –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–æ–π –ø—Ä–æ–≥—Ä–∞–º–º—ã')) and str(row.get('–í–µ—Ä—Å–∏—è –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–æ–π –ø—Ä–æ–≥—Ä–∞–º–º—ã', '')).strip() else None,
                '–≥—Ä—É–ø–ø–∞': str(row.get('–ì—Ä—É–ø–ø–∞', '')) if pd.notna(row.get('–ì—Ä—É–ø–ø–∞')) and str(row.get('–ì—Ä—É–ø–ø–∞', '')).strip() else None,
                '–∫—É—Ä—Å': str(row.get('–ö—É—Ä—Å', '')) if pd.notna(row.get('–ö—É—Ä—Å')) and str(row.get('–ö—É—Ä—Å', '')).strip() else None,
            }
            records_for_upsert.append(student_record)

        if not records_for_upsert:
            st.info("üìã –ù–µ—Ç –∑–∞–ø–∏—Å–µ–π –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
            return True

        st.info(f"üìã –ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–æ {len(records_for_upsert)} –∑–∞–ø–∏—Å–µ–π –¥–ª—è UPSERT")

        batch_size = 200
        total_processed = 0
        for i in range(0, len(records_for_upsert), batch_size):
            batch = records_for_upsert[i:i + batch_size]
            batch_num = (i // batch_size) + 1
            total_batches = ((len(records_for_upsert) - 1) // batch_size) + 1

            try:
                result = supabase.table('students').upsert(
                    batch,
                    on_conflict='–∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∞—è_–ø–æ—á—Ç–∞',
                    ignore_duplicates=False,
                    returning='minimal'
                ).execute()
                total_processed += len(batch)
                st.success(f"‚úÖ –ë–∞—Ç—á {batch_num}/{total_batches}: –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(batch)} –∑–∞–ø–∏—Å–µ–π")
            except Exception as e:
                error_str = str(e)
                if any(pat in error_str.lower() for pat in ["connection", "timeout", "ssl", "eof"]):
                    st.warning(f"‚ö†Ô∏è –°–µ—Ç–µ–≤–∞—è –æ—à–∏–±–∫–∞ –≤ –±–∞—Ç—á–µ {batch_num}, –ø–æ–≤—Ç–æ—Ä...")
                    time.sleep(2)
                    try:
                        result = supabase.table('students').upsert(batch, on_conflict='–∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∞—è_–ø–æ—á—Ç–∞').execute()
                        total_processed += len(batch)
                        st.success(f"‚úÖ –ë–∞—Ç—á {batch_num} (–ø–æ—Å–ª–µ –ø–æ–≤—Ç–æ—Ä–∞)")
                    except Exception as retry_error:
                        st.error(f"‚ùå –ë–∞—Ç—á {batch_num} –Ω–µ —É–¥–∞–ª—Å—è –ø–æ—Å–ª–µ –ø–æ–≤—Ç–æ—Ä–∞: {retry_error}")
                        return False
                else:
                    st.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ –±–∞—Ç—á–µ {batch_num}: {e}")
                    return False

        st.success(f"üéâ UPSERT –∑–∞–≤–µ—Ä—à—ë–Ω! –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {total_processed} –∑–∞–ø–∏—Å–µ–π")
        return True
    except Exception as e:
        st.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ UPSERT —Å—Ç—É–¥–µ–Ω—Ç–æ–≤: {e}")
        return False

def load_student_list_file(uploaded_file) -> pd.DataFrame:
    """
    –ó–∞–≥—Ä—É–∑–∫–∞ —Å–ø–∏—Å–∫–∞ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ –∏–∑ —Ñ–∞–π–ª–∞ Excel –∏–ª–∏ CSV
    """
    try:
        file_name = uploaded_file.name.lower()
        if file_name.endswith(('.xlsx', '.xls')):
            df = pd.read_excel(uploaded_file)
        elif file_name.endswith('.csv'):
            content = uploaded_file.getvalue()
            try:
                df = pd.read_csv(StringIO(content.decode('utf-16')), sep='\t')
            except (UnicodeDecodeError, pd.errors.ParserError):
                try:
                    df = pd.read_csv(StringIO(content.decode('utf-8')))
                except UnicodeDecodeError:
                    df = pd.read_csv(StringIO(content.decode('cp1251')))
        else:
            st.error("–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞")
            return pd.DataFrame()

        required_columns = {
            '–§–ò–û': ['—Ñ–∏–æ', '—Ñio', '–∏–º—è', 'name'],
            '–ö–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∞—è –ø–æ—á—Ç–∞': ['–∞–¥—Ä–µ—Å —ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω–æ–π –ø–æ—á—Ç—ã', '–∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∞—è –ø–æ—á—Ç–∞', 'email', '–ø–æ—á—Ç–∞', 'e-mail'],
            '–§–∏–ª–∏–∞–ª (–∫–∞–º–ø—É—Å)': ['—Ñ–∏–ª–∏–∞–ª', '–∫–∞–º–ø—É—Å', 'campus'],
            '–§–∞–∫—É–ª—å—Ç–µ—Ç': ['—Ñ–∞–∫—É–ª—å—Ç–µ—Ç', 'faculty'],
            '–û–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≥—Ä–∞–º–º–∞': ['–æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≥—Ä–∞–º–º–∞', '–ø—Ä–æ–≥—Ä–∞–º–º–∞', 'educational program'],
            '–í–µ—Ä—Å–∏—è –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–æ–π –ø—Ä–æ–≥—Ä–∞–º–º—ã': ['–≤–µ—Ä—Å–∏—è –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–æ–π –ø—Ä–æ–≥—Ä–∞–º–º—ã', '–≤–µ—Ä—Å–∏—è –ø—Ä–æ–≥—Ä–∞–º–º—ã', 'program version', 'version'],
            '–ì—Ä—É–ø–ø–∞': ['–≥—Ä—É–ø–ø–∞', 'group'],
            '–ö—É—Ä—Å': ['–∫—É—Ä—Å', 'course']
        }

        found_columns = {}
        df_columns_lower = [str(col).lower().strip() for col in df.columns]
        for target_col, possible_names in required_columns.items():
            for col_idx, col_name in enumerate(df_columns_lower):
                if any(possible_name in col_name for possible_name in possible_names):
                    found_columns[target_col] = df.columns[col_idx]
                    break

        result_df = pd.DataFrame()
        for target_col, source_col in found_columns.items():
            if source_col in df.columns:
                result_df[target_col] = df[source_col]

        if '–î–∞–Ω–Ω—ã–µ –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ' in df.columns:
            user_data = df['–î–∞–Ω–Ω—ã–µ –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ'].astype(str)
            parsed_data = user_data.str.split(';', expand=True)
            if len(parsed_data.columns) >= 4:
                result_df['–§–∞–∫—É–ª—å—Ç–µ—Ç'] = parsed_data[0]
                result_df['–û–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≥—Ä–∞–º–º–∞'] = parsed_data[1]
                result_df['–ö—É—Ä—Å'] = parsed_data[2]
                result_df['–ì—Ä—É–ø–ø–∞'] = parsed_data[3]

        for required_col in required_columns.keys():
            if required_col not in result_df.columns:
                if required_col == '–§–ò–û':
                    result_df[required_col] = None
                else:
                    result_df[required_col] = ''

        if '–ö–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∞—è –ø–æ—á—Ç–∞' in result_df.columns:
            result_df = result_df[result_df['–ö–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∞—è –ø–æ—á—Ç–∞'].astype(str).str.contains('@edu.hse.ru', na=False)]
            result_df['–ö–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∞—è –ø–æ—á—Ç–∞'] = pd.Series(result_df['–ö–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∞—è –ø–æ—á—Ç–∞']).astype(str).str.lower().str.strip()

        return result_df
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Å–ø–∏—Å–∫–∞ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤: {e}")
        return pd.DataFrame()

def upload_course_data_to_supabase(supabase, course_data, course_name):
    """–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –æ–¥–Ω–æ–≥–æ –∫—É—Ä—Å–∞ –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â—É—é —Ç–∞–±–ª–∏—Ü—É"""
    try:
        table_mapping = {'–¶–ì': 'course_cg', '–ü–∏—Ç–æ–Ω': 'course_python', '–ê–Ω–¥–∞–Ω': 'course_analysis'}
        table_name = table_mapping.get(course_name)
        if not table_name:
            st.error(f"‚ùå –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –∫—É—Ä—Å: {course_name}")
            return False

        st.info(f"üìà –ó–∞–≥—Ä—É–∑–∫–∞ –∫—É—Ä—Å–∞ {course_name} –≤ {table_name}...")

        if course_data is None or course_data.empty:
            st.warning(f"‚ö†Ô∏è –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∫—É—Ä—Å–∞ {course_name}")
            return True

        records_for_upsert = []
        processed_emails = set()
        for _, row in course_data.iterrows():
            email = str(row.get('–ö–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∞—è –ø–æ—á—Ç–∞', '')).strip().lower()
            if not email or '@edu.hse.ru' not in email:
                continue
            if email in processed_emails:
                continue
            processed_emails.add(email)

            percent_col = f'–ü—Ä–æ—Ü–µ–Ω—Ç_{course_name}'
            progress_value = None
            if percent_col in row and pd.notna(row[percent_col]) and row[percent_col] != '':
                try:
                    progress_value = float(row[percent_col])
                except (ValueError, TypeError):
                    progress_value = None

            records_for_upsert.append({
                '–∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∞—è_–ø–æ—á—Ç–∞': email,
                '–ø—Ä–æ—Ü–µ–Ω—Ç_–∑–∞–≤–µ—Ä—à–µ–Ω–∏—è': progress_value
            })

        if not records_for_upsert:
            st.info(f"üìã –ù–µ—Ç –∑–∞–ø–∏—Å–µ–π –¥–ª—è –∫—É—Ä—Å–∞ {course_name}")
            return True

        batch_size = 200
        total_processed = 0
        for i in range(0, len(records_for_upsert), batch_size):
            batch = records_for_upsert[i:i + batch_size]
            batch_num = (i // batch_size) + 1

            try:
                supabase.table(table_name).upsert(batch, on_conflict='–∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∞—è_–ø–æ—á—Ç–∞').execute()
                total_processed += len(batch)
                st.success(f"‚úÖ –ö—É—Ä—Å {course_name} - –±–∞—Ç—á {batch_num}: {len(batch)} –∑–∞–ø–∏—Å–µ–π")
            except Exception as e:
                st.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∫—É—Ä—Å–∞ {course_name}, –±–∞—Ç—á {batch_num}: {e}")
                return False

        st.success(f"üéâ –ö—É—Ä—Å {course_name}: {total_processed} –∑–∞–ø–∏—Å–µ–π –∑–∞–≥—Ä—É–∂–µ–Ω–æ")
        return True
    except Exception as e:
        st.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∫—É—Ä—Å–∞ {course_name}: {e}")
        return False

def extract_course_data(uploaded_file, course_name):
    """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∫—É—Ä—Å–∞ –∏–∑ —Ñ–∞–π–ª–∞"""
    try:
        file_name = uploaded_file.name.lower()
        if file_name.endswith(('.xlsx', '.xls')):
            df = pd.read_excel(uploaded_file)
        elif file_name.endswith('.csv'):
            content = uploaded_file.getvalue()
            try:
                df = pd.read_csv(StringIO(content.decode('utf-16')), sep='\t')
            except (UnicodeDecodeError, pd.errors.ParserError):
                try:
                    df = pd.read_csv(StringIO(content.decode('utf-8')))
                except UnicodeDecodeError:
                    df = pd.read_csv(StringIO(content.decode('cp1251')))
        else:
            st.error(f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞ –¥–ª—è –∫—É—Ä—Å–∞ {course_name}")
            return None

        email_column = None
        possible_email_names = ['–ê–¥—Ä–µ—Å —ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω–æ–π –ø–æ—á—Ç—ã', '–ö–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∞—è –ø–æ—á—Ç–∞', 'Email', '–ü–æ—á—Ç–∞', 'E-mail']
        for col_name in possible_email_names:
            if col_name in df.columns:
                email_column = col_name
                break

        if email_column is None:
            st.error(f"–°—Ç–æ–ª–±–µ—Ü —Å email –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ —Ñ–∞–π–ª–µ {course_name}")
            return None

        cg_excluded_keywords = [
            'take away', '—à–ø–∞—Ä–≥–∞–ª–∫–∞', '–∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è', '–æ–±—â–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è', '–ø—Ä–æ–º–æ-—Ä–æ–ª–∏–∫',
            '–ø–æ–¥–¥–µ—Ä–∂–∫–∞ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤', '–ø–æ—è—Å–Ω–µ–Ω–∏–µ', '—Å–ª—É—á–∞–π–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç –¥–ª—è —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ —Å –æ–≤–∑',
            '–º–∞—Ç–µ—Ä–∏–∞–ª—ã –ø–æ –º–æ–¥—É–ª—é', '–∫–æ–ø–∏—è', '–¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç', '—Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏—è',
            '–¥–µ–º–æ-–≤–µ—Ä—Å–∏—è', '–ø—Ä–∞–≤–∏–ª–∞ –ø—Ä–æ–≤–µ–¥–µ–Ω–∏—è –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ–≥–æ —ç–∫–∑–∞–º–µ–Ω–∞',
            '–ø–æ—Ä—è–¥–æ–∫ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ –∏ –ø—Ä–æ–≤–µ–¥–µ–Ω–∏—è –Ω–µ–∑–∞–≤–∏—Å–∏–º—ã—Ö —ç–∫–∑–∞–º–µ–Ω–æ–≤',
            '–∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π —Ç—Ä–µ–Ω–∞–∂–µ—Ä –ø—Ä–∞–≤–∏–ª –Ω—ç', '–ø–µ—Ä–µ—Å–¥–∞—á–∏ –≤ —Å–µ–Ω—Ç—è–±—Ä–µ', '–Ω–µ–∑—Ä—è—á–∏—Ö –∏ —Å–ª–∞–±–æ–≤–∏–¥—è—â–∏—Ö',
            '–ø—Ä–æ–µ–∫—Ç—ã —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ tei', '—Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–π —Ç–µ—Å—Ç', '–∫–ª—é—á–µ–≤—ã–µ –ø—Ä–∏–Ω—Ü–∏–ø—ã tei',
            '–±–∞–∑–æ–≤—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ tie', '—Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ –º–æ–¥—É–ª–∏ tei', '–±—É–¥—É—Ç –∏–¥–µ–Ω—Ç–∏—á–Ω—ã–º–∏',
            '–æ–ø—Ä–æ—Å', '—Ç–µ—Å—Ç –ø–æ –º–æ–¥—É–ª—é', '–∞–Ω–∫–µ—Ç–∞', 'user information', '—Å—Ç—Ä–∞–Ω–∞', 'user_id', '–¥–∞–Ω–Ω—ã–µ –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ'
        ]

        excluded_count = 0
        completed_columns = []
        timestamp_columns = []

        for col in df.columns:
            if col not in ['Unnamed: 0', email_column, '–î–∞–Ω–Ω—ã–µ –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ', 'User information', '–°—Ç—Ä–∞–Ω–∞']:
                if course_name == '–¶–ì':
                    should_exclude = False
                    col_str = str(col).strip().lower()
                    for excluded_keyword in cg_excluded_keywords:
                        if excluded_keyword.lower() in col_str:
                            should_exclude = True
                            excluded_count += 1
                            break
                    if should_exclude:
                        continue

                if not col.startswith('Unnamed:') and len(str(col).strip()) > 0:
                    sample_values = df[col].dropna().astype(str).head(100)
                    if any('–í—ã–ø–æ–ª–Ω–µ–Ω–æ' in str(val) or '–≤—ã–ø–æ–ª–Ω–µ–Ω–æ' in str(val).lower() for val in sample_values):
                        if not all(str(val) == '–ù–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–æ' for val in sample_values if pd.notna(val)):
                            completed_columns.append(col)
                elif col.startswith('Unnamed:') and col != 'Unnamed: 0':
                    sample_values = df[col].dropna().astype(str).head(20)
                    for val in sample_values:
                        val_str = str(val).strip()
                        if val_str and val_str != 'nan' and val_str != '':
                            if any(pattern in val_str for pattern in ['2020', '2021', '2022', '2023', '2024']) and ':' in val_str:
                                timestamp_columns.append(col)
                                break

        if timestamp_columns:
            completion_data = []
            for idx, row in df.iterrows():
                email_val = row[email_column]
                if pd.isna(email_val) or '@edu.hse.ru' not in str(email_val).lower():
                    continue

                total_tasks = len(timestamp_columns)
                completed_tasks = 0
                for col in timestamp_columns:
                    cell_val = row[col]
                    val_str = str(cell_val).strip() if not pd.isna(cell_val) else ''
                    if val_str and val_str != 'nan':
                        if any(pattern in val_str for pattern in ['2020', '2021', '2022', '2023', '2024']) and ':' in val_str:
                            completed_tasks += 1

                percentage = (completed_tasks / total_tasks * 100) if total_tasks > 0 else 0
                completion_data.append({'email': str(email_val).lower().strip(), 'percentage': percentage})

            if completion_data:
                result_df = pd.DataFrame(completion_data)
                result_df.columns = ['–ö–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∞—è –ø–æ—á—Ç–∞', f'–ü—Ä–æ—Ü–µ–Ω—Ç_{course_name}']
                st.success(f"‚úÖ –†–∞—Å—Å—á–∏—Ç–∞–Ω –ø—Ä–æ—Ü–µ–Ω—Ç –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –¥–ª—è {len(result_df)} —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ –∫—É—Ä—Å–∞ {course_name}")
                return result_df

        elif completed_columns:
            completion_data = []
            for idx, row in df.iterrows():
                email_val = row[email_column]
                if pd.isna(email_val) or '@edu.hse.ru' not in str(email_val).lower():
                    continue

                total_tasks = 0
                completed_tasks = 0
                for col in completed_columns:
                    cell_val = row[col]
                    val = str(cell_val).strip() if not pd.isna(cell_val) else ''
                    if val and val != 'nan':
                        total_tasks += 1
                        if '–í—ã–ø–æ–ª–Ω–µ–Ω–æ' in val or '–≤—ã–ø–æ–ª–Ω–µ–Ω–æ' in val.lower():
                            completed_tasks += 1

                percentage = (completed_tasks / total_tasks * 100) if total_tasks > 0 else 0
                completion_data.append({'email': str(email_val).lower().strip(), 'percentage': percentage})

            if completion_data:
                result_df = pd.DataFrame(completion_data)
                result_df.columns = ['–ö–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∞—è –ø–æ—á—Ç–∞', f'–ü—Ä–æ—Ü–µ–Ω—Ç_{course_name}']
                st.success(f"‚úÖ –†–∞—Å—Å—á–∏—Ç–∞–Ω –ø—Ä–æ—Ü–µ–Ω—Ç –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –¥–ª—è {len(result_df)} —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ –∫—É—Ä—Å–∞ {course_name}")
                return result_df

        st.warning(f"–ù–µ –Ω–∞–π–¥–µ–Ω–æ –¥–∞–Ω–Ω—ã—Ö –æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏ –¥–ª—è –∫—É—Ä—Å–∞ {course_name}")
        return None
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö –∫—É—Ä—Å–∞ {course_name}: {e}")
        return None

# =============================================================================
# –û–°–ù–û–í–ù–û–ï –ü–†–ò–õ–û–ñ–ï–ù–ò–ï
# =============================================================================

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è"""
    # =============================================================================
    # APPLE-–°–û–í–ú–ï–°–¢–ò–ú–´–ô UI/UX LAYER (–ë–ï–ó –ò–ó–ú–ï–ù–ï–ù–ò–Ø –õ–û–ì–ò–ö–ò)
    # =============================================================================
    st.markdown("""
    <style>
        /* Apple-style typography */
        h1, h2, h3, h4 {
            font-weight: 600;
            letter-spacing: -0.02em;
            line-height: 1.2;
            color: #e0e0e6;
        }
        h1 {
            font-size: 2.25rem;
            margin-bottom: 0.5rem;
        }
        h2 {
            font-size: 1.5rem;
            margin-top: 1.5rem;
            margin-bottom: 1rem;
        }
        p, li, .stMarkdown {
            color: #c6c6cc;
            line-height: 1.6;
        }
        /* Apple-style buttons */
        .stButton > button {
            border-radius: 12px;
            padding: 8px 20px;
            font-weight: 500;
            border: none;
            background-color: #4a86e8;
            color: white;
            transition: background-color 0.2s ease;
        }
        .stButton > button:hover {
            background-color: #5a96f8;
        }
        /* Apple-style info boxes */
        .stAlert {
            border-radius: 12px;
            padding: 14px 18px;
            margin: 16px 0;
        }
        /* Sidebar refinement */
        [data-testid="stSidebar"] {
            background-color: #2a2a30 !important;
        }
        [data-testid="stSidebar"] h2,
        [data-testid="stSidebar"] p,
        [data-testid="stSidebar"] label {
            color: #e0e0e6 !important;
        }
        /* Consistent spacing */
        .block-container {
            padding-top: 2rem;
            padding-bottom: 2rem;
        }
        hr {
            margin: 1.5rem 0;
            border-color: #3a3a42;
        }
        /* Footer */
        footer {
            visibility: hidden;
        }
        .custom-footer {
            text-align: center;
            color: #888892;
            font-size: 0.85rem;
            margin-top: 2rem;
            padding-top: 1.5rem;
            border-top: 1px solid #3a3a42;
        }
    </style>
    """, unsafe_allow_html=True)

    # –ó–∞–≥–æ–ª–æ–≤–æ–∫ (Apple-style: –±–µ–∑ —ç–º–æ–¥–∑–∏, —Å caption)
    st.title("DataCulture Platform")
    st.caption("–û–±—ä–µ–¥–∏–Ω—ë–Ω–Ω–∞—è –ø–ª–∞—Ç—Ñ–æ—Ä–º–∞ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ Data Culture @ HSE University")
    st.caption("–î–ª—è —Å–∞–º—ã—Ö –ª—É—á—à–∏—Ö —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤ –ø—Ä–æ–µ–∫—Ç–∞ –æ—Ç –¢–∏–º–æ—à–∫–∏")
    st.markdown("---")

    # --- –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–∞—è –Ω–∞–≤–∏–≥–∞—Ü–∏—è ---
    # –°–æ–∑–¥–∞–µ–º —Å–ø–∏—Å–æ–∫ —Å—Ç—Ä–∞–Ω–∏—Ü –¥–ª—è navigation
    pages = [
        st.Page("app_main.py", title="–ü–µ—Ä–µ–∑–∞—á–µ—Ç –æ—Ü–µ–Ω–æ–∫", icon="üìä"), # –ó–∞–º–µ–Ω–∏—Ç–µ "app_main.py" –Ω–∞ –∏–º—è –≤–∞—à–µ–≥–æ —Ñ–∞–π–ª–∞
        st.Page("app_cards.py", title="–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä HTML-–∫–∞—Ä—Ç–æ—á–µ–∫", icon="üéì"), # –ü—Ä–∏–º–µ—Ä –¥–ª—è –¥—Ä—É–≥–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã
        st.Page("app_cert.py", title="–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä —Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç–æ–≤", icon="üìú"), # –ü—Ä–∏–º–µ—Ä –¥–ª—è –¥—Ä—É–≥–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã
        st.Page("app_resits.py", title="–û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–µ—Ä–µ—Å–¥–∞—á –≤–Ω–µ—à–Ω–µ–π –æ—Ü–µ–Ω–∫–∏", icon="üìù"), # –ü—Ä–∏–º–µ—Ä –¥–ª—è –¥—Ä—É–≥–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã
        st.Page("app_analytics.py", title="–ê–Ω–∞–ª–∏—Ç–∏–∫–∞ –∫—É—Ä—Å–æ–≤", icon="üìà"), # –ü—Ä–∏–º–µ—Ä –¥–ª—è –¥—Ä—É–≥–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã
        st.Page("app_students.py", title="–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤", icon="üë•"), # –ü—Ä–∏–º–µ—Ä –¥–ª—è –¥—Ä—É–≥–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã
    ]

    # –ò—Å–ø–æ–ª—å–∑—É–µ–º navigation –≤ –±–æ–∫–æ–≤–æ–π –ø–∞–Ω–µ–ª–∏
    with st.sidebar:
        st.image(LOGO_URL, width=160)  # —É–º–µ–Ω—å—à–µ–Ω–æ –¥–æ 160px –¥–ª—è –ª—É—á—à–µ–π –ø—Ä–æ–ø–æ—Ä—Ü–∏–∏
        st.markdown("<br>", unsafe_allow_html=True)
        # –°–æ–∑–¥–∞–µ–º –Ω–∞–≤–∏–≥–∞—Ü–∏—é
        pg = navigation(pages)
        st.markdown("<br>", unsafe_allow_html=True)
        st.markdown("### ‚ÑπÔ∏è –û –ø–ª–∞—Ç—Ñ–æ—Ä–º–µ")
        st.info("""
        **DataCulture Platform** –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç —à–µ—Å—Ç—å –∫–ª—é—á–µ–≤—ã—Ö –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤:
        1. **–ü–µ—Ä–µ–∑–∞—á–µ—Ç –æ—Ü–µ–Ω–æ–∫** ‚Äî –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π —Ä–∞—Å—á–µ—Ç –∏—Ç–æ–≥–æ–≤—ã—Ö –æ—Ü–µ–Ω–æ–∫  
        2. **–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –∫–∞—Ä—Ç–æ—á–µ–∫** ‚Äî —Å–æ–∑–¥–∞–Ω–∏–µ HTML-—Ä–∞—Å—Å—ã–ª–æ–∫ –≤ —Ñ–∏—Ä–º–µ–Ω–Ω–æ–º —Å—Ç–∏–ª–µ –í–®–≠  
        3. **–°–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç—ã** ‚Äî –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≤—ã–¥–∞—á–∏ —Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç–æ–≤  
        4. **–ü–µ—Ä–µ—Å–¥–∞—á–∏** ‚Äî –æ–±—Ä–∞–±–æ—Ç–∫–∞ –ø–µ—Ä–µ—Å–¥–∞—á –≤–Ω–µ—à–Ω–µ–π –æ—Ü–µ–Ω–∫–∏  
        5. **–ê–Ω–∞–ª–∏—Ç–∏–∫–∞ –∫—É—Ä—Å–æ–≤** ‚Äî –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏ –∑–∞–≥—Ä—É–∑–∫–∞ –∞–Ω–∞–ª–∏—Ç–∏–∫–∏ –∫—É—Ä—Å–æ–≤ –≤ Supabase  
        6. **–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤** ‚Äî –∑–∞–≥—Ä—É–∑–∫–∞ –∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ –≤ Supabase  
        """)

    # –ó–∞–ø—É—Å–∫–∞–µ–º –≤—ã–±—Ä–∞–Ω–Ω—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É
    pg.run()

    # –§—É—Ç–µ—Ä (Apple-style)
    st.markdown("""
    <div class="custom-footer">
        DataCulture Platform v1.0 ¬∑ Created by –¢–∏–º–æ—à–∫–∞
    </div>
    """, unsafe_allow_html=True)

if __name__ == "__main__":
    main()
