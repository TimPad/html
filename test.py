"""
DataCulture Unified Platform
–û–±—ä–µ–¥–∏–Ω—ë–Ω–Ω–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –¥–ª—è –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ Data Culture @ HSE University
–ê–≤—Ç–æ—Ä: –¢–∏–º–æ—à–∫–∞
"""

import streamlit as st
import pandas as pd
import numpy as np
from datetime import datetime
import io
import json
from openai import OpenAI
import tempfile
import os
from typing import Dict, Tuple
from supabase import create_client, Client
from streamlit import navigation


# =============================================================================
# –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø –ü–†–ò–õ–û–ñ–ï–ù–ò–Ø
# =============================================================================

st.set_page_config(
    page_title="DataCulture Platform",
    page_icon="üìä",
    layout="wide",
    initial_sidebar_state="expanded"
)

# =============================================================================
# –ö–û–ù–°–¢–ê–ù–¢–´
# =============================================================================

LOGO_URL = "https://raw.githubusercontent.com/TimPad/html/main/DC_green.svg"

HTML_EXAMPLE = f"""<div style="font-family: 'Inter', 'Segoe UI', Roboto, Arial, sans-serif; max-width: 860px; margin: 40px auto; background: #ffffff; border-radius: 16px; box-shadow: 0 4px 14px rgba(0,0,0,0.08); border: 1px solid #e5ebf8; overflow: hidden;">
    <div style="background: #00256c; color: white; padding: 28px 32px; text-align: center;">
        <img src="{LOGO_URL}" alt="–õ–æ–≥–æ—Ç–∏–ø Data Culture" style="height: 48px; margin-bottom: 16px;">
        <p><span style="font-size: 1.6em; font-weight: 700;">–ó–ê–ì–û–õ–û–í–û–ö –û–ë–™–Ø–í–õ–ï–ù–ò–Ø</span></p>
        <p style="margin-top: 8px; line-height: 1.5;">–ö—Ä–∞—Ç–∫–æ–µ –≤–≤–µ–¥–µ–Ω–∏–µ –∏–ª–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç.</p>
    </div>
    <div style="padding: 28px 32px; color: #111827; line-height: 1.65;">
        <p>–û—Å–Ω–æ–≤–Ω–æ–π —Ç–µ–∫—Å—Ç –æ–±—ä—è–≤–ª–µ–Ω–∏—è...</p>
        <h3 style="color: #00256c;">–ü–æ–¥–∑–∞–≥–æ–ª–æ–≤–æ–∫</h3>
        <ul style="margin: 12px 0 22px 22px;">
            <li>–ü—É–Ω–∫—Ç —Å–ø–∏—Å–∫–∞</li>
        </ul>
        <div style="background: #f4f6fb; border-radius: 10px; padding: 16px 20px; margin: 16px 0;">
            <p>–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω—ã–π –±–ª–æ–∫</p>
        </div>
        <div style="background: #fff8e1; border-left: 4px solid #f59e0b; padding: 14px 18px; border-radius: 8px; margin-bottom: 20px;">
            <p style="margin: 0; font-weight: 600; color: #92400e;">‚ö†Ô∏è –í–Ω–∏–º–∞–Ω–∏–µ! –í–∞–∂–Ω–æ–µ —É—Ç–æ—á–Ω–µ–Ω–∏–µ.</p>
        </div>
        <div style="background: #f0fdf4; border-left: 4px solid #16a34a; padding: 16px 20px; border-radius: 8px;">
            <p style="margin: 4px 0 0;"><strong>–£–¥–∞—á–∏!</strong> üöÄ</p>
        </div>
    </div>
</div>"""

SYSTEM_MESSAGE = (
    "–í—ã ‚Äî —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏—é –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã—Ö —Ä–∞—Å—Å—ã–ª–æ–∫ –ù–ò–£ –í–®–≠. "
    "–í–∞—à–∞ –∑–∞–¥–∞—á–∞ ‚Äî –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –≤—Ö–æ–¥–Ω–æ–π —Ç–µ–∫—Å—Ç –æ–±—ä—è–≤–ª–µ–Ω–∏—è –≤ HTML-–∫–∞—Ä—Ç–æ—á–∫—É, —Å—Ç—Ä–æ–≥–æ —Å–ª–µ–¥—É—è —Ñ–∏—Ä–º–µ–Ω–Ω–æ–º—É —Å—Ç–∏–ª—é. "
    "–í —à–∞–ø–∫–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –ª–æ–≥–æ—Ç–∏–ø –ø–æ —Å—Å—ã–ª–∫–µ: " + LOGO_URL + ". "
    "–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—É –∏ CSS-—Å—Ç–∏–ª–∏ –∏–∑ –ø—Ä–∏–≤–µ–¥—ë–Ω–Ω–æ–≥–æ –Ω–∏–∂–µ –ø—Ä–∏–º–µ—Ä–∞. "
    "–ù–µ –¥–æ–±–∞–≤–ª—è–π—Ç–µ –ø–æ—è—Å–Ω–µ–Ω–∏–π, –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ –∏–ª–∏ –ª–∏—à–Ω–∏—Ö —Ç–µ–≥–æ–≤. "
    "–í–µ—Ä–Ω–∏—Ç–µ –¢–û–õ–¨–ö–û –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π JSON –≤ —Ñ–æ—Ä–º–∞—Ç–µ: {\"type\": \"HTML\", \"content\": \"<div>...</div>\"}.\n\n"
    "–ü—Ä–∏–º–µ—Ä –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ –≤—ã–≤–æ–¥–∞:\n"
    + json.dumps({"type": "HTML", "content": HTML_EXAMPLE}, ensure_ascii=False, indent=2)
)

# =============================================================================
# –§–£–ù–ö–¶–ò–ò –î–õ–Ø –ú–û–î–£–õ–Ø 1: –ü–ï–†–ï–ó–ê–ß–ï–¢ –û–¶–ï–ù–û–ö
# =============================================================================

def process_grade_recalculation(df: pd.DataFrame, use_dynamics: bool) -> pd.DataFrame:
    """
    –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø–µ—Ä–µ–∑–∞—á–µ—Ç–∞ –æ—Ü–µ–Ω–æ–∫
    
    Args:
        df: DataFrame —Å –¥–∞–Ω–Ω—ã–º–∏ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤
        use_dynamics: –£—á–∏—Ç—ã–≤–∞—Ç—å –ª–∏ –¥–∏–Ω–∞–º–∏–∫—É –æ—Ü–µ–Ω–æ–∫
        
    Returns:
        –û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π DataFrame —Å –∫–æ–ª–æ–Ω–∫–∞–º–∏ –î–ü–†_–∏—Ç–æ–≥ –∏ –ù–≠_–∏—Ç–æ–≥
    """
    processed_df = df.copy()

    required_columns = [
        '–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –ù–≠', '–û—Ü–µ–Ω–∫–∞ –ù–≠', '–û—Ü–µ–Ω–∫–∞ –¥–∏—Å—Ü–∏–ø–ª–∏–Ω—ã-–ø—Ä–µ—Ä–µ–∫–≤–∏–∑–∏—Ç–∞',
        '–í–Ω–µ—à–Ω–µ–µ –∏–∑–º–µ—Ä–µ–Ω–∏–µ —Ü–∏—Ñ—Ä–æ–≤—ã—Ö –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–π. –í—Ö–æ–¥–Ω–æ–π –∫–æ–Ω—Ç—Ä–æ–ª—å',
        '–í–Ω–µ—à–Ω–µ–µ –∏–∑–º–µ—Ä–µ–Ω–∏–µ —Ü–∏—Ñ—Ä–æ–≤—ã—Ö –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–π. –ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–π –∫–æ–Ω—Ç—Ä–æ–ª—å',
        '–í–Ω–µ—à–Ω–µ–µ –∏–∑–º–µ—Ä–µ–Ω–∏–µ —Ü–∏—Ñ—Ä–æ–≤—ã—Ö –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–π. –ò—Ç–æ–≥–æ–≤—ã–π –∫–æ–Ω—Ç—Ä–æ–ª—å'
    ]
    
    for col in required_columns:
        if col not in processed_df.columns:
            raise KeyError(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–π —Å—Ç–æ–ª–±–µ—Ü: '{col}'")

    processed_df['–û—Ü–µ–Ω–∫–∞ –¥–∏—Å—Ü–∏–ø–ª–∏–Ω—ã-–ø—Ä–µ—Ä–µ–∫–≤–∏–∑–∏—Ç–∞'] = processed_df['–û—Ü–µ–Ω–∫–∞ –¥–∏—Å—Ü–∏–ø–ª–∏–Ω—ã-–ø—Ä–µ—Ä–µ–∫–≤–∏–∑–∏—Ç–∞'].apply(
        lambda x: 8 if x >= 9 else x
    )

    processed_df['–≠—Ç–∞–ø'] = 1
    processed_df.loc[processed_df['–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –ù–≠'].str.contains('–∞–Ω–∞–ª–∏–∑—É –¥–∞–Ω–Ω—ã—Ö', case=False, na=False), '–≠—Ç–∞–ø'] = 3
    processed_df.loc[processed_df['–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –ù–≠'].str.contains('–ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—é', case=False, na=False), '–≠—Ç–∞–ø'] = 2

    dpr_results = []
    ie_results = []

    for index, row in processed_df.iterrows():
        if row['–≠—Ç–∞–ø'] == 1:
            innopolis_grade = row['–í–Ω–µ—à–Ω–µ–µ –∏–∑–º–µ—Ä–µ–Ω–∏–µ —Ü–∏—Ñ—Ä–æ–≤—ã—Ö –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–π. –í—Ö–æ–¥–Ω–æ–π –∫–æ–Ω—Ç—Ä–æ–ª—å']
        elif row['–≠—Ç–∞–ø'] == 2:
            innopolis_grade = row['–í–Ω–µ—à–Ω–µ–µ –∏–∑–º–µ—Ä–µ–Ω–∏–µ —Ü–∏—Ñ—Ä–æ–≤—ã—Ö –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–π. –ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–π –∫–æ–Ω—Ç—Ä–æ–ª—å']
        else:
            innopolis_grade = row['–í–Ω–µ—à–Ω–µ–µ –∏–∑–º–µ—Ä–µ–Ω–∏–µ —Ü–∏—Ñ—Ä–æ–≤—ã—Ö –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–π. –ò—Ç–æ–≥–æ–≤—ã–π –∫–æ–Ω—Ç—Ä–æ–ª—å']

        if use_dynamics:
            vhod = row['–í–Ω–µ—à–Ω–µ–µ –∏–∑–º–µ—Ä–µ–Ω–∏–µ —Ü–∏—Ñ—Ä–æ–≤—ã—Ö –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–π. –í—Ö–æ–¥–Ω–æ–π –∫–æ–Ω—Ç—Ä–æ–ª—å']
            prom = row['–í–Ω–µ—à–Ω–µ–µ –∏–∑–º–µ—Ä–µ–Ω–∏–µ —Ü–∏—Ñ—Ä–æ–≤—ã—Ö –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–π. –ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–π –∫–æ–Ω—Ç—Ä–æ–ª—å']
            itog = row['–í–Ω–µ—à–Ω–µ–µ –∏–∑–º–µ—Ä–µ–Ω–∏–µ —Ü–∏—Ñ—Ä–æ–≤—ã—Ö –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–π. –ò—Ç–æ–≥–æ–≤—ã–π –∫–æ–Ω—Ç—Ä–æ–ª—å']
            
            if (vhod - prom > 1) or (vhod - itog > 1) or (prom - itog > 1):
                dpr_results.append(np.nan)
                ie_results.append(np.nan)
                continue

        ne_grade = row['–û—Ü–µ–Ω–∫–∞ –ù–≠']
        dpr_grade = row['–û—Ü–µ–Ω–∫–∞ –¥–∏—Å—Ü–∏–ø–ª–∏–Ω—ã-–ø—Ä–µ—Ä–µ–∫–≤–∏–∑–∏—Ç–∞']
        
        ne_grade = 0 if pd.isna(ne_grade) else ne_grade
        dpr_grade = 0 if pd.isna(dpr_grade) else dpr_grade
        innopolis_grade = 0 if pd.isna(innopolis_grade) else innopolis_grade

        max_grade = max(ne_grade, dpr_grade, innopolis_grade)
        
        # –†–∞—Å—á–µ—Ç –î–ü–†_–∏—Ç–æ–≥
        dpr_final = np.nan
        if ne_grade < 4:
            dpr_final = np.nan
        elif max_grade == innopolis_grade and innopolis_grade > 3 and innopolis_grade != dpr_grade and innopolis_grade != ne_grade:
            dpr_final = innopolis_grade
        elif ne_grade == dpr_grade:
            dpr_final = np.nan
        elif dpr_grade < 4:
            dpr_final = ne_grade if ne_grade >= 4 else np.nan
        elif max_grade == dpr_grade and dpr_grade >= 4:
            dpr_final = np.nan
        else:
            dpr_final = ne_grade
        dpr_results.append(dpr_final)

        # –†–∞—Å—á–µ—Ç –ù–≠_–∏—Ç–æ–≥
        ie_final = np.nan
        if ne_grade < 4:
            ie_final = np.nan
        elif max_grade == innopolis_grade and innopolis_grade > 3 and innopolis_grade != dpr_grade and innopolis_grade != ne_grade:
            ie_final = innopolis_grade
        elif ne_grade == dpr_grade:
            ie_final = np.nan
        elif max_grade == dpr_grade and dpr_grade >= 4:
            if ne_grade >= 8:
                ie_final = np.nan
            elif dpr_grade >= 8:
                ie_final = 8
            else:
                ie_final = dpr_grade
        elif ne_grade < 4 and innopolis_grade > 3 and use_dynamics:
             ie_final = innopolis_grade
        else:
            ie_final = np.nan
        ie_results.append(ie_final)

    processed_df['–î–ü–†_–∏—Ç–æ–≥'] = dpr_results
    processed_df['–ù–≠_–∏—Ç–æ–≥'] = ie_results
    
    return processed_df

# =============================================================================
# –§–£–ù–ö–¶–ò–ò –î–õ–Ø –ú–û–î–£–õ–Ø 2: –ì–ï–ù–ï–†–ê–¢–û–† HTML-–ö–ê–†–¢–û–ß–ï–ö
# =============================================================================

@st.cache_resource
def get_nebius_client():
    """–ü–æ–ª—É—á–∏—Ç—å –∫–ª–∏–µ–Ω—Ç Nebius API"""
    if "NEBIUS_API_KEY" not in st.secrets:
        raise ValueError("NEBIUS_API_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ secrets.")
    return OpenAI(
        base_url="https://api.studio.nebius.com/v1/",
        api_key=st.secrets["NEBIUS_API_KEY"]
    )

def generate_hse_html(client: OpenAI, user_text: str) -> str:
    """
    –ì–µ–Ω–µ—Ä–∞—Ü–∏—è HTML-–∫–∞—Ä—Ç–æ—á–∫–∏ —á–µ—Ä–µ–∑ Nebius API
    
    Args:
        client: OpenAI –∫–ª–∏–µ–Ω—Ç
        user_text: –¢–µ–∫—Å—Ç –æ–±—ä—è–≤–ª–µ–Ω–∏—è
        
    Returns:
        HTML-–∫–æ–¥ –∫–∞—Ä—Ç–æ—á–∫–∏
    """
    response = client.chat.completions.create(
        model="Qwen/Qwen3-Coder-30B-A3B-Instruct",
        response_format={"type": "json_object"},
        messages=[
            {"role": "system", "content": SYSTEM_MESSAGE},
            {"role": "user", "content": user_text}
        ],
        timeout=60.0
    )

    raw_content = response.choices[0].message.content.strip()

    try:
        parsed = json.loads(raw_content)
    except json.JSONDecodeError:
        raise ValueError(f"–ú–æ–¥–µ–ª—å –≤–µ—Ä–Ω—É–ª–∞ –Ω–µ-JSON. –û—Ç–≤–µ—Ç:\n{raw_content[:500]}")

    if not isinstance(parsed, dict):
        raise ValueError("–û—Ç–≤–µ—Ç –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –æ–±—ä–µ–∫—Ç–æ–º JSON.")

    if parsed.get("type") != "HTML":
        raise ValueError("–ü–æ–ª–µ 'type' –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å 'HTML'.")

    content = parsed.get("content")
    if not isinstance(content, str) or not content.strip():
        raise ValueError("–ü–æ–ª–µ 'content' –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∏–ª–∏ –ø—É—Å—Ç–æ–µ.")

    return content.strip()

# =============================================================================
# –§–£–ù–ö–¶–ò–ò –î–õ–Ø –ú–û–î–£–õ–Ø 3: –û–ë–†–ê–ë–û–¢–ö–ê –°–ï–†–¢–ò–§–ò–ö–ê–¢–û–í
# =============================================================================

def deduplicate_lines(text):
    """–£–¥–∞–ª—è–µ—Ç –¥—É–±–ª–∏—Ä—É—é—â–∏–µ—Å—è —Å—Ç—Ä–æ–∫–∏ –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
    if pd.isna(text) or not isinstance(text, str):
        return text
    
    lines = text.split('\n')
    seen_lines = set()
    unique_lines = []
    
    for line in lines:
        line_clean = line.strip()
        if line_clean and line_clean not in seen_lines:
            seen_lines.add(line_clean)
            unique_lines.append(line)
    
    return '\n'.join(unique_lines)

@st.cache_data
def load_reference_data(skills_content: bytes) -> Dict[str, str]:
    """–ó–∞–≥—Ä—É–∑–∫–∞ —Å–ø—Ä–∞–≤–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∏–∑ —Ñ–∞–π–ª–∞ –Ω–∞–≤—ã–∫–æ–≤"""
    with tempfile.NamedTemporaryFile(delete=False, suffix='.xlsx') as tmp_file:
        tmp_file.write(skills_content)
        tmp_file_path = tmp_file.name
    
    try:
        skills_df = pd.read_excel(tmp_file_path)
        
        grade_mapping = {}
        for _, row in skills_df.iterrows():
            discipline = row['–î–∏—Å—Ü–∏–ø–ª–∏–Ω–∞']
            level = row['–£—Ä–æ–≤–µ–Ω—å_–æ—Ü–µ–Ω–∫–∏']
            description = row['–û–ø–∏—Å–∞–Ω–∏–µ_–Ω–∞–≤—ã–∫–æ–≤']
            clean_description = deduplicate_lines(description)
            composite_key = f"{discipline}‚Äî{level}"
            grade_mapping[composite_key] = clean_description
        
        return grade_mapping
    finally:
        os.unlink(tmp_file_path)

# =============================================================================
# –§–£–ù–ö–¶–ò–ò –î–õ–Ø –ú–û–î–£–õ–Ø 4: –û–ë–†–ê–ë–û–¢–ö–ê –ü–ï–†–ï–°–î–ê–ß –í–ù–ï–®–ù–ï–ô –û–¶–ï–ù–ö–ò
# =============================================================================

@st.cache_resource
def get_supabase_client() -> Client:
    """–ü–æ–ª—É—á–∏—Ç—å –∫–ª–∏–µ–Ω—Ç Supabase"""
    if "url" not in st.secrets or "key" not in st.secrets:
        raise ValueError("Supabase URL –∏ KEY –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ secrets.toml")
    return create_client(st.secrets["url"], st.secrets["key"])

def load_students_from_supabase() -> pd.DataFrame:
    """
    –ó–∞–≥—Ä—É–∑–∫–∞ —Å–ø–∏—Å–∫–∞ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ –∏–∑ Supabase (–≤—Å–µ –∑–∞–ø–∏—Å–∏ —Å –ø–∞–≥–∏–Ω–∞—Ü–∏–µ–π)
    –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞–µ—Ç –∫–æ–ª–æ–Ω–∫–∏ –≤ —Ç—Ä–µ–±—É–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç
    –§–∏–ª—å—Ç—Ä—É–µ—Ç —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ –ø–æ –∫—É—Ä—Å—É = "–ö—É—Ä—Å 4"
    
    Returns:
        DataFrame —Å–æ —Å—Ç—É–¥–µ–Ω—Ç–∞–º–∏ —Å –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–Ω—ã–º–∏ –∫–æ–ª–æ–Ω–∫–∞–º–∏ –∏ —Ñ–∏–ª—å—Ç—Ä–æ–º –ø–æ –∫—É—Ä—Å—É
    """
    try:
        supabase = get_supabase_client()
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤—Å–µ –∑–∞–ø–∏—Å–∏ —Å –ø–∞–≥–∏–Ω–∞—Ü–∏–µ–π –∏ —Ñ–∏–ª—å—Ç—Ä–æ–º –ø–æ –∫—É—Ä—Å—É
        all_data = []
        page_size = 1000
        offset = 0
        
        while True:
            # –î–æ–±–∞–≤–ª—è–µ–º —Ñ–∏–ª—å—Ç—Ä –ø–æ –∫—É—Ä—Å—É = "–ö—É—Ä—Å 4"
            response = supabase.table('students').select('*').eq('–∫—É—Ä—Å', '–ö—É—Ä—Å 4').range(offset, offset + page_size - 1).execute()
            
            if response.data:
                all_data.extend(response.data)
                
                # –ï—Å–ª–∏ –ø–æ–ª—É—á–∏–ª–∏ –º–µ–Ω—å—à–µ –∑–∞–ø–∏—Å–µ–π, —á–µ–º page_size, –∑–Ω–∞—á–∏—Ç —ç—Ç–æ –ø–æ—Å–ª–µ–¥–Ω—è—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞
                if len(response.data) < page_size:
                    break
                    
                offset += page_size
            else:
                break
        
        if all_data:
            df = pd.DataFrame(all_data)
            
            # –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –∫–æ–ª–æ–Ω–æ–∫ –∏–∑ —Ñ–æ—Ä–º–∞—Ç–∞ Supabase –≤ —Ç—Ä–µ–±—É–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç
            column_mapping = {
                '–∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∞—è_–ø–æ—á—Ç–∞': '–ê–¥—Ä–µ—Å —ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω–æ–π –ø–æ—á—Ç—ã',
                '—Ñ–∏–æ': '–§–ò–û',
                '—Ñ–∏–ª–∏–∞–ª_–∫–∞–º–ø—É—Å': '–§–∏–ª–∏–∞–ª (–∫–∞–º–ø—É—Å)',
                '—Ñ–∞–∫—É–ª—å—Ç–µ—Ç': '–§–∞–∫—É–ª—å—Ç–µ—Ç',
                '–æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è_–ø—Ä–æ–≥—Ä–∞–º–º–∞': '–û–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≥—Ä–∞–º–º–∞',
                '–≤–µ—Ä—Å–∏—è_–æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–æ–π_–ø—Ä–æ–≥—Ä–∞–º–º—ã': '–í–µ—Ä—Å–∏—è –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–æ–π –ø—Ä–æ–≥—Ä–∞–º–º—ã',
                '–≥—Ä—É–ø–ø–∞': '–ì—Ä—É–ø–ø–∞',
                '–∫—É—Ä—Å': '–ö—É—Ä—Å'
            }
            
            # –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ —Ç–µ –∫–æ–ª–æ–Ω–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ —Å—É—â–µ—Å—Ç–≤—É—é—Ç
            existing_columns = {k: v for k, v in column_mapping.items() if k in df.columns}
            df = df.rename(columns=existing_columns)
            
            return df
        else:
            st.warning("‚ö†Ô∏è –¢–∞–±–ª–∏—Ü–∞ students –ø—É—Å—Ç–∞ –∏–ª–∏ –Ω–µ—Ç —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ –Ω–∞ –ö—É—Ä—Å–µ 4 –≤ Supabase")
            return pd.DataFrame()
    except Exception as e:
        st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ –∏–∑ Supabase: {str(e)}")
        return pd.DataFrame()

def create_peresdachi_table_if_not_exists():
    """
    –°–æ–∑–¥–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã peresdachi –≤ Supabase (–µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç)
    –ü—Ä–∏–º–µ—á–∞–Ω–∏–µ: –¢–∞–±–ª–∏—Ü–∞ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å —Å–æ–∑–¥–∞–Ω–∞ –≤—Ä—É—á–Ω—É—é –≤ Supabase Dashboard
    """
    pass  # –¢–∞–±–ª–∏—Ü–∞ —Å–æ–∑–¥–∞–µ—Ç—Å—è –≤—Ä—É—á–Ω—É—é –≤ Supabase

def load_existing_peresdachi() -> pd.DataFrame:
    """
    –ó–∞–≥—Ä—É–∑–∫–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –∑–∞–ø–∏—Å–µ–π –∏–∑ —Ç–∞–±–ª–∏—Ü—ã peresdachi (–≤—Å–µ –∑–∞–ø–∏—Å–∏ —Å –ø–∞–≥–∏–Ω–∞—Ü–∏–µ–π)
    
    Returns:
        DataFrame —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º–∏ –ø–µ—Ä–µ—Å–¥–∞—á–∞–º–∏
    """
    try:
        supabase = get_supabase_client()
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤—Å–µ –∑–∞–ø–∏—Å–∏ —Å –ø–∞–≥–∏–Ω–∞—Ü–∏–µ–π
        all_data = []
        page_size = 1000
        offset = 0
        
        while True:
            response = supabase.table('peresdachi').select('*').range(offset, offset + page_size - 1).execute()
            
            if response.data:
                all_data.extend(response.data)
                
                # –ï—Å–ª–∏ –ø–æ–ª—É—á–∏–ª–∏ –º–µ–Ω—å—à–µ –∑–∞–ø–∏—Å–µ–π, —á–µ–º page_size, –∑–Ω–∞—á–∏—Ç —ç—Ç–æ –ø–æ—Å–ª–µ–¥–Ω—è—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞
                if len(response.data) < page_size:
                    break
                    
                offset += page_size
            else:
                break
        
        if all_data:
            return pd.DataFrame(all_data)
        else:
            return pd.DataFrame()
    except Exception as e:
        # –ï—Å–ª–∏ —Ç–∞–±–ª–∏—Ü–∞ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç–æ–π DataFrame
        st.warning(f"‚ö†Ô∏è –¢–∞–±–ª–∏—Ü–∞ peresdachi –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –∏–ª–∏ –ø—É—Å—Ç–∞: {str(e)}")
        return pd.DataFrame()

def save_to_supabase(df: pd.DataFrame) -> Tuple[int, int]:
    """
    –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –≤ —Ç–∞–±–ª–∏—Ü—É peresdachi –≤ Supabase
    
    Args:
        df: DataFrame —Å –Ω–æ–≤—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
        
    Returns:
        Tuple (–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–æ–≤—ã—Ö –∑–∞–ø–∏—Å–µ–π, –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π)
    """
    try:
        supabase = get_supabase_client()
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –∑–∞–ø–∏—Å–∏
        existing_df = load_existing_peresdachi()
        
        if existing_df.empty:
            # –ï—Å–ª–∏ —Ç–∞–±–ª–∏—Ü–∞ –ø—É—Å—Ç–∞, –≤—Å–µ –∑–∞–ø–∏—Å–∏ –Ω–æ–≤—ã–µ
            new_records = df.to_dict('records')
            new_count = len(new_records)
        else:
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω–æ–≤—ã–µ –∑–∞–ø–∏—Å–∏ (–ø–æ –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏ email + –¥–∏—Å—Ü–∏–ø–ª–∏–Ω–∞ + –æ—Ü–µ–Ω–∫–∞)
            merge_cols = ['–ê–¥—Ä–µ—Å —ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω–æ–π –ø–æ—á—Ç—ã', '–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –¥–∏—Å—Ü–∏–ø–ª–∏–Ω—ã']
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –∫–æ–ª–æ–Ω–æ–∫
            if all(col in existing_df.columns for col in merge_cols) and all(col in df.columns for col in merge_cols):
                # –ù–∞—Ö–æ–¥–∏–º –Ω–æ–≤—ã–µ –∑–∞–ø–∏—Å–∏
                merged = df.merge(
                    existing_df[merge_cols],
                    on=merge_cols,
                    how='left',
                    indicator=True
                )
                new_df = merged[merged['_merge'] == 'left_only'].drop('_merge', axis=1)
                new_records = new_df.to_dict('records')
                new_count = len(new_records)
            else:
                # –ï—Å–ª–∏ –∫–æ–ª–æ–Ω–∫–∏ –Ω–µ —Å–æ–≤–ø–∞–¥–∞—é—Ç, —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Å–µ –∫–∞–∫ –Ω–æ–≤—ã–µ
                new_records = df.to_dict('records')
                new_count = len(new_records)
        
        # –í—Å—Ç–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–µ –∑–∞–ø–∏—Å–∏
        if new_records:
            # –£–¥–∞–ª—è–µ–º –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏ –∏ NaN –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π –≤—Å—Ç–∞–≤–∫–∏
            cleaned_records = []
            for record in new_records:
                cleaned_record = {k: (v if pd.notna(v) else None) for k, v in record.items()}
                cleaned_records.append(cleaned_record)
            
            response = supabase.table('peresdachi').insert(cleaned_records).execute()
            
        return new_count, len(df)
        
    except Exception as e:
        st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –≤ Supabase: {str(e)}")
        raise e

def get_new_records(all_df: pd.DataFrame) -> pd.DataFrame:
    """
    –ü–æ–ª—É—á–∏—Ç—å —Ç–æ–ª—å–∫–æ –Ω–æ–≤—ã–µ –∑–∞–ø–∏—Å–∏, –∫–æ—Ç–æ—Ä—ã—Ö –µ—â–µ –Ω–µ—Ç –≤ –±–∞–∑–µ
    
    Args:
        all_df: DataFrame —Å–æ –≤—Å–µ–º–∏ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–º–∏ –∑–∞–ø–∏—Å—è–º–∏
        
    Returns:
        DataFrame —Ç–æ–ª—å–∫–æ —Å –Ω–æ–≤—ã–º–∏ –∑–∞–ø–∏—Å—è–º–∏
    """
    try:
        existing_df = load_existing_peresdachi()
        
        if existing_df.empty:
            return all_df
        
        merge_cols = ['–ê–¥—Ä–µ—Å —ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω–æ–π –ø–æ—á—Ç—ã', '–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –¥–∏—Å—Ü–∏–ø–ª–∏–Ω—ã']
        
        if all(col in existing_df.columns for col in merge_cols) and all(col in all_df.columns for col in merge_cols):
            merged = all_df.merge(
                existing_df[merge_cols],
                on=merge_cols,
                how='left',
                indicator=True
            )
            new_df = merged[merged['_merge'] == 'left_only'].drop('_merge', axis=1)
            return new_df
        else:
            return all_df
            
    except Exception as e:
        st.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–∏ –Ω–æ–≤—ã—Ö –∑–∞–ø–∏—Å–µ–π: {str(e)}")
        return all_df

def process_external_assessment(grades_df: pd.DataFrame, students_df: pd.DataFrame) -> pd.DataFrame:
    """
    –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–µ—Ä–µ—Å–¥–∞—á –≤–Ω–µ—à–Ω–µ–π –æ—Ü–µ–Ω–∫–∏
    
    Args:
        grades_df: DataFrame —Å –æ—Ü–µ–Ω–∫–∞–º–∏ –∏–∑ –≤–Ω–µ—à–Ω–µ–π —Å–∏—Å—Ç–µ–º—ã
        students_df: DataFrame —Å–æ —Å–ø–∏—Å–∫–æ–º —Å—Ç—É–¥–µ–Ω—Ç–æ–≤
        
    Returns:
        –û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π DataFrame —Å –∏—Ç–æ–≥–æ–≤—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
    """
    # –®–∞–≥ 1: –û—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö - —É–¥–∞–ª–µ–Ω–∏–µ "-" –∏ –ª–∏—à–Ω–∏—Ö –ø—Ä–æ–±–µ–ª–æ–≤
    for col in grades_df.columns:
        if grades_df[col].dtype == 'object':
            grades_df[col] = grades_df[col].astype(str).str.replace('-', '', regex=False).str.strip()
    
    # –®–∞–≥ 2: –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –∫–æ–ª–æ–Ω–æ–∫
    column_mapping = {
        '–¢–µ—Å—Ç:–í—Ö–æ–¥–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ (–ó–Ω–∞—á–µ–Ω–∏–µ)': '–í–Ω–µ—à–Ω–µ–µ –∏–∑–º–µ—Ä–µ–Ω–∏–µ —Ü–∏—Ñ—Ä–æ–≤—ã—Ö –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–π. –í—Ö–æ–¥–Ω–æ–π –∫–æ–Ω—Ç—Ä–æ–ª—å',
        '–¢–µ—Å—Ç:–ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ (–ó–Ω–∞—á–µ–Ω–∏–µ)': '–í–Ω–µ—à–Ω–µ–µ –∏–∑–º–µ—Ä–µ–Ω–∏–µ —Ü–∏—Ñ—Ä–æ–≤—ã—Ö –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–π. –ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–π –∫–æ–Ω—Ç—Ä–æ–ª—å',
        '–¢–µ—Å—Ç:–ò—Ç–æ–≥–æ–≤–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ (–ó–Ω–∞—á–µ–Ω–∏–µ)': '–í–Ω–µ—à–Ω–µ–µ –∏–∑–º–µ—Ä–µ–Ω–∏–µ —Ü–∏—Ñ—Ä–æ–≤—ã—Ö –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–π. –ò—Ç–æ–≥–æ–≤—ã–π –∫–æ–Ω—Ç—Ä–æ–ª—å'
    }
    
    grades_df = grades_df.rename(columns=column_mapping)
    
    # –®–∞–≥ 3: Melt - –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –∫–æ–ª–æ–Ω–æ–∫ –≤ —Å—Ç—Ä–æ–∫–∏
    value_columns = [
        '–í–Ω–µ—à–Ω–µ–µ –∏–∑–º–µ—Ä–µ–Ω–∏–µ —Ü–∏—Ñ—Ä–æ–≤—ã—Ö –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–π. –í—Ö–æ–¥–Ω–æ–π –∫–æ–Ω—Ç—Ä–æ–ª—å',
        '–í–Ω–µ—à–Ω–µ–µ –∏–∑–º–µ—Ä–µ–Ω–∏–µ —Ü–∏—Ñ—Ä–æ–≤—ã—Ö –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–π. –ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–π –∫–æ–Ω—Ç—Ä–æ–ª—å',
        '–í–Ω–µ—à–Ω–µ–µ –∏–∑–º–µ—Ä–µ–Ω–∏–µ —Ü–∏—Ñ—Ä–æ–≤—ã—Ö –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–π. –ò—Ç–æ–≥–æ–≤—ã–π –∫–æ–Ω—Ç—Ä–æ–ª—å'
    ]
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º ID –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
    id_cols = ['–ê–¥—Ä–µ—Å —ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω–æ–π –ø–æ—á—Ç—ã']
    if '–ê–¥—Ä–µ—Å —ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω–æ–π –ø–æ—á—Ç—ã' not in grades_df.columns:
        st.error("–ö–æ–ª–æ–Ω–∫–∞ '–ê–¥—Ä–µ—Å —ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω–æ–π –ø–æ—á—Ç—ã' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ —Ñ–∞–π–ª–µ –æ—Ü–µ–Ω–æ–∫")
        return pd.DataFrame()
    
    melted_df = pd.melt(
        grades_df,
        id_vars=id_cols,
        value_vars=value_columns,
        var_name='–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –¥–∏—Å—Ü–∏–ø–ª–∏–Ω—ã',
        value_name='–û—Ü–µ–Ω–∫–∞'
    )
    
    # –®–∞–≥ 4: –ü—Ä–∏—Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ –ø–æ email
    students_cols = ['–§–ò–û', '–ê–¥—Ä–µ—Å —ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω–æ–π –ø–æ—á—Ç—ã', '–§–∏–ª–∏–∞–ª (–∫–∞–º–ø—É—Å)', 
                     '–§–∞–∫—É–ª—å—Ç–µ—Ç', '–û–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≥—Ä–∞–º–º–∞', '–ì—Ä—É–ø–ø–∞', '–ö—É—Ä—Å']
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –∫–æ–ª–æ–Ω–æ–∫
    missing_cols = [col for col in students_cols if col not in students_df.columns]
    if missing_cols:
        st.warning(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –∫–æ–ª–æ–Ω–∫–∏ –≤ —Ñ–∞–π–ª–µ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤: {missing_cols}")
        available_cols = [col for col in students_cols if col in students_df.columns]
    else:
        available_cols = students_cols
    
    students_subset = students_df[available_cols].copy()
    
    # –û—á–∏—Å—Ç–∫–∞ email –≤ –æ–±–æ–∏—Ö —Ñ–∞–π–ª–∞—Ö –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è
    melted_df['–ê–¥—Ä–µ—Å —ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω–æ–π –ø–æ—á—Ç—ã'] = melted_df['–ê–¥—Ä–µ—Å —ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω–æ–π –ø–æ—á—Ç—ã'].astype(str).str.strip().str.lower()
    students_subset['–ê–¥—Ä–µ—Å —ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω–æ–π –ø–æ—á—Ç—ã'] = students_subset['–ê–¥—Ä–µ—Å —ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω–æ–π –ø–æ—á—Ç—ã'].astype(str).str.strip().str.lower()
    
    result_df = melted_df.merge(
        students_subset,
        on='–ê–¥—Ä–µ—Å —ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω–æ–π –ø–æ—á—Ç—ã',
        how='left'
    )
    
    # –®–∞–≥ 5: –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –ø—É—Å—Ç—ã—Ö –∫–æ–ª–æ–Ω–æ–∫
    result_df['ID –¥–∏—Å—Ü–∏–ø–ª–∏–Ω—ã'] = ''
    result_df['–ü–µ—Ä–∏–æ–¥ –∞—Ç—Ç–µ—Å—Ç–∞—Ü–∏–∏'] = ''
    
    # –®–∞–≥ 6: –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –∫–æ–ª–æ–Ω–æ–∫ —Å–æ–≥–ª–∞—Å–Ω–æ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º
    if '–§–∏–ª–∏–∞–ª (–∫–∞–º–ø—É—Å)' in result_df.columns:
        result_df = result_df.rename(columns={'–§–∏–ª–∏–∞–ª (–∫–∞–º–ø—É—Å)': '–ö–∞–º–ø—É—Å'})
    
    # –®–∞–≥ 7: –£–ø–æ—Ä—è–¥–æ—á–∏–≤–∞–Ω–∏–µ –∫–æ–ª–æ–Ω–æ–∫
    output_columns = [
        '–§–ò–û', '–ê–¥—Ä–µ—Å —ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω–æ–π –ø–æ—á—Ç—ã', '–ö–∞–º–ø—É—Å', '–§–∞–∫—É–ª—å—Ç–µ—Ç',
        '–û–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≥—Ä–∞–º–º–∞', '–ì—Ä—É–ø–ø–∞', '–ö—É—Ä—Å', 'ID –¥–∏—Å—Ü–∏–ø–ª–∏–Ω—ã',
        '–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –¥–∏—Å—Ü–∏–ø–ª–∏–Ω—ã', '–ü–µ—Ä–∏–æ–¥ –∞—Ç—Ç–µ—Å—Ç–∞—Ü–∏–∏', '–û—Ü–µ–Ω–∫–∞'
    ]
    
    # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –∫–æ–ª–æ–Ω–∫–∏
    final_columns = [col for col in output_columns if col in result_df.columns]
    result_df = result_df[final_columns]
    
    # –£–¥–∞–ª–µ–Ω–∏–µ —Å—Ç—Ä–æ–∫ —Å –ø—É—Å—Ç—ã–º–∏ –æ—Ü–µ–Ω–∫–∞–º–∏ –∏–ª–∏ –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
    result_df = result_df[result_df['–û—Ü–µ–Ω–∫–∞'].notna()]
    result_df = result_df[result_df['–û—Ü–µ–Ω–∫–∞'].astype(str).str.strip() != '']
    result_df = result_df[result_df['–û—Ü–µ–Ω–∫–∞'].astype(str).str.strip() != 'nan']
    
    return result_df

def process_student_data(df: pd.DataFrame, grade_mapping: Dict[str, str]) -> Tuple[pd.DataFrame, list]:
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ –¥–ª—è —Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç–æ–≤"""
    results = []
    processing_log = []
    
    processing_log.append(f"üìä –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º {len(df)} —Å—Ç—É–¥–µ–Ω—Ç–æ–≤")
    
    for index, row in df.iterrows():
        student_results = []
        processed_keys = set()
        
        for discipline_num in range(1, 4):
            discipline_col = f"–î–∏—Å—Ü–∏–ø–ª–∏–Ω–∞ {discipline_num}"
            grade_5_col = f"–û—Ü–µ–Ω–∫–∞ 5 –±–∞–ª–ª–æ–≤ –î–∏—Å—Ü–∏–ø–ª–∏–Ω–∞ {discipline_num}"
            
            if discipline_col not in df.columns or grade_5_col not in df.columns:
                continue
                
            discipline_value = str(row[discipline_col]).strip()
            grade_value = str(row[grade_5_col]).strip()
            
            if pd.isna(discipline_value) or pd.isna(grade_value) or discipline_value == 'nan' or grade_value == 'nan':
                continue
            
            lookup_key = f"{discipline_value}‚Äî{grade_value}"
            
            if lookup_key in processed_keys:
                continue
            
            if lookup_key in grade_mapping:
                skill_description = grade_mapping[lookup_key]
                
                short_name_col = f"–ù–∞–∑–≤–∞–Ω–∏–µ –î–∏—Å—Ü–∏–ø–ª–∏–Ω—ã {discipline_num}"
                if short_name_col in df.columns:
                    display_name = str(row[short_name_col]).strip()
                    formatted_discipline = display_name.capitalize() if display_name != 'nan' and display_name else discipline_value
                else:
                    formatted_discipline = discipline_value
                
                formatted_result = f"üìö {formatted_discipline}:\n{skill_description}"
                student_results.append(formatted_result)
                processed_keys.add(lookup_key)
        
        final_result = "\n\n".join(student_results) if student_results else "–ù–∞–≤—ã–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã."
        results.append(final_result)
    
    processing_log.append(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ")
    
    df_result = df.copy()
    df_result['–ò—Ç–æ–≥–æ–≤—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç'] = results
    
    columns_to_remove = [col for col in df_result.columns if col.startswith("–ù–∞–∑–≤–∞–Ω–∏–µ –î–∏—Å—Ü–∏–ø–ª–∏–Ω—ã ")]
    if columns_to_remove:
        df_result = df_result.drop(columns=columns_to_remove)
    
    return df_result, processing_log

# =============================================================================
# –§–£–ù–ö–¶–ò–ò –î–õ–Ø –ú–û–î–£–õ–Ø 5: –ê–ù–ê–õ–ò–¢–ò–ö–ê –ö–£–†–°–û–í
# =============================================================================

from io import StringIO
import time

def upload_students_to_supabase(supabase, student_data):
    """
    –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ –≤ —Ç–∞–±–ª–∏—Ü—É students —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ UPSERT
    """
    try:
        st.info("üë• –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ (UPSERT)...")
        records_for_upsert = []
        processed_emails = set()
        
        for _, row in student_data.iterrows():
            email = str(row.get('–ö–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∞—è –ø–æ—á—Ç–∞', '')).strip().lower()
            if not email or '@edu.hse.ru' not in email:
                continue
            if email in processed_emails:
                continue
            processed_emails.add(email)
                
            student_record = {
                '–∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∞—è_–ø–æ—á—Ç–∞': email,
                '—Ñ–∏–æ': str(row.get('–§–ò–û', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')).strip() or '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ',
                '—Ñ–∏–ª–∏–∞–ª_–∫–∞–º–ø—É—Å': str(row.get('–§–∏–ª–∏–∞–ª (–∫–∞–º–ø—É—Å)', '')) if pd.notna(row.get('–§–∏–ª–∏–∞–ª (–∫–∞–º–ø—É—Å)')) and str(row.get('–§–∏–ª–∏–∞–ª (–∫–∞–º–ø—É—Å)', '')).strip() else None,
                '—Ñ–∞–∫—É–ª—å—Ç–µ—Ç': str(row.get('–§–∞–∫—É–ª—å—Ç–µ—Ç', '')) if pd.notna(row.get('–§–∞–∫—É–ª—å—Ç–µ—Ç')) and str(row.get('–§–∞–∫—É–ª—å—Ç–µ—Ç', '')).strip() else None,
                '–æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è_–ø—Ä–æ–≥—Ä–∞–º–º–∞': str(row.get('–û–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≥—Ä–∞–º–º–∞', '')) if pd.notna(row.get('–û–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≥—Ä–∞–º–º–∞')) and str(row.get('–û–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≥—Ä–∞–º–º–∞', '')).strip() else None,
                '–≤–µ—Ä—Å–∏—è_–æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–æ–π_–ø—Ä–æ–≥—Ä–∞–º–º—ã': str(row.get('–í–µ—Ä—Å–∏—è –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–æ–π –ø—Ä–æ–≥—Ä–∞–º–º—ã', '')) if pd.notna(row.get('–í–µ—Ä—Å–∏—è –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–æ–π –ø—Ä–æ–≥—Ä–∞–º–º—ã')) and str(row.get('–í–µ—Ä—Å–∏—è –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–æ–π –ø—Ä–æ–≥—Ä–∞–º–º—ã', '')).strip() else None,
                '–≥—Ä—É–ø–ø–∞': str(row.get('–ì—Ä—É–ø–ø–∞', '')) if pd.notna(row.get('–ì—Ä—É–ø–ø–∞')) and str(row.get('–ì—Ä—É–ø–ø–∞', '')).strip() else None,
                '–∫—É—Ä—Å': str(row.get('–ö—É—Ä—Å', '')) if pd.notna(row.get('–ö—É—Ä—Å')) and str(row.get('–ö—É—Ä—Å', '')).strip() else None,
            }
            records_for_upsert.append(student_record)
        
        if not records_for_upsert:
            st.info("üìã –ù–µ—Ç –∑–∞–ø–∏—Å–µ–π –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
            return True
        
        st.info(f"üìã –ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–æ {len(records_for_upsert)} –∑–∞–ø–∏—Å–µ–π –¥–ª—è UPSERT")
        batch_size = 200
        total_processed = 0
        
        for i in range(0, len(records_for_upsert), batch_size):
            batch = records_for_upsert[i:i + batch_size]
            batch_num = (i // batch_size) + 1
            total_batches = ((len(records_for_upsert) - 1) // batch_size) + 1
            
            try:
                result = supabase.table('students').upsert(
                    batch,
                    on_conflict='–∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∞—è_–ø–æ—á—Ç–∞',
                    ignore_duplicates=False,
                    returning='minimal'
                ).execute()
                total_processed += len(batch)
                st.success(f"‚úÖ –ë–∞—Ç—á {batch_num}/{total_batches}: –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(batch)} –∑–∞–ø–∏—Å–µ–π")
            except Exception as e:
                error_str = str(e)
                if any(pat in error_str.lower() for pat in ["connection", "timeout", "ssl", "eof"]):
                    st.warning(f"‚ö†Ô∏è –°–µ—Ç–µ–≤–∞—è –æ—à–∏–±–∫–∞ –≤ –±–∞—Ç—á–µ {batch_num}, –ø–æ–≤—Ç–æ—Ä...")
                    time.sleep(2)
                    try:
                        result = supabase.table('students').upsert(batch, on_conflict='–∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∞—è_–ø–æ—á—Ç–∞').execute()
                        total_processed += len(batch)
                        st.success(f"‚úÖ –ë–∞—Ç—á {batch_num} (–ø–æ—Å–ª–µ –ø–æ–≤—Ç–æ—Ä–∞)")
                    except Exception as retry_error:
                        st.error(f"‚ùå –ë–∞—Ç—á {batch_num} –Ω–µ —É–¥–∞–ª—Å—è –ø–æ—Å–ª–µ –ø–æ–≤—Ç–æ—Ä–∞: {retry_error}")
                        return False
                else:
                    st.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ –±–∞—Ç—á–µ {batch_num}: {e}")
                    return False
        
        st.success(f"üéâ UPSERT –∑–∞–≤–µ—Ä—à—ë–Ω! –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {total_processed} –∑–∞–ø–∏—Å–µ–π")
        return True
    except Exception as e:
        st.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ UPSERT —Å—Ç—É–¥–µ–Ω—Ç–æ–≤: {e}")
        return False

def load_student_list_file(uploaded_file) -> pd.DataFrame:
    """
    –ó–∞–≥—Ä—É–∑–∫–∞ —Å–ø–∏—Å–∫–∞ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ –∏–∑ —Ñ–∞–π–ª–∞ Excel –∏–ª–∏ CSV
    """
    try:
        file_name = uploaded_file.name.lower()
        if file_name.endswith(('.xlsx', '.xls')):
            df = pd.read_excel(uploaded_file)
        elif file_name.endswith('.csv'):
            content = uploaded_file.getvalue()
            try:
                df = pd.read_csv(StringIO(content.decode('utf-16')), sep='\t')
            except (UnicodeDecodeError, pd.errors.ParserError):
                try:
                    df = pd.read_csv(StringIO(content.decode('utf-8')))
                except UnicodeDecodeError:
                    df = pd.read_csv(StringIO(content.decode('cp1251')))
        else:
            st.error("–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞")
            return pd.DataFrame()

        required_columns = {
            '–§–ò–û': ['—Ñ–∏–æ', '—Ñio', '–∏–º—è', 'name'],
            '–ö–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∞—è –ø–æ—á—Ç–∞': ['–∞–¥—Ä–µ—Å —ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω–æ–π –ø–æ—á—Ç—ã', '–∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∞—è –ø–æ—á—Ç–∞', 'email', '–ø–æ—á—Ç–∞', 'e-mail'],
            '–§–∏–ª–∏–∞–ª (–∫–∞–º–ø—É—Å)': ['—Ñ–∏–ª–∏–∞–ª', '–∫–∞–º–ø—É—Å', 'campus'],
            '–§–∞–∫—É–ª—å—Ç–µ—Ç': ['—Ñ–∞–∫—É–ª—å—Ç–µ—Ç', 'faculty'],
            '–û–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≥—Ä–∞–º–º–∞': ['–æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≥—Ä–∞–º–º–∞', '–ø—Ä–æ–≥—Ä–∞–º–º–∞', 'educational program'],
            '–í–µ—Ä—Å–∏—è –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–æ–π –ø—Ä–æ–≥—Ä–∞–º–º—ã': ['–≤–µ—Ä—Å–∏—è –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–æ–π –ø—Ä–æ–≥—Ä–∞–º–º—ã', '–≤–µ—Ä—Å–∏—è –ø—Ä–æ–≥—Ä–∞–º–º—ã', 'program version', 'version'],
            '–ì—Ä—É–ø–ø–∞': ['–≥—Ä—É–ø–ø–∞', 'group'],
            '–ö—É—Ä—Å': ['–∫—É—Ä—Å', 'course']
        }

        found_columns = {}
        df_columns_lower = [str(col).lower().strip() for col in df.columns]
        for target_col, possible_names in required_columns.items():
            for col_idx, col_name in enumerate(df_columns_lower):
                if any(possible_name in col_name for possible_name in possible_names):
                    found_columns[target_col] = df.columns[col_idx]
                    break

        result_df = pd.DataFrame()
        for target_col, source_col in found_columns.items():
            if source_col in df.columns:
                result_df[target_col] = df[source_col]

        if '–î–∞–Ω–Ω—ã–µ –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ' in df.columns:
            user_data = df['–î–∞–Ω–Ω—ã–µ –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ'].astype(str)
            parsed_data = user_data.str.split(';', expand=True)
            if len(parsed_data.columns) >= 4:
                result_df['–§–∞–∫—É–ª—å—Ç–µ—Ç'] = parsed_data[0]
                result_df['–û–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≥—Ä–∞–º–º–∞'] = parsed_data[1] 
                result_df['–ö—É—Ä—Å'] = parsed_data[2]
                result_df['–ì—Ä—É–ø–ø–∞'] = parsed_data[3]

        for required_col in required_columns.keys():
            if required_col not in result_df.columns:
                if required_col == '–§–ò–û':
                    result_df[required_col] = None
                else:
                    result_df[required_col] = ''

        if '–ö–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∞—è –ø–æ—á—Ç–∞' in result_df.columns:
            result_df = result_df[result_df['–ö–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∞—è –ø–æ—á—Ç–∞'].astype(str).str.contains('@edu.hse.ru', na=False)]
            result_df['–ö–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∞—è –ø–æ—á—Ç–∞'] = pd.Series(result_df['–ö–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∞—è –ø–æ—á—Ç–∞']).astype(str).str.lower().str.strip()
        return result_df
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Å–ø–∏—Å–∫–∞ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤: {e}")
        return pd.DataFrame()

def upload_course_data_to_supabase(supabase, course_data, course_name):
    """–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –æ–¥–Ω–æ–≥–æ –∫—É—Ä—Å–∞ –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â—É—é —Ç–∞–±–ª–∏—Ü—É"""
    try:
        table_mapping = {'–¶–ì': 'course_cg', '–ü–∏—Ç–æ–Ω': 'course_python', '–ê–Ω–¥–∞–Ω': 'course_analysis'}
        table_name = table_mapping.get(course_name)
        if not table_name:
            st.error(f"‚ùå –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –∫—É—Ä—Å: {course_name}")
            return False
            
        st.info(f"üìà –ó–∞–≥—Ä—É–∑–∫–∞ –∫—É—Ä—Å–∞ {course_name} –≤ {table_name}...")
        if course_data is None or course_data.empty:
            st.warning(f"‚ö†Ô∏è –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∫—É—Ä—Å–∞ {course_name}")
            return True

        records_for_upsert = []
        processed_emails = set()
        
        for _, row in course_data.iterrows():
            email = str(row.get('–ö–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∞—è –ø–æ—á—Ç–∞', '')).strip().lower()
            if not email or '@edu.hse.ru' not in email:
                continue
            if email in processed_emails:
                continue
                
            processed_emails.add(email)
            
            percent_col = f'–ü—Ä–æ—Ü–µ–Ω—Ç_{course_name}'
            progress_value = None
            if percent_col in row and pd.notna(row[percent_col]) and row[percent_col] != '':
                try:
                    progress_value = float(row[percent_col])
                except (ValueError, TypeError):
                    progress_value = None
            
            records_for_upsert.append({
                '–∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∞—è_–ø–æ—á—Ç–∞': email,
                '–ø—Ä–æ—Ü–µ–Ω—Ç_–∑–∞–≤–µ—Ä—à–µ–Ω–∏—è': progress_value
            })
        
        if not records_for_upsert:
            st.info(f"üìã –ù–µ—Ç –∑–∞–ø–∏—Å–µ–π –¥–ª—è –∫—É—Ä—Å–∞ {course_name}")
            return True

        batch_size = 200
        total_processed = 0
        for i in range(0, len(records_for_upsert), batch_size):
            batch = records_for_upsert[i:i + batch_size]
            batch_num = (i // batch_size) + 1
            try:
                supabase.table(table_name).upsert(batch, on_conflict='–∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∞—è_–ø–æ—á—Ç–∞').execute()
                total_processed += len(batch)
                st.success(f"‚úÖ –ö—É—Ä—Å {course_name} - –±–∞—Ç—á {batch_num}: {len(batch)} –∑–∞–ø–∏—Å–µ–π")
            except Exception as e:
                st.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∫—É—Ä—Å–∞ {course_name}, –±–∞—Ç—á {batch_num}: {e}")
                return False

        st.success(f"üéâ –ö—É—Ä—Å {course_name}: {total_processed} –∑–∞–ø–∏—Å–µ–π –∑–∞–≥—Ä—É–∂–µ–Ω–æ")
        return True
    except Exception as e:
        st.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∫—É—Ä—Å–∞ {course_name}: {e}")
        return False

def extract_course_data(uploaded_file, course_name):
    """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∫—É—Ä—Å–∞ –∏–∑ —Ñ–∞–π–ª–∞"""
    try:
        file_name = uploaded_file.name.lower()
        if file_name.endswith(('.xlsx', '.xls')):
            df = pd.read_excel(uploaded_file)
        elif file_name.endswith('.csv'):
            content = uploaded_file.getvalue()
            try:
                df = pd.read_csv(StringIO(content.decode('utf-16')), sep='\t')
            except (UnicodeDecodeError, pd.errors.ParserError):
                try:
                    df = pd.read_csv(StringIO(content.decode('utf-8')))
                except UnicodeDecodeError:
                    df = pd.read_csv(StringIO(content.decode('cp1251')))
        else:
            st.error(f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞ –¥–ª—è –∫—É—Ä—Å–∞ {course_name}")
            return None

        email_column = None
        possible_email_names = ['–ê–¥—Ä–µ—Å —ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω–æ–π –ø–æ—á—Ç—ã', '–ö–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∞—è –ø–æ—á—Ç–∞', 'Email', '–ü–æ—á—Ç–∞', 'E-mail']
        for col_name in possible_email_names:
            if col_name in df.columns:
                email_column = col_name
                break
        if email_column is None:
            st.error(f"–°—Ç–æ–ª–±–µ—Ü —Å email –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ —Ñ–∞–π–ª–µ {course_name}")
            return None

        cg_excluded_keywords = [
            'take away', '—à–ø–∞—Ä–≥–∞–ª–∫–∞', '–∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è', '–æ–±—â–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è', '–ø—Ä–æ–º–æ-—Ä–æ–ª–∏–∫',
            '–ø–æ–¥–¥–µ—Ä–∂–∫–∞ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤', '–ø–æ—è—Å–Ω–µ–Ω–∏–µ', '—Å–ª—É—á–∞–π–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç –¥–ª—è —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ —Å –æ–≤–∑',
            '–º–∞—Ç–µ—Ä–∏–∞–ª—ã –ø–æ –º–æ–¥—É–ª—é', '–∫–æ–ø–∏—è', '–¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç', '—Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏—è',
            '–¥–µ–º–æ-–≤–µ—Ä—Å–∏—è', '–ø—Ä–∞–≤–∏–ª–∞ –ø—Ä–æ–≤–µ–¥–µ–Ω–∏—è –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ–≥–æ —ç–∫–∑–∞–º–µ–Ω–∞',
            '–ø–æ—Ä—è–¥–æ–∫ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ –∏ –ø—Ä–æ–≤–µ–¥–µ–Ω–∏—è –Ω–µ–∑–∞–≤–∏—Å–∏–º—ã—Ö —ç–∫–∑–∞–º–µ–Ω–æ–≤',
            '–∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π —Ç—Ä–µ–Ω–∞–∂–µ—Ä –ø—Ä–∞–≤–∏–ª –Ω—ç', '–ø–µ—Ä–µ—Å–¥–∞—á–∏ –≤ —Å–µ–Ω—Ç—è–±—Ä–µ', '–Ω–µ–∑—Ä—è—á–∏—Ö –∏ —Å–ª–∞–±–æ–≤–∏–¥—è—â–∏—Ö',
            '–ø—Ä–æ–µ–∫—Ç—ã —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ tei', '—Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–π —Ç–µ—Å—Ç', '–∫–ª—é—á–µ–≤—ã–µ –ø—Ä–∏–Ω—Ü–∏–ø—ã tei',
            '–±–∞–∑–æ–≤—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ tie', '—Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ –º–æ–¥—É–ª–∏ tei', '–±—É–¥—É—Ç –∏–¥–µ–Ω—Ç–∏—á–Ω—ã–º–∏',
            '–æ–ø—Ä–æ—Å', '—Ç–µ—Å—Ç –ø–æ –º–æ–¥—É–ª—é', '–∞–Ω–∫–µ—Ç–∞', 'user information', '—Å—Ç—Ä–∞–Ω–∞', 'user_id', '–¥–∞–Ω–Ω—ã–µ –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ'
        ]

        excluded_count = 0
        completed_columns = []
        timestamp_columns = []

        for col in df.columns:
            if col not in ['Unnamed: 0', email_column, '–î–∞–Ω–Ω—ã–µ –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ', 'User information', '–°—Ç—Ä–∞–Ω–∞']:
                if course_name == '–¶–ì':
                    should_exclude = False
                    col_str = str(col).strip().lower()
                    for excluded_keyword in cg_excluded_keywords:
                        if excluded_keyword.lower() in col_str:
                            should_exclude = True
                            excluded_count += 1
                            break
                    if should_exclude:
                        continue

                if not col.startswith('Unnamed:') and len(str(col).strip()) > 0:
                    sample_values = df[col].dropna().astype(str).head(100)
                    if any('–í—ã–ø–æ–ª–Ω–µ–Ω–æ' in str(val) or '–≤—ã–ø–æ–ª–Ω–µ–Ω–æ' in str(val).lower() for val in sample_values):
                        if not all(str(val) == '–ù–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–æ' for val in sample_values if pd.notna(val)):
                            completed_columns.append(col)
                elif col.startswith('Unnamed:') and col != 'Unnamed: 0':
                    sample_values = df[col].dropna().astype(str).head(20)
                    for val in sample_values:
                        val_str = str(val).strip()
                        if any(pattern in val_str for pattern in ['2020', '2021', '2022', '2023', '2024']) and ':' in val_str:
                            timestamp_columns.append(col)
                            break

        if timestamp_columns:
            completion_data = []
            for idx, row in df.iterrows():
                email_val = row[email_column]
                if pd.isna(email_val) or '@edu.hse.ru' not in str(email_val).lower():
                    continue
                total_tasks = len(timestamp_columns)
                completed_tasks = 0
                for col in timestamp_columns:
                    cell_val = row[col]
                    val_str = str(cell_val).strip() if not pd.isna(cell_val) else ''
                    if val_str and val_str != 'nan' and val_str != '':
                        if any(pattern in val_str for pattern in ['2020', '2021', '2022', '2023', '2024']) and ':' in val_str:
                            completed_tasks += 1
                percentage = (completed_tasks / total_tasks * 100) if total_tasks > 0 else 0
                completion_data.append({'email': str(email_val).lower().strip(), 'percentage': percentage})
            if completion_data:
                result_df = pd.DataFrame(completion_data)
                result_df.columns = ['–ö–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∞—è –ø–æ—á—Ç–∞', f'–ü—Ä–æ—Ü–µ–Ω—Ç_{course_name}']
                st.success(f"‚úÖ –†–∞—Å—Å—á–∏—Ç–∞–Ω –ø—Ä–æ—Ü–µ–Ω—Ç –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –¥–ª—è {len(result_df)} —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ –∫—É—Ä—Å–∞ {course_name}")
                return result_df

        elif completed_columns:
            completion_data = []
            for idx, row in df.iterrows():
                email_val = row[email_column]
                if pd.isna(email_val) or '@edu.hse.ru' not in str(email_val).lower():
                    continue
                total_tasks = 0
                completed_tasks = 0
                for col in completed_columns:
                    cell_val = row[col]
                    val = str(cell_val).strip() if not pd.isna(cell_val) else ''
                    if val and val != 'nan':
                        total_tasks += 1
                        if '–í—ã–ø–æ–ª–Ω–µ–Ω–æ' in val or '–≤—ã–ø–æ–ª–Ω–µ–Ω–æ' in val.lower():
                            completed_tasks += 1
                percentage = (completed_tasks / total_tasks * 100) if total_tasks > 0 else 0
                completion_data.append({'email': str(email_val).lower().strip(), 'percentage': percentage})
            if completion_data:
                result_df = pd.DataFrame(completion_data)
                result_df.columns = ['–ö–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∞—è –ø–æ—á—Ç–∞', f'–ü—Ä–æ—Ü–µ–Ω—Ç_{course_name}']
                st.success(f"‚úÖ –†–∞—Å—Å—á–∏—Ç–∞–Ω –ø—Ä–æ—Ü–µ–Ω—Ç –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –¥–ª—è {len(result_df)} —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ –∫—É—Ä—Å–∞ {course_name}")
                return result_df

        st.warning(f"–ù–µ –Ω–∞–π–¥–µ–Ω–æ –¥–∞–Ω–Ω—ã—Ö –æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏ –¥–ª—è –∫—É—Ä—Å–∞ {course_name}")
        return None
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö –∫—É—Ä—Å–∞ {course_name}: {e}")
        return None

# =============================================================================
# –û–°–ù–û–í–ù–û–ï –ü–†–ò–õ–û–ñ–ï–ù–ò–ï
# =============================================================================

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è"""
    
    # =============================================================================
    # APPLE-–°–û–í–ú–ï–°–¢–ò–ú–´–ô UI/UX LAYER (–ë–ï–ó –ò–ó–ú–ï–ù–ï–ù–ò–Ø –õ–û–ì–ò–ö–ò)
    # =============================================================================
    st.markdown("""
    <style>
        /* Apple-style typography */
        h1, h2, h3, h4 {
            font-weight: 600;
            letter-spacing: -0.02em;
            line-height: 1.2;
            color: #e0e0e6;
        }
        h1 {
            font-size: 2.25rem;
            margin-bottom: 0.5rem;
        }
        h2 {
            font-size: 1.5rem;
            margin-top: 1.5rem;
            margin-bottom: 1rem;
        }
        p, li, .stMarkdown {
            color: #c6c6cc;
            line-height: 1.6;
        }
        /* Apple-style buttons */
        .stButton > button {
            border-radius: 12px;
            padding: 8px 20px;
            font-weight: 500;
            border: none;
            background-color: #4a86e8;
            color: white;
            transition: background-color 0.2s ease;
        }
        .stButton > button:hover {
            background-color: #5a96f8;
        }
        /* Apple-style info boxes */
        .stAlert {
            border-radius: 12px;
            padding: 14px 18px;
            margin: 16px 0;
        }
        /* Sidebar refinement */
        [data-testid="stSidebar"] {
            background-color: #2a2a30 !important;
        }
        [data-testid="stSidebar"] h2,
        [data-testid="stSidebar"] p,
        [data-testid="stSidebar"] label {
            color: #e0e0e6 !important;
        }
        /* Consistent spacing */
        .block-container {
            padding-top: 2rem;
            padding-bottom: 2rem;
        }
        hr {
            margin: 1.5rem 0;
            border-color: #3a3a42;
        }
        /* Footer */
        footer {
            visibility: hidden;
        }
        .custom-footer {
            text-align: center;
            color: #888892;
            font-size: 0.85rem;
            margin-top: 2rem;
            padding-top: 1.5rem;
            border-top: 1px solid #3a3a42;
        }
    </style>
    """, unsafe_allow_html=True)

    # –ó–∞–≥–æ–ª–æ–≤–æ–∫ (Apple-style: –±–µ–∑ —ç–º–æ–¥–∑–∏, —Å caption)
    st.title("DataCulture Platform")
    st.caption("–û–±—ä–µ–¥–∏–Ω—ë–Ω–Ω–∞—è –ø–ª–∞—Ç—Ñ–æ—Ä–º–∞ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ Data Culture @ HSE University")
    st.caption("–î–ª—è —Å–∞–º—ã—Ö –ª—É—á—à–∏—Ö —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤ –ø—Ä–æ–µ–∫—Ç–∞ –æ—Ç –¢–∏–º–æ—à–∫–∏")
    st.markdown("---")

    # –ë–æ–∫–æ–≤–∞—è –ø–∞–Ω–µ–ª—å –Ω–∞–≤–∏–≥–∞—Ü–∏–∏
    with st.sidebar:
        st.image(LOGO_URL, width=160)  # —É–º–µ–Ω—å—à–µ–Ω–æ –¥–æ 160px –¥–ª—è –ª—É—á—à–µ–π –ø—Ä–æ–ø–æ—Ä—Ü–∏–∏
        st.markdown("<br>", unsafe_allow_html=True)
        tool = st.navigation(
            "–ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç",
            [
                "–ü–µ—Ä–µ–∑–∞—á–µ—Ç –æ—Ü–µ–Ω–æ–∫",
                "–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä HTML-–∫–∞—Ä—Ç–æ—á–µ–∫",
                "–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä —Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç–æ–≤",
                "–û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–µ—Ä–µ—Å–¥–∞—á –≤–Ω–µ—à–Ω–µ–π –æ—Ü–µ–Ω–∫–∏",
                "–ê–Ω–∞–ª–∏—Ç–∏–∫–∞ –∫—É—Ä—Å–æ–≤",
                "–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤"
            ],
            index=0
        )
        st.markdown("<br>", unsafe_allow_html=True)
        st.markdown("### ‚ÑπÔ∏è –û –ø–ª–∞—Ç—Ñ–æ—Ä–º–µ")
        st.info("""
        **DataCulture Platform** –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç —à–µ—Å—Ç—å –∫–ª—é—á–µ–≤—ã—Ö –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤:
        1. **–ü–µ—Ä–µ–∑–∞—á–µ—Ç –æ—Ü–µ–Ω–æ–∫** ‚Äî –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π —Ä–∞—Å—á–µ—Ç –∏—Ç–æ–≥–æ–≤—ã—Ö –æ—Ü–µ–Ω–æ–∫  
        2. **–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –∫–∞—Ä—Ç–æ—á–µ–∫** ‚Äî —Å–æ–∑–¥–∞–Ω–∏–µ HTML-—Ä–∞—Å—Å—ã–ª–æ–∫ –≤ —Ñ–∏—Ä–º–µ–Ω–Ω–æ–º —Å—Ç–∏–ª–µ –í–®–≠  
        3. **–°–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç—ã** ‚Äî –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≤—ã–¥–∞—á–∏ —Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç–æ–≤  
        4. **–ü–µ—Ä–µ—Å–¥–∞—á–∏** ‚Äî –æ–±—Ä–∞–±–æ—Ç–∫–∞ –ø–µ—Ä–µ—Å–¥–∞—á –≤–Ω–µ—à–Ω–µ–π –æ—Ü–µ–Ω–∫–∏  
        5. **–ê–Ω–∞–ª–∏—Ç–∏–∫–∞ –∫—É—Ä—Å–æ–≤** ‚Äî –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏ –∑–∞–≥—Ä—É–∑–∫–∞ –∞–Ω–∞–ª–∏—Ç–∏–∫–∏ –∫—É—Ä—Å–æ–≤ –≤ Supabase  
        6. **–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤** ‚Äî –∑–∞–≥—Ä—É–∑–∫–∞ –∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ –≤ Supabase  
        """)

    # =============================================================================
    # –ú–û–î–£–õ–ò (–±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π –≤ –ª–æ–≥–∏–∫–µ ‚Äî —Ç–æ–ª—å–∫–æ –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏–µ —É–∂–µ —É—á—Ç–µ–Ω–æ –≤—ã—à–µ)
    # =============================================================================
    if tool == "–ü–µ—Ä–µ–∑–∞—á–µ—Ç –æ—Ü–µ–Ω–æ–∫":
        st.header("üìä –°–µ—Ä–≤–∏—Å –ø–µ—Ä–µ–∑–∞—á–µ—Ç–∞ –æ—Ü–µ–Ω–æ–∫")
        st.markdown("""
        –ó–∞–≥—Ä—É–∑–∏—Ç–µ Excel –∏–ª–∏ CSV —Ñ–∞–π–ª —Å –¥–∞–Ω–Ω—ã–º–∏ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ —Ä–∞—Å—á–µ—Ç–∞ –∏—Ç–æ–≥–æ–≤—ã—Ö –æ—Ü–µ–Ω–æ–∫.
        **–¢—Ä–µ–±—É–µ–º—ã–µ –∫–æ–ª–æ–Ω–∫–∏:**
        - –ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –ù–≠
        - –û—Ü–µ–Ω–∫–∞ –ù–≠
        - –û—Ü–µ–Ω–∫–∞ –¥–∏—Å—Ü–∏–ø–ª–∏–Ω—ã-–ø—Ä–µ—Ä–µ–∫–≤–∏–∑–∏—Ç–∞
        - –í–Ω–µ—à–Ω–µ–µ –∏–∑–º–µ—Ä–µ–Ω–∏–µ —Ü–∏—Ñ—Ä–æ–≤—ã—Ö –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–π (–í—Ö–æ–¥–Ω–æ–π, –ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–π, –ò—Ç–æ–≥–æ–≤—ã–π –∫–æ–Ω—Ç—Ä–æ–ª—å)
        """)
        uploaded_file = st.file_uploader(
            "–í—ã–±–µ—Ä–∏—Ç–µ —Ñ–∞–π–ª –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏",
            type=['xlsx', 'csv'],
            key="grade_file"
        )
        if uploaded_file is not None:
            file_name = uploaded_file.name
            processing_mode = st.radio(
                "–†–µ–∂–∏–º –æ–±—Ä–∞–±–æ—Ç–∫–∏:",
                ("–ü–µ—Ä–µ–∑–∞—á–µ—Ç –ë–ï–ó –¥–∏–Ω–∞–º–∏–∫–∏", "–ü–µ—Ä–µ–∑–∞—á–µ—Ç –° –¥–∏–Ω–∞–º–∏–∫–æ–π"),
                help="""
                - **–ë–ï–ó –¥–∏–Ω–∞–º–∏–∫–∏**: –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –ø–µ—Ä–µ–∑–∞—á–µ—Ç –ø–æ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –æ—Ü–µ–Ω–∫–µ.
                - **–° –¥–∏–Ω–∞–º–∏–∫–æ–π**: –ï—Å–ª–∏ –æ—Ü–µ–Ω–∫–∞ –ø–∞–¥–∞–µ—Ç –±–æ–ª–µ–µ —á–µ–º –Ω–∞ 1 –±–∞–ª–ª –º–µ–∂–¥—É —ç—Ç–∞–ø–∞–º–∏, –ø–µ—Ä–µ–∑–∞—á–µ—Ç –±–ª–æ–∫–∏—Ä—É–µ—Ç—Å—è.
                """
            )
            if st.button("üöÄ –û–±—Ä–∞–±–æ—Ç–∞—Ç—å —Ñ–∞–π–ª", type="primary"):
                with st.spinner("–û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö‚Ä¶"):
                    try:
                        if file_name.endswith('.xlsx'):
                            df_initial = pd.read_excel(uploaded_file, engine='openpyxl')
                        else:
                            df_initial = pd.read_csv(uploaded_file)
                        use_dynamics_flag = (processing_mode == "–ü–µ—Ä–µ–∑–∞—á–µ—Ç –° –¥–∏–Ω–∞–º–∏–∫–æ–π")
                        result_df = process_grade_recalculation(df_initial, use_dynamics=use_dynamics_flag)
                        st.success("‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
                        st.subheader("üìä –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–π –ø—Ä–æ—Å–º–æ—Ç—Ä")
                        st.dataframe(result_df.head(10), use_container_width=True)
                        output = io.BytesIO()
                        with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
                            result_df.to_excel(writer, index=False, sheet_name='–†–µ–∑—É–ª—å—Ç–∞—Ç')
                        excel_data = output.getvalue()
                        current_date = datetime.now().strftime('%d-%m-%y')
                        download_filename = f"–†–µ–∑—É–ª—å—Ç–∞—Ç_{file_name.split('.')[0]}_{current_date}.xlsx"
                        st.download_button(
                            label="üì• –°–∫–∞—á–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç",
                            data=excel_data,
                            file_name=download_filename,
                            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                        )
                    except KeyError as e:
                        st.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä–µ —Ñ–∞–π–ª–∞: {e}")
                    except Exception as e:
                        st.error(f"‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {e}")

    elif tool == "–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä HTML-–∫–∞—Ä—Ç–æ—á–µ–∫":
        st.header("üéì –ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –∫–∞—Ä—Ç–æ—á–µ–∫ –ù–ò–£ –í–®–≠")
        st.markdown("""
        –°–æ–∑–¥–∞–π—Ç–µ HTML-–∫–∞—Ä—Ç–æ—á–∫—É —Ä–∞—Å—Å—ã–ª–∫–∏ –≤ —Ñ–∏—Ä–º–µ–Ω–Ω–æ–º —Å—Ç–∏–ª–µ –í–®–≠ —Å –ø–æ–º–æ—â—å—é –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞.
        **–ö–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:**
        1. –í–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç –æ–±—ä—è–≤–ª–µ–Ω–∏—è –∏–ª–∏ –Ω–æ–≤–æ—Å—Ç–∏
        2. –ù–∞–∂–º–∏—Ç–µ –∫–Ω–æ–ø–∫—É –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
        3. –ü–æ–ª—É—á–∏—Ç–µ –≥–æ—Ç–æ–≤—ã–π HTML-–∫–æ–¥ –∏ –ø—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä
        """)
        try:
            has_api_key = "NEBIUS_API_KEY" in st.secrets
        except FileNotFoundError:
            has_api_key = False
        if not has_api_key:
            st.error("‚ùå NEBIUS_API_KEY –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω. –û–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä—É.")
            st.info("üí° –°–æ–∑–¥–∞–π—Ç–µ —Ñ–∞–π–ª `.streamlit/secrets.toml` —Å –≤–∞—à–∏–º API –∫–ª—é—á–æ–º")
            st.stop()
        user_text = st.text_area(
            "–í–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç –æ–±—ä—è–≤–ª–µ–Ω–∏—è:",
            height=250,
            placeholder="–í—Å—Ç–∞–≤—å—Ç–µ —Å—é–¥–∞ —Ç–µ–∫—Å—Ç –ø–∏—Å—å–º–∞ –∏–ª–∏ –Ω–æ–≤–æ—Å—Ç–∏..."
        )
        if st.button("‚ú® –°—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å HTML", type="primary"):
            if not user_text.strip():
                st.warning("‚ö†Ô∏è –í–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏")
            else:
                with st.spinner("–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–∞—Ä—Ç–æ—á–∫–∏‚Ä¶"):
                    try:
                        client = get_nebius_client()
                        html_code = generate_hse_html(client, user_text)
                        st.success("‚úÖ –ö–∞—Ä—Ç–æ—á–∫–∞ —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω–∞!")
                        col1, col2 = st.columns([1, 1])
                        with col1:
                            st.subheader("üìÑ HTML-–∫–æ–¥")
                            st.code(html_code, language="html")
                            st.download_button(
                                label="üíæ –°–∫–∞—á–∞—Ç—å HTML",
                                data=html_code.encode("utf-8"),
                                file_name="hse_card.html",
                                mime="text/html"
                            )
                        with col2:
                            st.subheader("üåê –ü—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä")
                            import streamlit.components.v1 as components
                            components.html(html_code, height=800, scrolling=True)
                    except Exception as e:
                        st.error(f"‚ùå –û—à–∏–±–∫–∞: {e}")

    elif tool == "–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä —Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç–æ–≤":
        st.header("üìú –°–∏—Å—Ç–µ–º–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç–æ–≤")
        st.markdown("""
        –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö —ç–∫–∑–∞–º–µ–Ω–æ–≤ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ –¥–ª—è —Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç–æ–≤.
        **–¢—Ä–µ–±—É–µ—Ç—Å—è –¥–≤–∞ —Ñ–∞–π–ª–∞:**
        1. Excel —Å –¥–∞–Ω–Ω—ã–º–∏ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ (–∫–æ–ª–æ–Ω–∫–∏: –£—á–∞—â–∏–π—Å—è, –î–∏—Å—Ü–∏–ø–ª–∏–Ω–∞ 1/2/3, –û—Ü–µ–Ω–∫–∞ 5 –±–∞–ª–ª–æ–≤)
        2. Excel —Å–æ —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–æ–º –Ω–∞–≤—ã–∫–æ–≤ (–∫–æ–ª–æ–Ω–∫–∏: –î–∏—Å—Ü–∏–ø–ª–∏–Ω–∞, –£—Ä–æ–≤–µ–Ω—å_–æ—Ü–µ–Ω–∫–∏, –û–ø–∏—Å–∞–Ω–∏–µ_–Ω–∞–≤—ã–∫–æ–≤)
        """)
        with st.sidebar:
            st.markdown("---")
            st.markdown("### üì• –°–∫–∞—á–∞—Ç—å –ø—Ä–∏–º–µ—Ä—ã")
            current_dir = os.path.dirname(os.path.abspath(__file__))
            excel_example_path = os.path.join(current_dir, '–°–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç—ã –ø—Ä–∏–º–µ—Ä.xlsx')
            if os.path.exists(excel_example_path):
                with open(excel_example_path, 'rb') as example_file:
                    excel_example_data = example_file.read()
                st.download_button(
                    label="üìä –ü—Ä–∏–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö —Å—Ç—É–¥–µ–Ω—Ç–æ–≤",
                    data=excel_example_data,
                    file_name="–°–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç—ã_–ø—Ä–∏–º–µ—Ä.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    use_container_width=True
                )
            skills_example_path = os.path.join(current_dir, '–∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ_–Ω–∞–≤—ã–∫–∏.xlsx')
            if os.path.exists(skills_example_path):
                with open(skills_example_path, 'rb') as skills_file:
                    skills_data = skills_file.read()
                st.download_button(
                    label="üìÑ –°–ø—Ä–∞–≤–æ—á–Ω–∏–∫ –Ω–∞–≤—ã–∫–æ–≤",
                    data=skills_data,
                    file_name="–∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ_–Ω–∞–≤—ã–∫–∏.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    use_container_width=True
                )
            st.markdown("---")
            st.markdown("### üìã –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ —Ñ–∞–π–ª–∞–º")
            st.markdown("""
            **üìä –î–∞–Ω–Ω—ã–µ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤:**
            - `–£—á–∞—â–∏–π—Å—è`
            - `–ù–∞–∑–≤–∞–Ω–∏–µ –î–∏—Å—Ü–∏–ø–ª–∏–Ω—ã 1/2/3`
            - `–î–∏—Å—Ü–∏–ø–ª–∏–Ω–∞ 1/2/3`
            - `–û—Ü–µ–Ω–∫–∞ 5 –±–∞–ª–ª–æ–≤ –î–∏—Å—Ü–∏–ø–ª–∏–Ω–∞ 1/2/3`
            **üìÑ –°–ø—Ä–∞–≤–æ—á–Ω–∏–∫ –Ω–∞–≤—ã–∫–æ–≤:**
            - `–î–∏—Å—Ü–∏–ø–ª–∏–Ω–∞`
            - `–£—Ä–æ–≤–µ–Ω—å_–æ—Ü–µ–Ω–∫–∏`
            - `–û–ø–∏—Å–∞–Ω–∏–µ_–Ω–∞–≤—ã–∫–æ–≤`
            üí° **–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –ø—Ä–∏–º–µ—Ä—ã –≤—ã—à–µ!**
            """)
        col1, col2 = st.columns([1, 1])
        with col1:
            st.subheader("üìä –î–∞–Ω–Ω—ã–µ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤")
            excel_file = st.file_uploader(
                "–í—ã–±–µ—Ä–∏—Ç–µ Excel —Ñ–∞–π–ª",
                type=['xlsx', 'xls'],
                key="students_file"
            )
        with col2:
            st.subheader("üìÑ –°–ø—Ä–∞–≤–æ—á–Ω–∏–∫ –Ω–∞–≤—ã–∫–æ–≤")
            skills_file = st.file_uploader(
                "–í—ã–±–µ—Ä–∏—Ç–µ Excel —Ñ–∞–π–ª",
                type=['xlsx', 'xls'],
                key="skills_file"
            )
        if excel_file and skills_file:
            try:
                with st.spinner("üì• –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–æ–≤‚Ä¶"):
                    df = pd.read_excel(excel_file)
                    skills_content = skills_file.read()
                    grade_mapping = load_reference_data(skills_content)
                st.success("‚úÖ –§–∞–π–ª—ã —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã!")
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("–°—Ç—É–¥–µ–Ω—Ç–æ–≤", len(df))
                with col2:
                    st.metric("–ö–æ–ª–æ–Ω–æ–∫", len(df.columns))
                with col3:
                    st.metric("–ù–∞–≤—ã–∫–æ–≤ –≤ —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–µ", len(grade_mapping))
                with st.expander("üëÄ –ü—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä –¥–∞–Ω–Ω—ã—Ö"):
                    st.dataframe(df.head(), use_container_width=True)
                if st.button("üöÄ –û–±—Ä–∞–±–æ—Ç–∞—Ç—å –¥–∞–Ω–Ω—ã–µ", type="primary"):
                    with st.spinner("‚öôÔ∏è –û–±—Ä–∞–±–æ—Ç–∫–∞‚Ä¶"):
                        result_df, processing_log = process_student_data(df, grade_mapping)
                    st.success("‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
                    st.subheader("üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã")
                    st.dataframe(result_df, use_container_width=True)
                    output = io.BytesIO()
                    with pd.ExcelWriter(output, engine='openpyxl', mode='w') as writer:
                        result_df.to_excel(writer, index=False)
                    output.seek(0)
                    st.download_button(
                        label="üì• –°–∫–∞—á–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã",
                        data=output.getvalue(),
                        file_name="–°–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç—ã_—Å_—Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏.xlsx",
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                    )
            except Exception as e:
                st.error(f"‚ùå –û—à–∏–±–∫–∞: {str(e)}")
        elif excel_file:
            st.info("üìÑ –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ç–∞–∫–∂–µ —Ñ–∞–π–ª —Å–æ —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–æ–º –Ω–∞–≤—ã–∫–æ–≤")
        elif skills_file:
            st.info("üìä –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ç–∞–∫–∂–µ —Ñ–∞–π–ª —Å –¥–∞–Ω–Ω—ã–º–∏ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤")
        else:
            st.info("üìÅ –ó–∞–≥—Ä—É–∑–∏—Ç–µ –æ–±–∞ —Ñ–∞–π–ª–∞ –¥–ª—è –Ω–∞—á–∞–ª–∞ —Ä–∞–±–æ—Ç—ã")

    elif tool == "–û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–µ—Ä–µ—Å–¥–∞—á –≤–Ω–µ—à–Ω–µ–π –æ—Ü–µ–Ω–∫–∏":
        st.header("üìù –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–µ—Ä–µ—Å–¥–∞—á –≤–Ω–µ—à–Ω–µ–π –æ—Ü–µ–Ω–∫–∏")
        st.markdown("""
        –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –ø–µ—Ä–µ—Å–¥–∞—á –∏–∑ –≤–Ω–µ—à–Ω–µ–π —Å–∏—Å—Ç–µ–º—ã –æ—Ü–µ–Ω–∏–≤–∞–Ω–∏—è —Å –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–µ–π Supabase.
        **–¢—Ä–µ–±—É–µ—Ç—Å—è:**
        1. **–§–∞–π–ª —Å –æ—Ü–µ–Ω–∫–∞–º–∏** ‚Äî —Ç–∞–±–ª–∏—Ü–∞ –∏–∑ –≤–Ω–µ—à–Ω–µ–π —Å–∏—Å—Ç–µ–º—ã —Å —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è–º–∏
        2. **–°–ø–∏—Å–æ–∫ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤** ‚Äî –∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏–∑ Supabase (—Ç–∞–±–ª–∏—Ü–∞ `students`)
        """)
        try:
            supabase = get_supabase_client()
            st.success("‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Supabase —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ")
        except Exception as e:
            st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Supabase: {str(e)}")
            st.stop()
        st.markdown("---")
        st.subheader("üìä –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞ —Å –æ—Ü–µ–Ω–∫–∞–º–∏")
        grades_file = st.file_uploader(
            "–í—ã–±–µ—Ä–∏—Ç–µ —Ñ–∞–π–ª —Å –æ—Ü–µ–Ω–∫–∞–º–∏ (external_assessment)",
            type=['xlsx', 'xls'],
            key="external_grades_file"
        )
        if grades_file:
            try:
                with st.spinner("üì• –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞ —Å –æ—Ü–µ–Ω–∫–∞–º–∏‚Ä¶"):
                    grades_df = pd.read_excel(grades_file)
                st.success("‚úÖ –§–∞–π–ª —Å –æ—Ü–µ–Ω–∫–∞–º–∏ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω!")
                with st.spinner("üì• –ó–∞–≥—Ä—É–∑–∫–∞ —Å–ø–∏—Å–∫–∞ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ –∏–∑ Supabase‚Ä¶"):
                    students_df = load_students_from_supabase()
                if students_df.empty:
                    st.error("‚ùå –°–ø–∏—Å–æ–∫ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ –ø—É—Å—Ç. –ó–∞–≥—Ä—É–∑–∏—Ç–µ –¥–∞–Ω–Ω—ã–µ –≤ —Ç–∞–±–ª–∏—Ü—É `students` –≤ Supabase.")
                    st.stop()
                else:
                    st.success(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(students_df)} —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ –∏–∑ Supabase")
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("–ó–∞–ø–∏—Å–µ–π —Å –æ—Ü–µ–Ω–∫–∞–º–∏", len(grades_df))
                with col2:
                    st.metric("–°—Ç—É–¥–µ–Ω—Ç–æ–≤ –≤ –±–∞–∑–µ", len(students_df))
                with col3:
                    st.metric("–ö–æ–ª–æ–Ω–æ–∫ –≤ –æ—Ü–µ–Ω–∫–∞—Ö", len(grades_df.columns))
                col_preview1, col_preview2 = st.columns(2)
                with col_preview1:
                    with st.expander("üëÄ –ü—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä —Ñ–∞–π–ª–∞ —Å –æ—Ü–µ–Ω–∫–∞–º–∏"):
                        st.dataframe(grades_df.head(), use_container_width=True)
                with col_preview2:
                    with st.expander("üëÄ –ü—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä —Å–ø–∏—Å–∫–∞ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤"):
                        st.dataframe(students_df.head(10), use_container_width=True)
                if st.button("üöÄ –û–±—Ä–∞–±–æ—Ç–∞—Ç—å –¥–∞–Ω–Ω—ã–µ", type="primary", key="process_btn"):
                    with st.spinner("‚öôÔ∏è –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–µ—Ä–µ—Å–¥–∞—á‚Ä¶"):
                        try:
                            result_df = process_external_assessment(grades_df, students_df)
                            if result_df.empty:
                                st.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –¥–∞–Ω–Ω—ã–µ. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Ñ–∞–π–ª–∞.")
                            else:
                                st.success("‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
                                with st.spinner("üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ Supabase‚Ä¶"):
                                    try:
                                        new_count, total_count = save_to_supabase(result_df)
                                        st.success(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ Supabase: {new_count} –Ω–æ–≤—ã—Ö –∑–∞–ø–∏—Å–µ–π –∏–∑ {total_count}")
                                    except Exception as e:
                                        st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏: {str(e)}")
                                st.subheader("üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—Ä–∞–±–æ—Ç–∫–∏")
                                col1, col2, col3 = st.columns(3)
                                with col1:
                                    st.metric("–í—Å–µ–≥–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∑–∞–ø–∏—Å–µ–π", total_count)
                                with col2:
                                    st.metric("–ù–æ–≤—ã—Ö –∑–∞–ø–∏—Å–µ–π", new_count)
                                with col3:
                                    st.metric("–£–∂–µ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–ª–æ", total_count - new_count)
                                new_records_df = get_new_records(result_df)
                                tab1, tab2 = st.tabs(["üìã –í—Å–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ", "üÜï –¢–æ–ª—å–∫–æ –Ω–æ–≤—ã–µ –∑–∞–ø–∏—Å–∏"])
                                with tab1:
                                    st.dataframe(result_df, use_container_width=True)
                                    output_all = io.BytesIO()
                                    with pd.ExcelWriter(output_all, engine='openpyxl') as writer:
                                        result_df.to_excel(writer, index=False, sheet_name='–í—Å–µ –ø–µ—Ä–µ—Å–¥–∞—á–∏')
                                    output_all.seek(0)
                                    current_date = datetime.now().strftime('%d-%m-%Y')
                                    st.download_button(
                                        label="üì• –°–∫–∞—á–∞—Ç—å –≤—Å–µ –∑–∞–ø–∏—Å–∏ (XLSX)",
                                        data=output_all.getvalue(),
                                        file_name=f"–ü–µ—Ä–µ—Å–¥–∞—á–∏_–≤—Å–µ_{current_date}.xlsx",
                                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                                        key="download_all"
                                    )
                                with tab2:
                                    if new_records_df.empty:
                                        st.info("‚ÑπÔ∏è –ù–æ–≤—ã—Ö –∑–∞–ø–∏—Å–µ–π –Ω–µ—Ç. –í—Å–µ –¥–∞–Ω–Ω—ã–µ —É–∂–µ –±—ã–ª–∏ –≤ –±–∞–∑–µ.")
                                    else:
                                        st.dataframe(new_records_df, use_container_width=True)
                                        output_new = io.BytesIO()
                                        with pd.ExcelWriter(output_new, engine='openpyxl') as writer:
                                            new_records_df.to_excel(writer, index=False, sheet_name='–ù–æ–≤—ã–µ –ø–µ—Ä–µ—Å–¥–∞—á–∏')
                                        output_new.seek(0)
                                        st.download_button(
                                            label="üì• –°–∫–∞—á–∞—Ç—å —Ç–æ–ª—å–∫–æ –Ω–æ–≤—ã–µ –∑–∞–ø–∏—Å–∏ (XLSX)",
                                            data=output_new.getvalue(),
                                            file_name=f"–ü–µ—Ä–µ—Å–¥–∞—á–∏_–Ω–æ–≤—ã–µ_{current_date}.xlsx",
                                            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                                            key="download_new"
                                        )
                                with st.expander("üìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –æ–±—Ä–∞–±–æ—Ç–∫–µ"):
                                    col1, col2 = st.columns(2)
                                    with col1:
                                        if '–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –¥–∏—Å—Ü–∏–ø–ª–∏–Ω—ã' in result_df.columns:
                                            st.write("**–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –¥–∏—Å—Ü–∏–ø–ª–∏–Ω–∞–º:**")
                                            discipline_counts = result_df['–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –¥–∏—Å—Ü–∏–ø–ª–∏–Ω—ã'].value_counts()
                                            st.dataframe(discipline_counts)
                                    with col2:
                                        if '–§–ò–û' in result_df.columns:
                                            st.write("**–£–Ω–∏–∫–∞–ª—å–Ω—ã–µ —Å—Ç—É–¥–µ–Ω—Ç—ã:**")
                                            st.metric("–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å—Ç—É–¥–µ–Ω—Ç–æ–≤", result_df['–§–ò–û'].nunique())
                        except Exception as e:
                            st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ: {str(e)}")
            except Exception as e:
                st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Ñ–∞–π–ª–∞: {str(e)}")
        else:
            st.info("üìÅ –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª —Å –æ—Ü–µ–Ω–∫–∞–º–∏ –¥–ª—è –Ω–∞—á–∞–ª–∞ —Ä–∞–±–æ—Ç—ã")
            with st.expander("üìä –¢–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"):
                existing_peresdachi = load_existing_peresdachi()
                if existing_peresdachi.empty:
                    st.info("‚ÑπÔ∏è –¢–∞–±–ª–∏—Ü–∞ peresdachi –ø—É—Å—Ç–∞ –∏–ª–∏ –Ω–µ —Å–æ–∑–¥–∞–Ω–∞")
                else:
                    st.metric("–ó–∞–ø–∏—Å–µ–π –≤ —Ç–∞–±–ª–∏—Ü–µ peresdachi", len(existing_peresdachi))
                    st.dataframe(existing_peresdachi.head(10), use_container_width=True)

    elif tool == "–ê–Ω–∞–ª–∏—Ç–∏–∫–∞ –∫—É—Ä—Å–æ–≤":
        st.header("üìä –ê–Ω–∞–ª–∏—Ç–∏–∫–∞ –∫—É—Ä—Å–æ–≤")
        st.markdown("""
        –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏ –∑–∞–≥—Ä—É–∑–∫–∞ –∞–Ω–∞–ª–∏—Ç–∏–∫–∏ –∫—É—Ä—Å–æ–≤ –≤ Supabase.
        """)
        try:
            supabase = get_supabase_client()
            st.success("‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Supabase —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ")
        except Exception as e:
            st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Supabase: {str(e)}")
            st.stop()
        st.markdown("---")
        st.subheader("üìÅ –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–æ–≤ –∫—É—Ä—Å–æ–≤")
        col1, col2, col3 = st.columns(3)
        with col1:
            course_cg_file = st.file_uploader("üìä –ö—É—Ä—Å –¶–ì", type=['csv', 'xlsx', 'xls'], key="cg_file")
        with col2:
            course_python_file = st.file_uploader("üêç –ö—É—Ä—Å Python", type=['csv', 'xlsx', 'xls'], key="python_file")
        with col3:
            course_analysis_file = st.file_uploader("üìà –ö—É—Ä—Å –ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö", type=['csv', 'xlsx', 'xls'], key="analysis_file")
        files_uploaded = all([course_cg_file, course_python_file, course_analysis_file])
        if not files_uploaded:
            st.info("üìù –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –∑–∞–≥—Ä—É–∑–∏—Ç–µ –≤—Å–µ —Ç—Ä–∏ —Ñ–∞–π–ª–∞ –∫—É—Ä—Å–æ–≤:")
            file_status = {
                "–ö—É—Ä—Å –¶–ì": "‚úÖ" if course_cg_file else "‚ùå",
                "–ö—É—Ä—Å Python": "‚úÖ" if course_python_file else "‚ùå",
                "–ö—É—Ä—Å –ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö": "‚úÖ" if course_analysis_file else "‚ùå"
            }
            st.table(pd.DataFrame([{"–§–∞–π–ª": k, "–°—Ç–∞—Ç—É—Å": v} for k, v in file_status.items()]))
        else:
            st.success("‚úÖ –í—Å–µ —Ñ–∞–π–ª—ã –∑–∞–≥—Ä—É–∂–µ–Ω—ã! –ì–æ—Ç–æ–≤–æ –∫ –æ–±—Ä–∞–±–æ—Ç–∫–µ.")
            if st.button("üöÄ –û–±—Ä–∞–±–æ—Ç–∞—Ç—å –∫—É—Ä—Å—ã", type="primary", key="process_courses_btn"):
                with st.spinner("üîÑ –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö‚Ä¶"):
                    try:
                        st.info("üìä –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–æ–≤ –∫—É—Ä—Å–æ–≤‚Ä¶")
                        course_names = ['–¶–ì', '–ü–∏—Ç–æ–Ω', '–ê–Ω–¥–∞–Ω']
                        course_files = [course_cg_file, course_python_file, course_analysis_file]
                        course_data_list = []
                        for course_file, course_name in zip(course_files, course_names):
                            course_data = extract_course_data(course_file, course_name)
                            if course_data is None:
                                st.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∫—É—Ä—Å–∞ {course_name}")
                                st.stop()
                            course_data_list.append(course_data)
                            st.success(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω –∫—É—Ä—Å {course_name}: {len(course_data)} –∑–∞–ø–∏—Å–µ–π")
                        st.info("üíæ –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∫—É—Ä—Å–æ–≤ –≤ Supabase‚Ä¶")
                        success_count = 0
                        for course_data, course_name in zip(course_data_list, course_names):
                            if upload_course_data_to_supabase(supabase, course_data, course_name):
                                success_count += 1
                        if success_count == len(course_names):
                            st.success(f"üéâ –í—Å–µ {success_count} –∫—É—Ä—Å–∞ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã!")
                            st.subheader("üìã –°–≤–æ–¥–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞")
                            summary_data = []
                            for course_data, course_name in zip(course_data_list, course_names):
                                col_name = f'–ü—Ä–æ—Ü–µ–Ω—Ç_{course_name}'
                                if col_name in course_data.columns:
                                    course_stats = course_data[col_name].dropna()
                                    if len(course_stats) > 0:
                                        avg_completion = course_stats.mean()
                                        students_100 = len(course_stats[course_stats == 100.0])
                                        students_0 = len(course_stats[course_stats == 0.0])
                                        total_students = len(course_stats)
                                        summary_data.append({
                                            '–ö—É—Ä—Å': course_name,
                                            '–°—Ç—É–¥–µ–Ω—Ç–æ–≤ –≤—Å–µ–≥–æ': total_students,
                                            '–°—Ä–µ–¥–Ω–∏–π %': f"{avg_completion:.1f}%",
                                            '100%': students_100,
                                            '0%': students_0
                                        })
                            if summary_data:
                                st.table(pd.DataFrame(summary_data))
                            st.balloons()
                        else:
                            st.error(f"‚ùå –ó–∞–≥—Ä—É–∂–µ–Ω–æ —Ç–æ–ª—å–∫–æ {success_count} –∏–∑ {len(course_names)} –∫—É—Ä—Å–æ–≤")
                    except Exception as e:
                        st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ: {str(e)}")

    else:  # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤
        st.header("üë• –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤")
        st.markdown("""
        –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö Supabase.
        """)
        try:
            supabase = get_supabase_client()
            st.success("‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Supabase —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ")
        except Exception as e:
            st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Supabase: {str(e)}")
            st.stop()
        st.markdown("---")
        st.subheader("üìÅ –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞ —Å–æ —Å—Ç—É–¥–µ–Ω—Ç–∞–º–∏")
        students_file = st.file_uploader(
            "–í—ã–±–µ—Ä–∏—Ç–µ —Ñ–∞–π–ª —Å–æ —Å–ø–∏—Å–∫–æ–º —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ (Excel –∏–ª–∏ CSV)",
            type=['xlsx', 'xls', 'csv'],
            key="students_upload_file"
        )
        if students_file:
            try:
                with st.spinner("üìÑ –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞‚Ä¶"):
                    students_df = load_student_list_file(students_file)
                if students_df.empty:
                    st.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –∏–∑ —Ñ–∞–π–ª–∞. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞.")
                    st.stop()
                st.success(f"‚úÖ –§–∞–π–ª —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω!")
                st.subheader("üìä –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è")
                col1, col2 = st.columns(2)
                with col1:
                    st.metric("–ó–∞–ø–∏—Å–µ–π –≤ —Ñ–∞–π–ª–µ", len(students_df))
                with col2:
                    st.metric("–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö email", students_df['–ö–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∞—è –ø–æ—á—Ç–∞'].nunique())
                with st.expander("üëÄ –ü—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä –¥–∞–Ω–Ω—ã—Ö"):
                    st.dataframe(students_df.head(20), use_container_width=True)
                if st.button("üöÄ –û–±–Ω–æ–≤–∏—Ç—å —Å–ø–∏—Å–æ–∫ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ –≤ Supabase", type="primary", key="update_students_btn"):
                    with st.spinner("üîÑ –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö‚Ä¶"):
                        try:
                            if upload_students_to_supabase(supabase, students_df):
                                st.success("‚úÖ –°–ø–∏—Å–æ–∫ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ –æ–±–Ω–æ–≤–ª—ë–Ω!")
                                st.balloons()
                            else:
                                st.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±–Ω–æ–≤–∏—Ç—å —Å–ø–∏—Å–æ–∫ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤")
                        except Exception as e:
                            st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏: {str(e)}")
            except Exception as e:
                st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Ñ–∞–π–ª–∞: {str(e)}")
        else:
            st.info("üìÅ –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª —Å–æ —Å–ø–∏—Å–∫–æ–º —Å—Ç—É–¥–µ–Ω—Ç–æ–≤")
            with st.expander("üìä –¢–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"):
                try:
                    current_students = load_students_from_supabase()
                    if current_students.empty:
                        st.info("‚ÑπÔ∏è –¢–∞–±–ª–∏—Ü–∞ students –ø—É—Å—Ç–∞ –∏–ª–∏ –Ω–µ —Å–æ–∑–¥–∞–Ω–∞")
                    else:
                        st.success(f"‚úÖ –í –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö: {len(current_students)} —Å—Ç—É–¥–µ–Ω—Ç–æ–≤")
                        st.dataframe(current_students.head(10), use_container_width=True)
                except Exception as e:
                    st.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ: {str(e)}")

    # –§—É—Ç–µ—Ä (Apple-style)
    st.markdown("""
    <div class="custom-footer">
        DataCulture Platform v1.0 ¬∑ Created by –¢–∏–º–æ—à–∫–∞
    </div>
    """, unsafe_allow_html=True)

if __name__ == "__main__":
    main()
